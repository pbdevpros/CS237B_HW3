{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pbdevpros/CS237B_HW3/blob/P2ii/il_dist_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from gym_carlo.envs.geometry import Point\n",
        "\n",
        "scenario_names = ['intersection', 'circularroad', 'lanechange']\n",
        "obs_sizes = {'intersection': 5, 'circularroad': 4, 'lanechange': 3}\n",
        "goals = {'intersection': ['left','straight','right'], 'circularroad': ['inner','outer'], 'lanechange': ['left','right']}\n",
        "steering_lims = {'intersection': [-0.5,0.5], 'circularroad': [-0.15,0.15], 'lanechange': [-0.15, 0.15]}\n",
        "\n",
        "def maybe_makedirs(path_to_create):\n",
        "    \"\"\"This function will create a directory, unless it exists already,\n",
        "    at which point the function will return.\n",
        "    The exception handling is necessary as it prevents a race condition\n",
        "    from occurring.\n",
        "    Inputs:\n",
        "        path_to_create - A string path to a directory you'd like created.\n",
        "    \"\"\"\n",
        "    try: \n",
        "        os.makedirs(path_to_create)\n",
        "    except OSError:\n",
        "        if not os.path.isdir(path_to_create):\n",
        "            raise\n",
        "\n",
        "\n",
        "def load_data(args):\n",
        "    data_name = args.goal.lower()\n",
        "    scenario_name = args.scenario.lower()\n",
        "      \n",
        "    assert scenario_name in goals.keys(), '--scenario argument is invalid!'\n",
        "    data = {}\n",
        "    if data_name == 'all':\n",
        "        np_data = [np.load('data/' + scenario_name + '_' + dn + '.npy') for dn in goals[scenario_name]]\n",
        "        u = np.vstack([np.ones((np_data[i].shape[0],1))*i for i in range(len(np_data))])\n",
        "        np_data = np.vstack(np_data)\n",
        "        data['u_train'] = np.array(u).astype('uint8').reshape(-1,1)\n",
        "    else:\n",
        "        assert data_name in goals[scenario_name], '--data argument is invalid!'\n",
        "        np_data = np.load('data/' + scenario_name + '_' + data_name + '.npy')\n",
        "\n",
        "    data['x_train'] = np_data[:,:-2].astype('float32')\n",
        "    data['y_train'] = np_data[:,-2:].astype('float32') # control is always 2D: throttle and steering\n",
        "    \n",
        "    return data\n",
        "    \n",
        "   \n",
        "def optimal_act_circularroad(env, d):\n",
        "    if env.ego.speed > 10:\n",
        "        throttle = 0.06 + np.random.randn()*0.02\n",
        "    else:\n",
        "        throttle = 0.6 + np.random.randn()*0.1\n",
        "        \n",
        "    # setting the steering is not fun. Let's practice some trigonometry\n",
        "    r1 = 30.0 # inner building radius (not used rn)\n",
        "    r2 = 39.2 # inner ring radius\n",
        "    R = 32.3 # desired radius\n",
        "    if d==1: R += 4.9\n",
        "    Rp = np.sqrt(r2**2 - R**2) # distance between current \"target\" point and the current desired point\n",
        "    theta = np.arctan2(env.ego.y - 60, env.ego.x - 60)\n",
        "    target = Point(60 + R*np.cos(theta) + Rp*np.cos(3*np.pi/2-theta), 60 + R*np.sin(theta) - Rp*np.sin(3*np.pi/2-theta)) # this is pure magic (or I need to draw it to explain)\n",
        "    desired_heading = np.arctan2(target.y - env.ego.y, target.x - env.ego.x) % (2*np.pi)\n",
        "    h = np.array([env.ego.heading, env.ego.heading - 2*np.pi])\n",
        "    hi = np.argmin(np.abs(desired_heading - h))\n",
        "    if desired_heading >= h[hi]: steering = 0.15 + np.random.randn()*0.05\n",
        "    else: steering = -0.15 + np.random.randn()*0.05\n",
        "    return np.array([steering, throttle]).reshape(1,-1)\n",
        "    \n",
        "    \n",
        "def optimal_act_lanechange(env, d):\n",
        "    if env.ego.speed > 10:\n",
        "        throttle = 0.06 + np.random.randn()*0.02\n",
        "    else:\n",
        "        throttle = 0.8 + np.random.randn()*0.1\n",
        "        \n",
        "    if d==0:\n",
        "        target = Point(37.55, env.ego.y + env.ego.speed*3)\n",
        "    elif d==1:\n",
        "        target = Point(42.45, env.ego.y + env.ego.speed*3)\n",
        "    desired_heading = np.arctan2(target.y - env.ego.y, target.x - env.ego.x) % (2*np.pi)\n",
        "    h = np.array([env.ego.heading, env.ego.heading - 2*np.pi])\n",
        "    hi = np.argmin(np.abs(desired_heading - h))\n",
        "    if desired_heading >= h[hi]: steering = 0.15 + np.random.randn()*0.05\n",
        "    else: steering = -0.15 + np.random.randn()*0.05\n",
        "    return np.array([steering, throttle]).reshape(1,-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "GSnk_UQ0O77d",
        "outputId": "062784fb-2026-409d-dcbb-867bb42badb9"
      },
      "id": "GSnk_UQ0O77d",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-9610a96989dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgym_carlo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscenario_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'intersection'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'circularroad'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lanechange'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gym_carlo'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow_probability import distributions as tfd\n",
        "import argparse\n",
        "# from utils import *\n",
        "\n",
        "tf.config.run_functions_eagerly(True)\n",
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions"
      ],
      "metadata": {
        "id": "iE2lWeSaO6u6"
      },
      "id": "iE2lWeSaO6u6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c07555ce",
      "metadata": {
        "id": "c07555ce"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9c52127",
      "metadata": {
        "id": "b9c52127"
      },
      "outputs": [],
      "source": [
        "def nn(data, args):\n",
        "    \"\"\"\n",
        "    Trains a feedforward NN. \n",
        "    \"\"\"\n",
        "    params = {\n",
        "        'train_batch_size': 4096*32,\n",
        "    }\n",
        "    in_size = data['x_train'].shape[-1]\n",
        "    out_size = data['y_train'].shape[-1]\n",
        "    \n",
        "    nn_model = NN(in_size, out_size)\n",
        "    if args.restore:\n",
        "        nn_model.load_weights('./policies/' + args.scenario.lower() + '_' + args.goal.lower() + '_ILDIST')\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\n",
        "\n",
        "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(x, y):\n",
        "        ######### Your code starts here #########\n",
        "        # We want to perform a single training step (for one batch):\n",
        "        # 1. Make a forward pass through the model\n",
        "        # 2. Calculate the loss for the output of the forward pass\n",
        "        # 3. Based on the loss calculate the gradient for all weights\n",
        "        # 4. Run an optimization step on the weights.\n",
        "        # Helpful Functions: tf.GradientTape(), tf.GradientTape.gradient(), tf.keras.Optimizer.apply_gradients\n",
        "        with tf.GradientTape() as tape:\n",
        "            # forward pass\n",
        "            y_est = nn_model(x, training=True) # use dropout\n",
        "            # compute the loss\n",
        "            current_loss = loss(y_est, y)\n",
        "        grads = tape.gradient(current_loss, nn_model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, nn_model.trainable_variables))\n",
        "        ########## Your code ends here ##########\n",
        "\n",
        "        train_loss(current_loss)\n",
        "\n",
        "    @tf.function\n",
        "    def train(train_data):\n",
        "        for x, y in train_data:\n",
        "            train_step(x, y)\n",
        "\n",
        "\n",
        "    train_data = tf.data.Dataset.from_tensor_slices((data['x_train'], data['y_train'])).shuffle(100000).batch(params['train_batch_size'])\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        # Reset the metrics at the start of the next epoch\n",
        "        train_loss.reset_states()\n",
        "\n",
        "        train(train_data)\n",
        "\n",
        "        template = 'Epoch {}, Loss: {}'\n",
        "        print(template.format(epoch + 1, train_loss.result()))\n",
        "    nn_model.save_weights('./policies/' + args.scenario.lower() + '_' + args.goal.lower() + '_ILDIST')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23e6db4a",
      "metadata": {
        "id": "23e6db4a"
      },
      "source": [
        "# Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33c1573e",
      "metadata": {
        "id": "33c1573e"
      },
      "outputs": [],
      "source": [
        "class MixtureDensityModelErrorFinal(tf.keras.losses.Loss):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(MixtureDensityModelErrorFinal, self).__init__()\n",
        "\n",
        "    def call(self, y_true, y_pred, sample_weight=None):\n",
        "        y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
        "        self.z_mu = y_pred[:, :2]\n",
        "        self.z_sigma = y_pred[:, 2:]\n",
        "        epsilon = 0.00001\n",
        "        # print(self.z_mu.shape)\n",
        "        # print(self.z_sigma.shape)\n",
        "        # B, N = self.z_sigma.shape\n",
        "        # self.z_sigma = tf.reshape(self.z_sigma, (B, int(N/2), int(N/2)))\n",
        "        # covariance = self.z_sigma @ tf.transpose(self.z_sigma, perm=[0, 2, 1])\n",
        "        scale_tril = tfp.math.fill_triangular(self.z_sigma) + epsilon\n",
        "        # sigma = tf.matmul(scale_tril, tf.transpose(scale_tril, perm=[0, 2, 1]))\n",
        "        # print(covariance.shape)\n",
        "        mvn = tfd.MultivariateNormalTriL(loc=self.z_mu, scale_tril=scale_tril, allow_nan_stats=False)\n",
        "        # E = tf.reduce_mean(tf.math.log(mvn.prob(y_true)), 0)\n",
        "        E = tf.reduce_mean(mvn.log_prob(y_true), 0)\n",
        "        return -1 * E\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3edec096",
      "metadata": {
        "id": "3edec096"
      },
      "outputs": [],
      "source": [
        "def loss(y_est, y):\n",
        "    y = tf.cast(y, dtype=tf.float32)\n",
        "    ######### Your code starts here #########\n",
        "    # We want to compute the negative log-likelihood loss between y_est and y where\n",
        "    # - y_est is the output of the network for a batch of observations,\n",
        "    # - y is the actions the expert took for the corresponding batch of observations\n",
        "    # At the end your code should return the scalar loss value.\n",
        "    # HINT: You may find the classes of tensorflow_probability.distributions (imported as tfd) useful.\n",
        "    #       In particular, you can use MultivariateNormalFullCovariance or MultivariateNormalTriL, but they are not the only way.\n",
        "    # loss_object = MixtureDensityModelError(num_means=2, num_kernels=3)\n",
        "    loss_object = MixtureDensityModelErrorFinal()\n",
        "    sample_weights = tf.constant(([0.8, 0.2]))\n",
        "    y = y * sample_weights\n",
        "    y_est = y_est * tf.constant(([0.8, 0.2, 0.1, 0.1, 0.1]))\n",
        "    return loss_object(y, y_est)\n",
        "    \n",
        "    ########## Your code ends here ##########"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a6b1d42",
      "metadata": {
        "id": "1a6b1d42"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b7c8641",
      "metadata": {
        "id": "9b7c8641"
      },
      "outputs": [],
      "source": [
        "class NN(tf.keras.Model):\n",
        "    def __init__(self, in_size, out_size):\n",
        "        super(NN, self).__init__()\n",
        "        \n",
        "        ######### Your code starts here #########\n",
        "        # We want to define and initialize the weights & biases of the neural network.\n",
        "        # - in_size is dim(O)\n",
        "        # - out_size is dim(A) = 2\n",
        "        # IMPORTANT: out_size is still 2 in this case, because the action space is 2-dimensional. But your network will output some other size as it is outputing a distribution!\n",
        "        # HINT: You should use either of the following for weight initialization:\n",
        "        #         - tf.keras.initializers.GlorotUniform (this is what we tried)\n",
        "        #         - tf.keras.initializers.GlorotNormal\n",
        "        #         - tf.keras.initializers.he_uniform or tf.keras.initializers.he_normal\n",
        "        self.internal_layers = [\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(24, kernel_initializer=tf.keras.initializers.GlorotUniform(), activation='relu'),\n",
        "            # tf.keras.layers.Dropout(0.1),\n",
        "            tf.keras.layers.Dense(24, kernel_initializer=tf.keras.initializers.GlorotUniform(), activation='relu'),\n",
        "            # tf.keras.layers.Dropout(0.2),\n",
        "            # tf.keras.layers.Dense(12, kernel_initializer=tf.keras.initializers.GlorotUniform(), activation='relu'),\n",
        "        ]\n",
        "        # num_outputs = (out_size + 2) * 3 # Removed after using only 6 ouputs\n",
        "        num_outputs = out_size + 3\n",
        "        self.layer_output = tf.keras.layers.Dense(num_outputs, kernel_initializer=tf.keras.initializers.GlorotUniform(), activation='relu')\n",
        "        ########## Your code ends here ##########\n",
        "\n",
        "    def call(self, x):\n",
        "        x = tf.cast(x, dtype=tf.float32)\n",
        "        ######### Your code starts here #########\n",
        "        # We want to perform a forward-pass of the network. Using the weights and biases, this function should give the network output for x where:\n",
        "        # x is a (?, |O|) tensor that keeps a batch of observations\n",
        "        # IMPORTANT: First two columns of the output tensor must correspond to the mean vector!\n",
        "        for i in range(len(self.internal_layers)):\n",
        "            layer = self.internal_layers[i]\n",
        "            x = layer(x)\n",
        "        return self.layer_output(x)\n",
        "        ########## Your code ends here ##########"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f9de95d",
      "metadata": {
        "id": "2f9de95d"
      },
      "source": [
        "# Run Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceb1fdaf",
      "metadata": {
        "id": "ceb1fdaf"
      },
      "outputs": [],
      "source": [
        "args = parser\n",
        "args.scenario = \"intersection\"\n",
        "args.restore = False\n",
        "args.goal = \"left\"\n",
        "args.epochs = 3\n",
        "args.lr = 0.0002\n",
        "data = load_data(args)\n",
        "# nn(data, args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1065c665",
      "metadata": {
        "id": "1065c665"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}