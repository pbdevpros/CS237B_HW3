{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaHj6n4KRzjC",
        "outputId": "679cd309-79e8-473e-e86c-721b7d3c9b57"
      },
      "id": "MaHj6n4KRzjC",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/CS237B_HW3-P2ii\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "636mOlCXSdOP",
        "outputId": "4af5eea6-01a0-4d23-ef2e-f92ba3b8ab0a"
      },
      "id": "636mOlCXSdOP",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CS237B_HW3-P2ii\n",
            "\u001b[0m\u001b[01;34mcustom\u001b[0m/                 make_submission.sh  test_coil.py    train_ildist.py\n",
            "\u001b[01;34mdata\u001b[0m/                   play.py             test_ildist.py  train_il.py\n",
            "\u001b[01;34mgym_carlo\u001b[0m/              \u001b[01;34mpolicies\u001b[0m/           test_il.py      utils.py\n",
            "il_dist_notebook.ipynb  requirements.txt    \u001b[01;34mtex\u001b[0m/\n",
            "intent_inference.py     shared_autonomy.py  train_coil.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['DISPLAY']=':0.0'"
      ],
      "metadata": {
        "id": "Y6qP3zwnS3WL"
      },
      "id": "Y6qP3zwnS3WL",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from gym_carlo.envs.geometry import Point\n",
        "\n",
        "scenario_names = ['intersection', 'circularroad', 'lanechange']\n",
        "obs_sizes = {'intersection': 5, 'circularroad': 4, 'lanechange': 3}\n",
        "goals = {'intersection': ['left','straight','right'], 'circularroad': ['inner','outer'], 'lanechange': ['left','right']}\n",
        "steering_lims = {'intersection': [-0.5,0.5], 'circularroad': [-0.15,0.15], 'lanechange': [-0.15, 0.15]}\n",
        "\n",
        "def maybe_makedirs(path_to_create):\n",
        "    \"\"\"This function will create a directory, unless it exists already,\n",
        "    at which point the function will return.\n",
        "    The exception handling is necessary as it prevents a race condition\n",
        "    from occurring.\n",
        "    Inputs:\n",
        "        path_to_create - A string path to a directory you'd like created.\n",
        "    \"\"\"\n",
        "    try: \n",
        "        os.makedirs(path_to_create)\n",
        "    except OSError:\n",
        "        if not os.path.isdir(path_to_create):\n",
        "            raise\n",
        "\n",
        "\n",
        "def load_data(args):\n",
        "    data_name = args.goal.lower()\n",
        "    scenario_name = args.scenario.lower()\n",
        "      \n",
        "    assert scenario_name in goals.keys(), '--scenario argument is invalid!'\n",
        "    data = {}\n",
        "    if data_name == 'all':\n",
        "        np_data = [np.load('data/' + scenario_name + '_' + dn + '.npy') for dn in goals[scenario_name]]\n",
        "        u = np.vstack([np.ones((np_data[i].shape[0],1))*i for i in range(len(np_data))])\n",
        "        np_data = np.vstack(np_data)\n",
        "        data['u_train'] = np.array(u).astype('uint8').reshape(-1,1)\n",
        "    else:\n",
        "        assert data_name in goals[scenario_name], '--data argument is invalid!'\n",
        "        np_data = np.load('data/' + scenario_name + '_' + data_name + '.npy')\n",
        "\n",
        "    data['x_train'] = np_data[:,:-2].astype('float32')\n",
        "    data['y_train'] = np_data[:,-2:].astype('float32') # control is always 2D: throttle and steering\n",
        "    \n",
        "    return data\n",
        "    \n",
        "   \n",
        "def optimal_act_circularroad(env, d):\n",
        "    if env.ego.speed > 10:\n",
        "        throttle = 0.06 + np.random.randn()*0.02\n",
        "    else:\n",
        "        throttle = 0.6 + np.random.randn()*0.1\n",
        "        \n",
        "    # setting the steering is not fun. Let's practice some trigonometry\n",
        "    r1 = 30.0 # inner building radius (not used rn)\n",
        "    r2 = 39.2 # inner ring radius\n",
        "    R = 32.3 # desired radius\n",
        "    if d==1: R += 4.9\n",
        "    Rp = np.sqrt(r2**2 - R**2) # distance between current \"target\" point and the current desired point\n",
        "    theta = np.arctan2(env.ego.y - 60, env.ego.x - 60)\n",
        "    target = Point(60 + R*np.cos(theta) + Rp*np.cos(3*np.pi/2-theta), 60 + R*np.sin(theta) - Rp*np.sin(3*np.pi/2-theta)) # this is pure magic (or I need to draw it to explain)\n",
        "    desired_heading = np.arctan2(target.y - env.ego.y, target.x - env.ego.x) % (2*np.pi)\n",
        "    h = np.array([env.ego.heading, env.ego.heading - 2*np.pi])\n",
        "    hi = np.argmin(np.abs(desired_heading - h))\n",
        "    if desired_heading >= h[hi]: steering = 0.15 + np.random.randn()*0.05\n",
        "    else: steering = -0.15 + np.random.randn()*0.05\n",
        "    return np.array([steering, throttle]).reshape(1,-1)\n",
        "    \n",
        "    \n",
        "def optimal_act_lanechange(env, d):\n",
        "    if env.ego.speed > 10:\n",
        "        throttle = 0.06 + np.random.randn()*0.02\n",
        "    else:\n",
        "        throttle = 0.8 + np.random.randn()*0.1\n",
        "        \n",
        "    if d==0:\n",
        "        target = Point(37.55, env.ego.y + env.ego.speed*3)\n",
        "    elif d==1:\n",
        "        target = Point(42.45, env.ego.y + env.ego.speed*3)\n",
        "    desired_heading = np.arctan2(target.y - env.ego.y, target.x - env.ego.x) % (2*np.pi)\n",
        "    h = np.array([env.ego.heading, env.ego.heading - 2*np.pi])\n",
        "    hi = np.argmin(np.abs(desired_heading - h))\n",
        "    if desired_heading >= h[hi]: steering = 0.15 + np.random.randn()*0.05\n",
        "    else: steering = -0.15 + np.random.randn()*0.05\n",
        "    return np.array([steering, throttle]).reshape(1,-1)"
      ],
      "metadata": {
        "id": "GSnk_UQ0O77d"
      },
      "id": "GSnk_UQ0O77d",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow_probability import distributions as tfd\n",
        "import argparse\n",
        "# from utils import *\n",
        "\n",
        "tf.config.run_functions_eagerly(True)\n",
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions"
      ],
      "metadata": {
        "id": "iE2lWeSaO6u6"
      },
      "id": "iE2lWeSaO6u6",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c07555ce",
      "metadata": {
        "id": "c07555ce"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "b9c52127",
      "metadata": {
        "id": "b9c52127"
      },
      "outputs": [],
      "source": [
        "def nn(data, args):\n",
        "    \"\"\"\n",
        "    Trains a feedforward NN. \n",
        "    \"\"\"\n",
        "    params = {\n",
        "        'train_batch_size': 4096*32,\n",
        "    }\n",
        "    in_size = data['x_train'].shape[-1]\n",
        "    out_size = data['y_train'].shape[-1]\n",
        "    \n",
        "    nn_model = NN(in_size, out_size)\n",
        "    if args.restore:\n",
        "        nn_model.load_weights('./policies/' + args.scenario.lower() + '_' + args.goal.lower() + '_ILDIST')\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\n",
        "\n",
        "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(x, y):\n",
        "        ######### Your code starts here #########\n",
        "        # We want to perform a single training step (for one batch):\n",
        "        # 1. Make a forward pass through the model\n",
        "        # 2. Calculate the loss for the output of the forward pass\n",
        "        # 3. Based on the loss calculate the gradient for all weights\n",
        "        # 4. Run an optimization step on the weights.\n",
        "        # Helpful Functions: tf.GradientTape(), tf.GradientTape.gradient(), tf.keras.Optimizer.apply_gradients\n",
        "        with tf.GradientTape() as tape:\n",
        "            # forward pass\n",
        "            y_est = nn_model(x, training=True) # use dropout\n",
        "            # compute the loss\n",
        "            current_loss = loss(y_est, y)\n",
        "        grads = tape.gradient(current_loss, nn_model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, nn_model.trainable_variables))\n",
        "        ########## Your code ends here ##########\n",
        "\n",
        "        train_loss(current_loss)\n",
        "\n",
        "    @tf.function\n",
        "    def train(train_data):\n",
        "        for x, y in train_data:\n",
        "            train_step(x, y)\n",
        "\n",
        "\n",
        "    train_data = tf.data.Dataset.from_tensor_slices((data['x_train'], data['y_train'])).shuffle(100000).batch(params['train_batch_size'])\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        # Reset the metrics at the start of the next epoch\n",
        "        train_loss.reset_states()\n",
        "\n",
        "        train(train_data)\n",
        "\n",
        "        template = 'Epoch {}, Loss: {}'\n",
        "        print(template.format(epoch + 1, train_loss.result()))\n",
        "    nn_model.save_weights('./policies/' + args.scenario.lower() + '_' + args.goal.lower() + '_ILDIST')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23e6db4a",
      "metadata": {
        "id": "23e6db4a"
      },
      "source": [
        "# Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "33c1573e",
      "metadata": {
        "id": "33c1573e"
      },
      "outputs": [],
      "source": [
        "class MixtureDensityModelErrorFinal(tf.keras.losses.Loss):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(MixtureDensityModelErrorFinal, self).__init__()\n",
        "\n",
        "    def call(self, y_true, y_pred, sample_weight=None):\n",
        "        y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
        "        self.z_mu = y_pred[:, :2]\n",
        "        self.z_sigma = y_pred[:, 2:]\n",
        "        epsilon = 0.00001\n",
        "        # print(self.z_mu.shape)\n",
        "        # print(self.z_sigma.shape)\n",
        "        # B, N = self.z_sigma.shape\n",
        "        # self.z_sigma = tf.reshape(self.z_sigma, (B, int(N/2), int(N/2)))\n",
        "        # covariance = self.z_sigma @ tf.transpose(self.z_sigma, perm=[0, 2, 1])\n",
        "        scale_tril = tfp.math.fill_triangular(self.z_sigma) + epsilon\n",
        "        # sigma = tf.matmul(scale_tril, tf.transpose(scale_tril, perm=[0, 2, 1]))\n",
        "        # print(covariance.shape)\n",
        "        mvn = tfd.MultivariateNormalTriL(loc=self.z_mu, scale_tril=scale_tril, allow_nan_stats=False)\n",
        "        # E = tf.reduce_mean(tf.math.log(mvn.prob(y_true)), 0)\n",
        "        E = tf.reduce_mean(mvn.log_prob(y_true), 0)\n",
        "        return -1 * E\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "3edec096",
      "metadata": {
        "id": "3edec096"
      },
      "outputs": [],
      "source": [
        "def loss(y_est, y):\n",
        "    y = tf.cast(y, dtype=tf.float32)\n",
        "    ######### Your code starts here #########\n",
        "    # We want to compute the negative log-likelihood loss between y_est and y where\n",
        "    # - y_est is the output of the network for a batch of observations,\n",
        "    # - y is the actions the expert took for the corresponding batch of observations\n",
        "    # At the end your code should return the scalar loss value.\n",
        "    # HINT: You may find the classes of tensorflow_probability.distributions (imported as tfd) useful.\n",
        "    #       In particular, you can use MultivariateNormalFullCovariance or MultivariateNormalTriL, but they are not the only way.\n",
        "    # loss_object = MixtureDensityModelError(num_means=2, num_kernels=3)\n",
        "    loss_object = MixtureDensityModelErrorFinal()\n",
        "    sample_weights = tf.constant(([0.8, 0.2]))\n",
        "    y = y * sample_weights\n",
        "    y_est = y_est * tf.constant(([0.8, 0.2, 0.1, 0.1, 0.1]))\n",
        "    return loss_object(y, y_est)\n",
        "    \n",
        "    ########## Your code ends here ##########"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a6b1d42",
      "metadata": {
        "id": "1a6b1d42"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "9b7c8641",
      "metadata": {
        "id": "9b7c8641"
      },
      "outputs": [],
      "source": [
        "class NN(tf.keras.Model):\n",
        "    def __init__(self, in_size, out_size):\n",
        "        super(NN, self).__init__()\n",
        "        \n",
        "        ######### Your code starts here #########\n",
        "        # We want to define and initialize the weights & biases of the neural network.\n",
        "        # - in_size is dim(O)\n",
        "        # - out_size is dim(A) = 2\n",
        "        # IMPORTANT: out_size is still 2 in this case, because the action space is 2-dimensional. But your network will output some other size as it is outputing a distribution!\n",
        "        # HINT: You should use either of the following for weight initialization:\n",
        "        #         - tf.keras.initializers.GlorotUniform (this is what we tried)\n",
        "        #         - tf.keras.initializers.GlorotNormal\n",
        "        #         - tf.keras.initializers.he_uniform or tf.keras.initializers.he_normal\n",
        "        self.internal_layers = [\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(24, kernel_initializer=tf.keras.initializers.GlorotUniform(), activation='relu'),\n",
        "            # tf.keras.layers.Dropout(0.1),\n",
        "            tf.keras.layers.Dense(24, kernel_initializer=tf.keras.initializers.GlorotUniform(), activation='relu'),\n",
        "            # tf.keras.layers.Dropout(0.2),\n",
        "            # tf.keras.layers.Dense(12, kernel_initializer=tf.keras.initializers.GlorotUniform(), activation='relu'),\n",
        "        ]\n",
        "        # num_outputs = (out_size + 2) * 3 # Removed after using only 6 ouputs\n",
        "        num_outputs = out_size + 3\n",
        "        self.layer_output = tf.keras.layers.Dense(num_outputs, kernel_initializer=tf.keras.initializers.GlorotUniform(), activation='relu')\n",
        "        ########## Your code ends here ##########\n",
        "\n",
        "    def call(self, x):\n",
        "        x = tf.cast(x, dtype=tf.float32)\n",
        "        ######### Your code starts here #########\n",
        "        # We want to perform a forward-pass of the network. Using the weights and biases, this function should give the network output for x where:\n",
        "        # x is a (?, |O|) tensor that keeps a batch of observations\n",
        "        # IMPORTANT: First two columns of the output tensor must correspond to the mean vector!\n",
        "        for i in range(len(self.internal_layers)):\n",
        "            layer = self.internal_layers[i]\n",
        "            x = layer(x)\n",
        "        return self.layer_output(x)\n",
        "        ########## Your code ends here ##########"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f9de95d",
      "metadata": {
        "id": "2f9de95d"
      },
      "source": [
        "# Run Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "ceb1fdaf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceb1fdaf",
        "outputId": "5f0e13db-5f24-4dbb-87e5-a21c79186738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 18049488896.0\n",
            "Epoch 2, Loss: 17067469824.0\n",
            "Epoch 3, Loss: 16113245184.0\n",
            "Epoch 4, Loss: 15186887680.0\n",
            "Epoch 5, Loss: 14289098752.0\n",
            "Epoch 6, Loss: 13420339200.0\n",
            "Epoch 7, Loss: 12581186560.0\n",
            "Epoch 8, Loss: 11772089344.0\n",
            "Epoch 9, Loss: 10993446912.0\n",
            "Epoch 10, Loss: 10245453824.0\n",
            "Epoch 11, Loss: 9528471552.0\n",
            "Epoch 12, Loss: 8842355712.0\n",
            "Epoch 13, Loss: 8187282432.0\n",
            "Epoch 14, Loss: 7563163136.0\n",
            "Epoch 15, Loss: 6970341888.0\n",
            "Epoch 16, Loss: 6408321536.0\n",
            "Epoch 17, Loss: 5876839936.0\n",
            "Epoch 18, Loss: 5375636992.0\n",
            "Epoch 19, Loss: 4904287744.0\n",
            "Epoch 20, Loss: 4462344192.0\n",
            "Epoch 21, Loss: 4049302784.0\n",
            "Epoch 22, Loss: 3664460544.0\n",
            "Epoch 23, Loss: 3307495424.0\n",
            "Epoch 24, Loss: 2977121536.0\n",
            "Epoch 25, Loss: 2672657920.0\n",
            "Epoch 26, Loss: 2393214720.0\n",
            "Epoch 27, Loss: 2137858688.0\n",
            "Epoch 28, Loss: 1905530624.0\n",
            "Epoch 29, Loss: 1695210496.0\n",
            "Epoch 30, Loss: 1505738880.0\n",
            "Epoch 31, Loss: 1335827456.0\n",
            "Epoch 32, Loss: 1184016384.0\n",
            "Epoch 33, Loss: 1049014976.0\n",
            "Epoch 34, Loss: 929513024.0\n",
            "Epoch 35, Loss: 824196352.0\n",
            "Epoch 36, Loss: 731955392.0\n",
            "Epoch 37, Loss: 651602752.0\n",
            "Epoch 38, Loss: 582039424.0\n",
            "Epoch 39, Loss: 522152640.0\n",
            "Epoch 40, Loss: 471020480.0\n",
            "Epoch 41, Loss: 427723040.0\n",
            "Epoch 42, Loss: 391386592.0\n",
            "Epoch 43, Loss: 361262688.0\n",
            "Epoch 44, Loss: 336608736.0\n",
            "Epoch 45, Loss: 316699904.0\n",
            "Epoch 46, Loss: 300910560.0\n",
            "Epoch 47, Loss: 288647296.0\n",
            "Epoch 48, Loss: 279367584.0\n",
            "Epoch 49, Loss: 272572096.0\n",
            "Epoch 50, Loss: 267817664.0\n",
            "Epoch 51, Loss: 264741824.0\n",
            "Epoch 52, Loss: 263015584.0\n",
            "Epoch 53, Loss: 262328144.0\n",
            "Epoch 54, Loss: 262474576.0\n",
            "Epoch 55, Loss: 263210944.0\n",
            "Epoch 56, Loss: 264358736.0\n",
            "Epoch 57, Loss: 265759856.0\n",
            "Epoch 58, Loss: 267286224.0\n",
            "Epoch 59, Loss: 268837280.0\n",
            "Epoch 60, Loss: 270343328.0\n",
            "Epoch 61, Loss: 271736512.0\n",
            "Epoch 62, Loss: 272973088.0\n",
            "Epoch 63, Loss: 274019840.0\n",
            "Epoch 64, Loss: 274865152.0\n",
            "Epoch 65, Loss: 275502656.0\n",
            "Epoch 66, Loss: 275937056.0\n",
            "Epoch 67, Loss: 276180480.0\n",
            "Epoch 68, Loss: 276245248.0\n",
            "Epoch 69, Loss: 276141632.0\n",
            "Epoch 70, Loss: 275885536.0\n",
            "Epoch 71, Loss: 275489504.0\n",
            "Epoch 72, Loss: 274968128.0\n",
            "Epoch 73, Loss: 274332832.0\n",
            "Epoch 74, Loss: 273600128.0\n",
            "Epoch 75, Loss: 272782656.0\n",
            "Epoch 76, Loss: 271898560.0\n",
            "Epoch 77, Loss: 270965152.0\n",
            "Epoch 78, Loss: 269995808.0\n",
            "Epoch 79, Loss: 269007264.0\n",
            "Epoch 80, Loss: 268014448.0\n",
            "Epoch 81, Loss: 267032832.0\n",
            "Epoch 82, Loss: 266072592.0\n",
            "Epoch 83, Loss: 265146736.0\n",
            "Epoch 84, Loss: 264262848.0\n",
            "Epoch 85, Loss: 263422208.0\n",
            "Epoch 86, Loss: 262632816.0\n",
            "Epoch 87, Loss: 261893520.0\n",
            "Epoch 88, Loss: 261209472.0\n",
            "Epoch 89, Loss: 260598144.0\n",
            "Epoch 90, Loss: 260021040.0\n",
            "Epoch 91, Loss: 259496320.0\n",
            "Epoch 92, Loss: 259022512.0\n",
            "Epoch 93, Loss: 258595152.0\n",
            "Epoch 94, Loss: 258213456.0\n",
            "Epoch 95, Loss: 257871632.0\n",
            "Epoch 96, Loss: 257568016.0\n",
            "Epoch 97, Loss: 257297904.0\n",
            "Epoch 98, Loss: 257057904.0\n",
            "Epoch 99, Loss: 256843904.0\n",
            "Epoch 100, Loss: 256652752.0\n",
            "Epoch 101, Loss: 256481456.0\n",
            "Epoch 102, Loss: 256327360.0\n",
            "Epoch 103, Loss: 256186592.0\n",
            "Epoch 104, Loss: 256056032.0\n",
            "Epoch 105, Loss: 255933792.0\n",
            "Epoch 106, Loss: 255817888.0\n",
            "Epoch 107, Loss: 255706144.0\n",
            "Epoch 108, Loss: 255592752.0\n",
            "Epoch 109, Loss: 255485232.0\n",
            "Epoch 110, Loss: 255379024.0\n",
            "Epoch 111, Loss: 255272688.0\n",
            "Epoch 112, Loss: 255164896.0\n",
            "Epoch 113, Loss: 255055584.0\n",
            "Epoch 114, Loss: 254945584.0\n",
            "Epoch 115, Loss: 254833616.0\n",
            "Epoch 116, Loss: 254719632.0\n",
            "Epoch 117, Loss: 254604016.0\n",
            "Epoch 118, Loss: 254486656.0\n",
            "Epoch 119, Loss: 254351264.0\n",
            "Epoch 120, Loss: 254231392.0\n",
            "Epoch 121, Loss: 254110144.0\n",
            "Epoch 122, Loss: 253988640.0\n",
            "Epoch 123, Loss: 253866544.0\n",
            "Epoch 124, Loss: 253744880.0\n",
            "Epoch 125, Loss: 253622288.0\n",
            "Epoch 126, Loss: 253500800.0\n",
            "Epoch 127, Loss: 253380656.0\n",
            "Epoch 128, Loss: 253261600.0\n",
            "Epoch 129, Loss: 253143984.0\n",
            "Epoch 130, Loss: 253022800.0\n",
            "Epoch 131, Loss: 252902336.0\n",
            "Epoch 132, Loss: 252784352.0\n",
            "Epoch 133, Loss: 252668544.0\n",
            "Epoch 134, Loss: 252553664.0\n",
            "Epoch 135, Loss: 252442512.0\n",
            "Epoch 136, Loss: 252329856.0\n",
            "Epoch 137, Loss: 252218016.0\n",
            "Epoch 138, Loss: 252105792.0\n",
            "Epoch 139, Loss: 251994544.0\n",
            "Epoch 140, Loss: 251884144.0\n",
            "Epoch 141, Loss: 251776880.0\n",
            "Epoch 142, Loss: 251669360.0\n",
            "Epoch 143, Loss: 251562496.0\n",
            "Epoch 144, Loss: 251456368.0\n",
            "Epoch 145, Loss: 251350704.0\n",
            "Epoch 146, Loss: 251246656.0\n",
            "Epoch 147, Loss: 251142320.0\n",
            "Epoch 148, Loss: 251038560.0\n",
            "Epoch 149, Loss: 250935168.0\n",
            "Epoch 150, Loss: 250831840.0\n",
            "Epoch 151, Loss: 250729152.0\n",
            "Epoch 152, Loss: 250626432.0\n",
            "Epoch 153, Loss: 250524448.0\n",
            "Epoch 154, Loss: 250422672.0\n",
            "Epoch 155, Loss: 250321488.0\n",
            "Epoch 156, Loss: 250220640.0\n",
            "Epoch 157, Loss: 250119680.0\n",
            "Epoch 158, Loss: 250018144.0\n",
            "Epoch 159, Loss: 249918448.0\n",
            "Epoch 160, Loss: 249817984.0\n",
            "Epoch 161, Loss: 249718272.0\n",
            "Epoch 162, Loss: 249618992.0\n",
            "Epoch 163, Loss: 249519872.0\n",
            "Epoch 164, Loss: 249420880.0\n",
            "Epoch 165, Loss: 249322096.0\n",
            "Epoch 166, Loss: 249223728.0\n",
            "Epoch 167, Loss: 249125696.0\n",
            "Epoch 168, Loss: 249027808.0\n",
            "Epoch 169, Loss: 248930496.0\n",
            "Epoch 170, Loss: 248833184.0\n",
            "Epoch 171, Loss: 248735888.0\n",
            "Epoch 172, Loss: 248639056.0\n",
            "Epoch 173, Loss: 248542368.0\n",
            "Epoch 174, Loss: 248445632.0\n",
            "Epoch 175, Loss: 248349344.0\n",
            "Epoch 176, Loss: 248253072.0\n",
            "Epoch 177, Loss: 248157760.0\n",
            "Epoch 178, Loss: 248060672.0\n",
            "Epoch 179, Loss: 247964064.0\n",
            "Epoch 180, Loss: 247868528.0\n",
            "Epoch 181, Loss: 247773312.0\n",
            "Epoch 182, Loss: 247680080.0\n",
            "Epoch 183, Loss: 247586480.0\n",
            "Epoch 184, Loss: 247492224.0\n",
            "Epoch 185, Loss: 247396480.0\n",
            "Epoch 186, Loss: 247281168.0\n",
            "Epoch 187, Loss: 247187216.0\n",
            "Epoch 188, Loss: 247093840.0\n",
            "Epoch 189, Loss: 246999344.0\n",
            "Epoch 190, Loss: 246905536.0\n",
            "Epoch 191, Loss: 246795968.0\n",
            "Epoch 192, Loss: 246556400.0\n",
            "Epoch 193, Loss: 246371408.0\n",
            "Epoch 194, Loss: 246260592.0\n",
            "Epoch 195, Loss: 246149632.0\n",
            "Epoch 196, Loss: 246041616.0\n",
            "Epoch 197, Loss: 245936560.0\n",
            "Epoch 198, Loss: 245834656.0\n",
            "Epoch 199, Loss: 245732288.0\n",
            "Epoch 200, Loss: 245632496.0\n",
            "Epoch 201, Loss: 245531888.0\n",
            "Epoch 202, Loss: 245431824.0\n",
            "Epoch 203, Loss: 245332320.0\n",
            "Epoch 204, Loss: 245233264.0\n",
            "Epoch 205, Loss: 245134656.0\n",
            "Epoch 206, Loss: 245036512.0\n",
            "Epoch 207, Loss: 244938800.0\n",
            "Epoch 208, Loss: 244841472.0\n",
            "Epoch 209, Loss: 244744672.0\n",
            "Epoch 210, Loss: 244648448.0\n",
            "Epoch 211, Loss: 244552832.0\n",
            "Epoch 212, Loss: 244457792.0\n",
            "Epoch 213, Loss: 244363344.0\n",
            "Epoch 214, Loss: 244269472.0\n",
            "Epoch 215, Loss: 244176256.0\n",
            "Epoch 216, Loss: 244083568.0\n",
            "Epoch 217, Loss: 243991504.0\n",
            "Epoch 218, Loss: 243900032.0\n",
            "Epoch 219, Loss: 243809008.0\n",
            "Epoch 220, Loss: 243718416.0\n",
            "Epoch 221, Loss: 243628240.0\n",
            "Epoch 222, Loss: 243538544.0\n",
            "Epoch 223, Loss: 243449040.0\n",
            "Epoch 224, Loss: 243359888.0\n",
            "Epoch 225, Loss: 243271072.0\n",
            "Epoch 226, Loss: 243182496.0\n",
            "Epoch 227, Loss: 243094240.0\n",
            "Epoch 228, Loss: 243006176.0\n",
            "Epoch 229, Loss: 242918304.0\n",
            "Epoch 230, Loss: 242830576.0\n",
            "Epoch 231, Loss: 242743040.0\n",
            "Epoch 232, Loss: 242655632.0\n",
            "Epoch 233, Loss: 242568320.0\n",
            "Epoch 234, Loss: 242481088.0\n",
            "Epoch 235, Loss: 242394016.0\n",
            "Epoch 236, Loss: 242307008.0\n",
            "Epoch 237, Loss: 242220112.0\n",
            "Epoch 238, Loss: 242133360.0\n",
            "Epoch 239, Loss: 242046752.0\n",
            "Epoch 240, Loss: 241960224.0\n",
            "Epoch 241, Loss: 241873824.0\n",
            "Epoch 242, Loss: 241787552.0\n",
            "Epoch 243, Loss: 241701344.0\n",
            "Epoch 244, Loss: 241615232.0\n",
            "Epoch 245, Loss: 241529264.0\n",
            "Epoch 246, Loss: 241443392.0\n",
            "Epoch 247, Loss: 241357616.0\n",
            "Epoch 248, Loss: 241272016.0\n",
            "Epoch 249, Loss: 241186528.0\n",
            "Epoch 250, Loss: 241101136.0\n",
            "Epoch 251, Loss: 241015776.0\n",
            "Epoch 252, Loss: 240930592.0\n",
            "Epoch 253, Loss: 240845488.0\n",
            "Epoch 254, Loss: 240760496.0\n",
            "Epoch 255, Loss: 240675600.0\n",
            "Epoch 256, Loss: 240590848.0\n",
            "Epoch 257, Loss: 240506224.0\n",
            "Epoch 258, Loss: 240421696.0\n",
            "Epoch 259, Loss: 240337200.0\n",
            "Epoch 260, Loss: 240252864.0\n",
            "Epoch 261, Loss: 240168544.0\n",
            "Epoch 262, Loss: 240084352.0\n",
            "Epoch 263, Loss: 240000224.0\n",
            "Epoch 264, Loss: 239916256.0\n",
            "Epoch 265, Loss: 239832368.0\n",
            "Epoch 266, Loss: 239748576.0\n",
            "Epoch 267, Loss: 239664816.0\n",
            "Epoch 268, Loss: 239581216.0\n",
            "Epoch 269, Loss: 239497632.0\n",
            "Epoch 270, Loss: 239414160.0\n",
            "Epoch 271, Loss: 239330736.0\n",
            "Epoch 272, Loss: 239247456.0\n",
            "Epoch 273, Loss: 239164192.0\n",
            "Epoch 274, Loss: 239081088.0\n",
            "Epoch 275, Loss: 238998000.0\n",
            "Epoch 276, Loss: 238915040.0\n",
            "Epoch 277, Loss: 238832112.0\n",
            "Epoch 278, Loss: 238749344.0\n",
            "Epoch 279, Loss: 238666624.0\n",
            "Epoch 280, Loss: 238584016.0\n",
            "Epoch 281, Loss: 238501472.0\n",
            "Epoch 282, Loss: 238419024.0\n",
            "Epoch 283, Loss: 238336640.0\n",
            "Epoch 284, Loss: 238254352.0\n",
            "Epoch 285, Loss: 238172144.0\n",
            "Epoch 286, Loss: 238090048.0\n",
            "Epoch 287, Loss: 238008048.0\n",
            "Epoch 288, Loss: 237926192.0\n",
            "Epoch 289, Loss: 237844384.0\n",
            "Epoch 290, Loss: 237762656.0\n",
            "Epoch 291, Loss: 237680992.0\n",
            "Epoch 292, Loss: 237599520.0\n",
            "Epoch 293, Loss: 237518080.0\n",
            "Epoch 294, Loss: 237436752.0\n",
            "Epoch 295, Loss: 237355488.0\n",
            "Epoch 296, Loss: 237274304.0\n",
            "Epoch 297, Loss: 237193248.0\n",
            "Epoch 298, Loss: 237112304.0\n",
            "Epoch 299, Loss: 237031440.0\n",
            "Epoch 300, Loss: 236950688.0\n",
            "Epoch 301, Loss: 236870048.0\n",
            "Epoch 302, Loss: 236789440.0\n",
            "Epoch 303, Loss: 236708992.0\n",
            "Epoch 304, Loss: 236628624.0\n",
            "Epoch 305, Loss: 236548368.0\n",
            "Epoch 306, Loss: 236468176.0\n",
            "Epoch 307, Loss: 236388112.0\n",
            "Epoch 308, Loss: 236308160.0\n",
            "Epoch 309, Loss: 236228288.0\n",
            "Epoch 310, Loss: 236148544.0\n",
            "Epoch 311, Loss: 236068832.0\n",
            "Epoch 312, Loss: 235989280.0\n",
            "Epoch 313, Loss: 235909856.0\n",
            "Epoch 314, Loss: 235830512.0\n",
            "Epoch 315, Loss: 235751280.0\n",
            "Epoch 316, Loss: 235672128.0\n",
            "Epoch 317, Loss: 235593152.0\n",
            "Epoch 318, Loss: 235514256.0\n",
            "Epoch 319, Loss: 235435536.0\n",
            "Epoch 320, Loss: 235356880.0\n",
            "Epoch 321, Loss: 235278320.0\n",
            "Epoch 322, Loss: 235199872.0\n",
            "Epoch 323, Loss: 235121552.0\n",
            "Epoch 324, Loss: 235043376.0\n",
            "Epoch 325, Loss: 234965232.0\n",
            "Epoch 326, Loss: 234887232.0\n",
            "Epoch 327, Loss: 234809376.0\n",
            "Epoch 328, Loss: 234731552.0\n",
            "Epoch 329, Loss: 234653792.0\n",
            "Epoch 330, Loss: 234576160.0\n",
            "Epoch 331, Loss: 234498656.0\n",
            "Epoch 332, Loss: 234421264.0\n",
            "Epoch 333, Loss: 234343936.0\n",
            "Epoch 334, Loss: 234266720.0\n",
            "Epoch 335, Loss: 234189632.0\n",
            "Epoch 336, Loss: 234112592.0\n",
            "Epoch 337, Loss: 234035680.0\n",
            "Epoch 338, Loss: 233958912.0\n",
            "Epoch 339, Loss: 233882288.0\n",
            "Epoch 340, Loss: 233805744.0\n",
            "Epoch 341, Loss: 233729264.0\n",
            "Epoch 342, Loss: 233652960.0\n",
            "Epoch 343, Loss: 233576736.0\n",
            "Epoch 344, Loss: 233500576.0\n",
            "Epoch 345, Loss: 233424560.0\n",
            "Epoch 346, Loss: 233348704.0\n",
            "Epoch 347, Loss: 233272912.0\n",
            "Epoch 348, Loss: 233197280.0\n",
            "Epoch 349, Loss: 233121808.0\n",
            "Epoch 350, Loss: 233046384.0\n",
            "Epoch 351, Loss: 232971072.0\n",
            "Epoch 352, Loss: 232895824.0\n",
            "Epoch 353, Loss: 232820768.0\n",
            "Epoch 354, Loss: 232745824.0\n",
            "Epoch 355, Loss: 232670960.0\n",
            "Epoch 356, Loss: 232596176.0\n",
            "Epoch 357, Loss: 232521536.0\n",
            "Epoch 358, Loss: 232446976.0\n",
            "Epoch 359, Loss: 232372480.0\n",
            "Epoch 360, Loss: 232298160.0\n",
            "Epoch 361, Loss: 232223936.0\n",
            "Epoch 362, Loss: 232149760.0\n",
            "Epoch 363, Loss: 232075696.0\n",
            "Epoch 364, Loss: 232001728.0\n",
            "Epoch 365, Loss: 231927776.0\n",
            "Epoch 366, Loss: 231853968.0\n",
            "Epoch 367, Loss: 231780192.0\n",
            "Epoch 368, Loss: 231706560.0\n",
            "Epoch 369, Loss: 231632976.0\n",
            "Epoch 370, Loss: 231559536.0\n",
            "Epoch 371, Loss: 231486208.0\n",
            "Epoch 372, Loss: 231413024.0\n",
            "Epoch 373, Loss: 231339920.0\n",
            "Epoch 374, Loss: 231266912.0\n",
            "Epoch 375, Loss: 231194016.0\n",
            "Epoch 376, Loss: 231121200.0\n",
            "Epoch 377, Loss: 231048512.0\n",
            "Epoch 378, Loss: 230975904.0\n",
            "Epoch 379, Loss: 230903408.0\n",
            "Epoch 380, Loss: 230830992.0\n",
            "Epoch 381, Loss: 230758720.0\n",
            "Epoch 382, Loss: 230686512.0\n",
            "Epoch 383, Loss: 230614416.0\n",
            "Epoch 384, Loss: 230542400.0\n",
            "Epoch 385, Loss: 230470496.0\n",
            "Epoch 386, Loss: 230398640.0\n",
            "Epoch 387, Loss: 230326832.0\n",
            "Epoch 388, Loss: 230255152.0\n",
            "Epoch 389, Loss: 230183552.0\n",
            "Epoch 390, Loss: 230112032.0\n",
            "Epoch 391, Loss: 230040624.0\n",
            "Epoch 392, Loss: 229969312.0\n",
            "Epoch 393, Loss: 229898096.0\n",
            "Epoch 394, Loss: 229826976.0\n",
            "Epoch 395, Loss: 229755952.0\n",
            "Epoch 396, Loss: 229685040.0\n",
            "Epoch 397, Loss: 229614192.0\n",
            "Epoch 398, Loss: 229543408.0\n",
            "Epoch 399, Loss: 229472720.0\n",
            "Epoch 400, Loss: 229402096.0\n",
            "Epoch 401, Loss: 229331584.0\n",
            "Epoch 402, Loss: 229261184.0\n",
            "Epoch 403, Loss: 229190896.0\n",
            "Epoch 404, Loss: 229120672.0\n",
            "Epoch 405, Loss: 229050544.0\n",
            "Epoch 406, Loss: 228980576.0\n",
            "Epoch 407, Loss: 228910656.0\n",
            "Epoch 408, Loss: 228840864.0\n",
            "Epoch 409, Loss: 228771120.0\n",
            "Epoch 410, Loss: 228701488.0\n",
            "Epoch 411, Loss: 228631888.0\n",
            "Epoch 412, Loss: 228562384.0\n",
            "Epoch 413, Loss: 228492912.0\n",
            "Epoch 414, Loss: 228423504.0\n",
            "Epoch 415, Loss: 228354128.0\n",
            "Epoch 416, Loss: 228284864.0\n",
            "Epoch 417, Loss: 228215680.0\n",
            "Epoch 418, Loss: 228146576.0\n",
            "Epoch 419, Loss: 228077552.0\n",
            "Epoch 420, Loss: 228008608.0\n",
            "Epoch 421, Loss: 227939776.0\n",
            "Epoch 422, Loss: 227871024.0\n",
            "Epoch 423, Loss: 227802400.0\n",
            "Epoch 424, Loss: 227733840.0\n",
            "Epoch 425, Loss: 227665392.0\n",
            "Epoch 426, Loss: 227596992.0\n",
            "Epoch 427, Loss: 227528704.0\n",
            "Epoch 428, Loss: 227460512.0\n",
            "Epoch 429, Loss: 227392480.0\n",
            "Epoch 430, Loss: 227324480.0\n",
            "Epoch 431, Loss: 227256640.0\n",
            "Epoch 432, Loss: 227188848.0\n",
            "Epoch 433, Loss: 227121152.0\n",
            "Epoch 434, Loss: 227053520.0\n",
            "Epoch 435, Loss: 226986016.0\n",
            "Epoch 436, Loss: 226918560.0\n",
            "Epoch 437, Loss: 226851248.0\n",
            "Epoch 438, Loss: 226783936.0\n",
            "Epoch 439, Loss: 226716784.0\n",
            "Epoch 440, Loss: 226649632.0\n",
            "Epoch 441, Loss: 226582592.0\n",
            "Epoch 442, Loss: 226515584.0\n",
            "Epoch 443, Loss: 226448784.0\n",
            "Epoch 444, Loss: 226381968.0\n",
            "Epoch 445, Loss: 226315344.0\n",
            "Epoch 446, Loss: 226248736.0\n",
            "Epoch 447, Loss: 226182240.0\n",
            "Epoch 448, Loss: 226115776.0\n",
            "Epoch 449, Loss: 226049440.0\n",
            "Epoch 450, Loss: 225983152.0\n",
            "Epoch 451, Loss: 225916960.0\n",
            "Epoch 452, Loss: 225850768.0\n",
            "Epoch 453, Loss: 225784736.0\n",
            "Epoch 454, Loss: 225718720.0\n",
            "Epoch 455, Loss: 225652848.0\n",
            "Epoch 456, Loss: 225587024.0\n",
            "Epoch 457, Loss: 225521344.0\n",
            "Epoch 458, Loss: 225455728.0\n",
            "Epoch 459, Loss: 225390256.0\n",
            "Epoch 460, Loss: 225324832.0\n",
            "Epoch 461, Loss: 225259488.0\n",
            "Epoch 462, Loss: 225194192.0\n",
            "Epoch 463, Loss: 225129024.0\n",
            "Epoch 464, Loss: 225063936.0\n",
            "Epoch 465, Loss: 224998896.0\n",
            "Epoch 466, Loss: 224934032.0\n",
            "Epoch 467, Loss: 224869248.0\n",
            "Epoch 468, Loss: 224804496.0\n",
            "Epoch 469, Loss: 224739824.0\n",
            "Epoch 470, Loss: 224675248.0\n",
            "Epoch 471, Loss: 224610768.0\n",
            "Epoch 472, Loss: 224546336.0\n",
            "Epoch 473, Loss: 224481984.0\n",
            "Epoch 474, Loss: 224417712.0\n",
            "Epoch 475, Loss: 224353536.0\n",
            "Epoch 476, Loss: 224289376.0\n",
            "Epoch 477, Loss: 224225376.0\n",
            "Epoch 478, Loss: 224161456.0\n",
            "Epoch 479, Loss: 224097632.0\n",
            "Epoch 480, Loss: 224033888.0\n",
            "Epoch 481, Loss: 223970224.0\n",
            "Epoch 482, Loss: 223906608.0\n",
            "Epoch 483, Loss: 223843136.0\n",
            "Epoch 484, Loss: 223779728.0\n",
            "Epoch 485, Loss: 223716416.0\n",
            "Epoch 486, Loss: 223653168.0\n",
            "Epoch 487, Loss: 223590000.0\n",
            "Epoch 488, Loss: 223526928.0\n",
            "Epoch 489, Loss: 223463888.0\n",
            "Epoch 490, Loss: 223400960.0\n",
            "Epoch 491, Loss: 223338096.0\n",
            "Epoch 492, Loss: 223275280.0\n",
            "Epoch 493, Loss: 223212576.0\n",
            "Epoch 494, Loss: 223149904.0\n",
            "Epoch 495, Loss: 223087312.0\n",
            "Epoch 496, Loss: 223024752.0\n",
            "Epoch 497, Loss: 222962320.0\n",
            "Epoch 498, Loss: 222899888.0\n",
            "Epoch 499, Loss: 222837584.0\n",
            "Epoch 500, Loss: 222775376.0\n",
            "Epoch 501, Loss: 222713264.0\n",
            "Epoch 502, Loss: 222651184.0\n",
            "Epoch 503, Loss: 222589200.0\n",
            "Epoch 504, Loss: 222527232.0\n",
            "Epoch 505, Loss: 222465280.0\n",
            "Epoch 506, Loss: 222403392.0\n",
            "Epoch 507, Loss: 222341552.0\n",
            "Epoch 508, Loss: 222279776.0\n",
            "Epoch 509, Loss: 222218000.0\n",
            "Epoch 510, Loss: 222156288.0\n",
            "Epoch 511, Loss: 222094640.0\n",
            "Epoch 512, Loss: 222033024.0\n",
            "Epoch 513, Loss: 221971440.0\n",
            "Epoch 514, Loss: 221909936.0\n",
            "Epoch 515, Loss: 221848432.0\n",
            "Epoch 516, Loss: 221786960.0\n",
            "Epoch 517, Loss: 221725632.0\n",
            "Epoch 518, Loss: 221664336.0\n",
            "Epoch 519, Loss: 221603088.0\n",
            "Epoch 520, Loss: 221541872.0\n",
            "Epoch 521, Loss: 221480768.0\n",
            "Epoch 522, Loss: 221419712.0\n",
            "Epoch 523, Loss: 221358704.0\n",
            "Epoch 524, Loss: 221297840.0\n",
            "Epoch 525, Loss: 221236992.0\n",
            "Epoch 526, Loss: 221176256.0\n",
            "Epoch 527, Loss: 221115568.0\n",
            "Epoch 528, Loss: 221054976.0\n",
            "Epoch 529, Loss: 220994448.0\n",
            "Epoch 530, Loss: 220934016.0\n",
            "Epoch 531, Loss: 220873616.0\n",
            "Epoch 532, Loss: 220813216.0\n",
            "Epoch 533, Loss: 220752928.0\n",
            "Epoch 534, Loss: 220692640.0\n",
            "Epoch 535, Loss: 220632400.0\n",
            "Epoch 536, Loss: 220572224.0\n",
            "Epoch 537, Loss: 220512032.0\n",
            "Epoch 538, Loss: 220451936.0\n",
            "Epoch 539, Loss: 220391840.0\n",
            "Epoch 540, Loss: 220331856.0\n",
            "Epoch 541, Loss: 220271888.0\n",
            "Epoch 542, Loss: 220212016.0\n",
            "Epoch 543, Loss: 220152176.0\n",
            "Epoch 544, Loss: 220092336.0\n",
            "Epoch 545, Loss: 220032560.0\n",
            "Epoch 546, Loss: 219972880.0\n",
            "Epoch 547, Loss: 219913152.0\n",
            "Epoch 548, Loss: 219853488.0\n",
            "Epoch 549, Loss: 219793872.0\n",
            "Epoch 550, Loss: 219734320.0\n",
            "Epoch 551, Loss: 219674768.0\n",
            "Epoch 552, Loss: 219615280.0\n",
            "Epoch 553, Loss: 219555760.0\n",
            "Epoch 554, Loss: 219496336.0\n",
            "Epoch 555, Loss: 219436992.0\n",
            "Epoch 556, Loss: 219377712.0\n",
            "Epoch 557, Loss: 219318464.0\n",
            "Epoch 558, Loss: 219259232.0\n",
            "Epoch 559, Loss: 219200128.0\n",
            "Epoch 560, Loss: 219141008.0\n",
            "Epoch 561, Loss: 219081968.0\n",
            "Epoch 562, Loss: 219023024.0\n",
            "Epoch 563, Loss: 218964128.0\n",
            "Epoch 564, Loss: 218905312.0\n",
            "Epoch 565, Loss: 218846528.0\n",
            "Epoch 566, Loss: 218787824.0\n",
            "Epoch 567, Loss: 218729152.0\n",
            "Epoch 568, Loss: 218670544.0\n",
            "Epoch 569, Loss: 218612080.0\n",
            "Epoch 570, Loss: 218553584.0\n",
            "Epoch 571, Loss: 218495200.0\n",
            "Epoch 572, Loss: 218436848.0\n",
            "Epoch 573, Loss: 218378576.0\n",
            "Epoch 574, Loss: 218320304.0\n",
            "Epoch 575, Loss: 218262112.0\n",
            "Epoch 576, Loss: 218203984.0\n",
            "Epoch 577, Loss: 218145920.0\n",
            "Epoch 578, Loss: 218087904.0\n",
            "Epoch 579, Loss: 218029920.0\n",
            "Epoch 580, Loss: 217972000.0\n",
            "Epoch 581, Loss: 217914112.0\n",
            "Epoch 582, Loss: 217856224.0\n",
            "Epoch 583, Loss: 217798528.0\n",
            "Epoch 584, Loss: 217740864.0\n",
            "Epoch 585, Loss: 217683280.0\n",
            "Epoch 586, Loss: 217625696.0\n",
            "Epoch 587, Loss: 217568160.0\n",
            "Epoch 588, Loss: 217510688.0\n",
            "Epoch 589, Loss: 217453280.0\n",
            "Epoch 590, Loss: 217395952.0\n",
            "Epoch 591, Loss: 217338736.0\n",
            "Epoch 592, Loss: 217281488.0\n",
            "Epoch 593, Loss: 217224336.0\n",
            "Epoch 594, Loss: 217167168.0\n",
            "Epoch 595, Loss: 217110096.0\n",
            "Epoch 596, Loss: 217053088.0\n",
            "Epoch 597, Loss: 216996144.0\n",
            "Epoch 598, Loss: 216939248.0\n",
            "Epoch 599, Loss: 216882384.0\n",
            "Epoch 600, Loss: 216825600.0\n",
            "Epoch 601, Loss: 216768880.0\n",
            "Epoch 602, Loss: 216712160.0\n",
            "Epoch 603, Loss: 216655568.0\n",
            "Epoch 604, Loss: 216599008.0\n",
            "Epoch 605, Loss: 216542544.0\n",
            "Epoch 606, Loss: 216486176.0\n",
            "Epoch 607, Loss: 216429760.0\n",
            "Epoch 608, Loss: 216373520.0\n",
            "Epoch 609, Loss: 216317248.0\n",
            "Epoch 610, Loss: 216261136.0\n",
            "Epoch 611, Loss: 216205040.0\n",
            "Epoch 612, Loss: 216149056.0\n",
            "Epoch 613, Loss: 216093072.0\n",
            "Epoch 614, Loss: 216037184.0\n",
            "Epoch 615, Loss: 215981376.0\n",
            "Epoch 616, Loss: 215925536.0\n",
            "Epoch 617, Loss: 215869824.0\n",
            "Epoch 618, Loss: 215814128.0\n",
            "Epoch 619, Loss: 215758496.0\n",
            "Epoch 620, Loss: 215702848.0\n",
            "Epoch 621, Loss: 215647328.0\n",
            "Epoch 622, Loss: 215591792.0\n",
            "Epoch 623, Loss: 215536336.0\n",
            "Epoch 624, Loss: 215480864.0\n",
            "Epoch 625, Loss: 215425504.0\n",
            "Epoch 626, Loss: 215370176.0\n",
            "Epoch 627, Loss: 215314880.0\n",
            "Epoch 628, Loss: 215259632.0\n",
            "Epoch 629, Loss: 215204384.0\n",
            "Epoch 630, Loss: 215149264.0\n",
            "Epoch 631, Loss: 215094160.0\n",
            "Epoch 632, Loss: 215039072.0\n",
            "Epoch 633, Loss: 214984016.0\n",
            "Epoch 634, Loss: 214928976.0\n",
            "Epoch 635, Loss: 214873952.0\n",
            "Epoch 636, Loss: 214818960.0\n",
            "Epoch 637, Loss: 214764016.0\n",
            "Epoch 638, Loss: 214709088.0\n",
            "Epoch 639, Loss: 214654240.0\n",
            "Epoch 640, Loss: 214599408.0\n",
            "Epoch 641, Loss: 214544608.0\n",
            "Epoch 642, Loss: 214489920.0\n",
            "Epoch 643, Loss: 214435184.0\n",
            "Epoch 644, Loss: 214380512.0\n",
            "Epoch 645, Loss: 214325936.0\n",
            "Epoch 646, Loss: 214271376.0\n",
            "Epoch 647, Loss: 214216864.0\n",
            "Epoch 648, Loss: 214162416.0\n",
            "Epoch 649, Loss: 214107936.0\n",
            "Epoch 650, Loss: 214053584.0\n",
            "Epoch 651, Loss: 213999200.0\n",
            "Epoch 652, Loss: 213944832.0\n",
            "Epoch 653, Loss: 213890560.0\n",
            "Epoch 654, Loss: 213836320.0\n",
            "Epoch 655, Loss: 213782176.0\n",
            "Epoch 656, Loss: 213728032.0\n",
            "Epoch 657, Loss: 213673936.0\n",
            "Epoch 658, Loss: 213619904.0\n",
            "Epoch 659, Loss: 213565904.0\n",
            "Epoch 660, Loss: 213511936.0\n",
            "Epoch 661, Loss: 213458048.0\n",
            "Epoch 662, Loss: 213404176.0\n",
            "Epoch 663, Loss: 213350304.0\n",
            "Epoch 664, Loss: 213296416.0\n",
            "Epoch 665, Loss: 213242640.0\n",
            "Epoch 666, Loss: 213188864.0\n",
            "Epoch 667, Loss: 213135136.0\n",
            "Epoch 668, Loss: 213081520.0\n",
            "Epoch 669, Loss: 213027888.0\n",
            "Epoch 670, Loss: 212974320.0\n",
            "Epoch 671, Loss: 212920736.0\n",
            "Epoch 672, Loss: 212867264.0\n",
            "Epoch 673, Loss: 212813776.0\n",
            "Epoch 674, Loss: 212760368.0\n",
            "Epoch 675, Loss: 212707024.0\n",
            "Epoch 676, Loss: 212653712.0\n",
            "Epoch 677, Loss: 212600416.0\n",
            "Epoch 678, Loss: 212547200.0\n",
            "Epoch 679, Loss: 212494000.0\n",
            "Epoch 680, Loss: 212440848.0\n",
            "Epoch 681, Loss: 212387728.0\n",
            "Epoch 682, Loss: 212334640.0\n",
            "Epoch 683, Loss: 212281696.0\n",
            "Epoch 684, Loss: 212228752.0\n",
            "Epoch 685, Loss: 212175808.0\n",
            "Epoch 686, Loss: 212122944.0\n",
            "Epoch 687, Loss: 212070032.0\n",
            "Epoch 688, Loss: 212017088.0\n",
            "Epoch 689, Loss: 211964224.0\n",
            "Epoch 690, Loss: 211911328.0\n",
            "Epoch 691, Loss: 211858464.0\n",
            "Epoch 692, Loss: 211805648.0\n",
            "Epoch 693, Loss: 211752864.0\n",
            "Epoch 694, Loss: 211700144.0\n",
            "Epoch 695, Loss: 211647408.0\n",
            "Epoch 696, Loss: 211594688.0\n",
            "Epoch 697, Loss: 211542016.0\n",
            "Epoch 698, Loss: 211489376.0\n",
            "Epoch 699, Loss: 211436704.0\n",
            "Epoch 700, Loss: 211384144.0\n",
            "Epoch 701, Loss: 211331600.0\n",
            "Epoch 702, Loss: 211279104.0\n",
            "Epoch 703, Loss: 211226672.0\n",
            "Epoch 704, Loss: 211174304.0\n",
            "Epoch 705, Loss: 211121920.0\n",
            "Epoch 706, Loss: 211069568.0\n",
            "Epoch 707, Loss: 211017232.0\n",
            "Epoch 708, Loss: 210964816.0\n",
            "Epoch 709, Loss: 210912416.0\n",
            "Epoch 710, Loss: 210860000.0\n",
            "Epoch 711, Loss: 210807568.0\n",
            "Epoch 712, Loss: 210755184.0\n",
            "Epoch 713, Loss: 210702880.0\n",
            "Epoch 714, Loss: 210650496.0\n",
            "Epoch 715, Loss: 210598192.0\n",
            "Epoch 716, Loss: 210545968.0\n",
            "Epoch 717, Loss: 210493680.0\n",
            "Epoch 718, Loss: 210441392.0\n",
            "Epoch 719, Loss: 210389168.0\n",
            "Epoch 720, Loss: 210336864.0\n",
            "Epoch 721, Loss: 210284624.0\n",
            "Epoch 722, Loss: 210232464.0\n",
            "Epoch 723, Loss: 210180224.0\n",
            "Epoch 724, Loss: 210128112.0\n",
            "Epoch 725, Loss: 210075984.0\n",
            "Epoch 726, Loss: 210023824.0\n",
            "Epoch 727, Loss: 209971696.0\n",
            "Epoch 728, Loss: 209919504.0\n",
            "Epoch 729, Loss: 209867344.0\n",
            "Epoch 730, Loss: 209815168.0\n",
            "Epoch 731, Loss: 209763040.0\n",
            "Epoch 732, Loss: 209710912.0\n",
            "Epoch 733, Loss: 209658768.0\n",
            "Epoch 734, Loss: 209606608.0\n",
            "Epoch 735, Loss: 209554480.0\n",
            "Epoch 736, Loss: 209502288.0\n",
            "Epoch 737, Loss: 209450112.0\n",
            "Epoch 738, Loss: 209397872.0\n",
            "Epoch 739, Loss: 209345600.0\n",
            "Epoch 740, Loss: 209293264.0\n",
            "Epoch 741, Loss: 209240960.0\n",
            "Epoch 742, Loss: 209188528.0\n",
            "Epoch 743, Loss: 209136160.0\n",
            "Epoch 744, Loss: 209083760.0\n",
            "Epoch 745, Loss: 209031296.0\n",
            "Epoch 746, Loss: 208978880.0\n",
            "Epoch 747, Loss: 208926528.0\n",
            "Epoch 748, Loss: 208874128.0\n",
            "Epoch 749, Loss: 208821712.0\n",
            "Epoch 750, Loss: 208769232.0\n",
            "Epoch 751, Loss: 208716736.0\n",
            "Epoch 752, Loss: 208664192.0\n",
            "Epoch 753, Loss: 208611712.0\n",
            "Epoch 754, Loss: 208559232.0\n",
            "Epoch 755, Loss: 208506784.0\n",
            "Epoch 756, Loss: 208454352.0\n",
            "Epoch 757, Loss: 208401888.0\n",
            "Epoch 758, Loss: 208349360.0\n",
            "Epoch 759, Loss: 208296816.0\n",
            "Epoch 760, Loss: 208244320.0\n",
            "Epoch 761, Loss: 208191792.0\n",
            "Epoch 762, Loss: 208139328.0\n",
            "Epoch 763, Loss: 208086784.0\n",
            "Epoch 764, Loss: 208034256.0\n",
            "Epoch 765, Loss: 207981760.0\n",
            "Epoch 766, Loss: 207929200.0\n",
            "Epoch 767, Loss: 207876640.0\n",
            "Epoch 768, Loss: 207824144.0\n",
            "Epoch 769, Loss: 207771696.0\n",
            "Epoch 770, Loss: 207719152.0\n",
            "Epoch 771, Loss: 207666608.0\n",
            "Epoch 772, Loss: 207614064.0\n",
            "Epoch 773, Loss: 207561552.0\n",
            "Epoch 774, Loss: 207508976.0\n",
            "Epoch 775, Loss: 207456304.0\n",
            "Epoch 776, Loss: 207403632.0\n",
            "Epoch 777, Loss: 207350944.0\n",
            "Epoch 778, Loss: 207298176.0\n",
            "Epoch 779, Loss: 207245440.0\n",
            "Epoch 780, Loss: 207192784.0\n",
            "Epoch 781, Loss: 207140016.0\n",
            "Epoch 782, Loss: 207087168.0\n",
            "Epoch 783, Loss: 207034368.0\n",
            "Epoch 784, Loss: 206981456.0\n",
            "Epoch 785, Loss: 206928496.0\n",
            "Epoch 786, Loss: 206875568.0\n",
            "Epoch 787, Loss: 206822544.0\n",
            "Epoch 788, Loss: 206769328.0\n",
            "Epoch 789, Loss: 206716096.0\n",
            "Epoch 790, Loss: 206662736.0\n",
            "Epoch 791, Loss: 206609328.0\n",
            "Epoch 792, Loss: 206555872.0\n",
            "Epoch 793, Loss: 206502352.0\n",
            "Epoch 794, Loss: 206448784.0\n",
            "Epoch 795, Loss: 206395216.0\n",
            "Epoch 796, Loss: 206341568.0\n",
            "Epoch 797, Loss: 206287920.0\n",
            "Epoch 798, Loss: 206234256.0\n",
            "Epoch 799, Loss: 206180448.0\n",
            "Epoch 800, Loss: 206126624.0\n",
            "Epoch 801, Loss: 206072720.0\n",
            "Epoch 802, Loss: 206018512.0\n",
            "Epoch 803, Loss: 205964240.0\n",
            "Epoch 804, Loss: 205909984.0\n",
            "Epoch 805, Loss: 205855584.0\n",
            "Epoch 806, Loss: 205801008.0\n",
            "Epoch 807, Loss: 205746304.0\n",
            "Epoch 808, Loss: 205691456.0\n",
            "Epoch 809, Loss: 205636624.0\n",
            "Epoch 810, Loss: 205581648.0\n",
            "Epoch 811, Loss: 205526496.0\n",
            "Epoch 812, Loss: 205471152.0\n",
            "Epoch 813, Loss: 205415504.0\n",
            "Epoch 814, Loss: 205359584.0\n",
            "Epoch 815, Loss: 205303440.0\n",
            "Epoch 816, Loss: 205247104.0\n",
            "Epoch 817, Loss: 205190656.0\n",
            "Epoch 818, Loss: 205133872.0\n",
            "Epoch 819, Loss: 205076928.0\n",
            "Epoch 820, Loss: 205019808.0\n",
            "Epoch 821, Loss: 204962480.0\n",
            "Epoch 822, Loss: 204904896.0\n",
            "Epoch 823, Loss: 204847072.0\n",
            "Epoch 824, Loss: 204788976.0\n",
            "Epoch 825, Loss: 204730672.0\n",
            "Epoch 826, Loss: 204672240.0\n",
            "Epoch 827, Loss: 204613584.0\n",
            "Epoch 828, Loss: 204554608.0\n",
            "Epoch 829, Loss: 204495280.0\n",
            "Epoch 830, Loss: 204435808.0\n",
            "Epoch 831, Loss: 204376112.0\n",
            "Epoch 832, Loss: 204316144.0\n",
            "Epoch 833, Loss: 204255952.0\n",
            "Epoch 834, Loss: 204195456.0\n",
            "Epoch 835, Loss: 204134448.0\n",
            "Epoch 836, Loss: 204072896.0\n",
            "Epoch 837, Loss: 204011088.0\n",
            "Epoch 838, Loss: 203948880.0\n",
            "Epoch 839, Loss: 203886256.0\n",
            "Epoch 840, Loss: 203823168.0\n",
            "Epoch 841, Loss: 203759536.0\n",
            "Epoch 842, Loss: 203695536.0\n",
            "Epoch 843, Loss: 203631184.0\n",
            "Epoch 844, Loss: 203566176.0\n",
            "Epoch 845, Loss: 203500832.0\n",
            "Epoch 846, Loss: 203435056.0\n",
            "Epoch 847, Loss: 203369104.0\n",
            "Epoch 848, Loss: 203302720.0\n",
            "Epoch 849, Loss: 203235824.0\n",
            "Epoch 850, Loss: 203168592.0\n",
            "Epoch 851, Loss: 203100880.0\n",
            "Epoch 852, Loss: 203032752.0\n",
            "Epoch 853, Loss: 202964256.0\n",
            "Epoch 854, Loss: 202895456.0\n",
            "Epoch 855, Loss: 202826192.0\n",
            "Epoch 856, Loss: 202756384.0\n",
            "Epoch 857, Loss: 202686080.0\n",
            "Epoch 858, Loss: 202615344.0\n",
            "Epoch 859, Loss: 202543840.0\n",
            "Epoch 860, Loss: 202471680.0\n",
            "Epoch 861, Loss: 202399120.0\n",
            "Epoch 862, Loss: 202326096.0\n",
            "Epoch 863, Loss: 202252464.0\n",
            "Epoch 864, Loss: 202178224.0\n",
            "Epoch 865, Loss: 202103168.0\n",
            "Epoch 866, Loss: 202027392.0\n",
            "Epoch 867, Loss: 201951120.0\n",
            "Epoch 868, Loss: 201874512.0\n",
            "Epoch 869, Loss: 201797296.0\n",
            "Epoch 870, Loss: 201719488.0\n",
            "Epoch 871, Loss: 201641120.0\n",
            "Epoch 872, Loss: 201562160.0\n",
            "Epoch 873, Loss: 201482736.0\n",
            "Epoch 874, Loss: 201402976.0\n",
            "Epoch 875, Loss: 201322928.0\n",
            "Epoch 876, Loss: 201242448.0\n",
            "Epoch 877, Loss: 201161296.0\n",
            "Epoch 878, Loss: 201079616.0\n",
            "Epoch 879, Loss: 200996912.0\n",
            "Epoch 880, Loss: 200912288.0\n",
            "Epoch 881, Loss: 200827248.0\n",
            "Epoch 882, Loss: 200741376.0\n",
            "Epoch 883, Loss: 200655216.0\n",
            "Epoch 884, Loss: 200568544.0\n",
            "Epoch 885, Loss: 200481296.0\n",
            "Epoch 886, Loss: 200393408.0\n",
            "Epoch 887, Loss: 200305264.0\n",
            "Epoch 888, Loss: 200216928.0\n",
            "Epoch 889, Loss: 200127952.0\n",
            "Epoch 890, Loss: 200038560.0\n",
            "Epoch 891, Loss: 199948624.0\n",
            "Epoch 892, Loss: 199858128.0\n",
            "Epoch 893, Loss: 199767104.0\n",
            "Epoch 894, Loss: 199675424.0\n",
            "Epoch 895, Loss: 199583120.0\n",
            "Epoch 896, Loss: 199490448.0\n",
            "Epoch 897, Loss: 199397104.0\n",
            "Epoch 898, Loss: 199303728.0\n",
            "Epoch 899, Loss: 199209408.0\n",
            "Epoch 900, Loss: 199114272.0\n",
            "Epoch 901, Loss: 199018608.0\n",
            "Epoch 902, Loss: 198922208.0\n",
            "Epoch 903, Loss: 198825504.0\n",
            "Epoch 904, Loss: 198728064.0\n",
            "Epoch 905, Loss: 198630096.0\n",
            "Epoch 906, Loss: 198531392.0\n",
            "Epoch 907, Loss: 198432320.0\n",
            "Epoch 908, Loss: 198332528.0\n",
            "Epoch 909, Loss: 198231856.0\n",
            "Epoch 910, Loss: 198129952.0\n",
            "Epoch 911, Loss: 198027344.0\n",
            "Epoch 912, Loss: 197923808.0\n",
            "Epoch 913, Loss: 197819440.0\n",
            "Epoch 914, Loss: 197714016.0\n",
            "Epoch 915, Loss: 197607808.0\n",
            "Epoch 916, Loss: 197500688.0\n",
            "Epoch 917, Loss: 197392704.0\n",
            "Epoch 918, Loss: 197283856.0\n",
            "Epoch 919, Loss: 197174160.0\n",
            "Epoch 920, Loss: 197063536.0\n",
            "Epoch 921, Loss: 196952048.0\n",
            "Epoch 922, Loss: 196839552.0\n",
            "Epoch 923, Loss: 196725984.0\n",
            "Epoch 924, Loss: 196611552.0\n",
            "Epoch 925, Loss: 196496208.0\n",
            "Epoch 926, Loss: 196379488.0\n",
            "Epoch 927, Loss: 196261824.0\n",
            "Epoch 928, Loss: 196143072.0\n",
            "Epoch 929, Loss: 196023408.0\n",
            "Epoch 930, Loss: 195903216.0\n",
            "Epoch 931, Loss: 195781936.0\n",
            "Epoch 932, Loss: 195659696.0\n",
            "Epoch 933, Loss: 195536304.0\n",
            "Epoch 934, Loss: 195411696.0\n",
            "Epoch 935, Loss: 195285456.0\n",
            "Epoch 936, Loss: 195157936.0\n",
            "Epoch 937, Loss: 195029088.0\n",
            "Epoch 938, Loss: 194899232.0\n",
            "Epoch 939, Loss: 194767984.0\n",
            "Epoch 940, Loss: 194635552.0\n",
            "Epoch 941, Loss: 194502576.0\n",
            "Epoch 942, Loss: 194368464.0\n",
            "Epoch 943, Loss: 194233552.0\n",
            "Epoch 944, Loss: 194097920.0\n",
            "Epoch 945, Loss: 193961056.0\n",
            "Epoch 946, Loss: 193823120.0\n",
            "Epoch 947, Loss: 193683936.0\n",
            "Epoch 948, Loss: 193543440.0\n",
            "Epoch 949, Loss: 193401696.0\n",
            "Epoch 950, Loss: 193258944.0\n",
            "Epoch 951, Loss: 193114304.0\n",
            "Epoch 952, Loss: 192967040.0\n",
            "Epoch 953, Loss: 192817536.0\n",
            "Epoch 954, Loss: 192665504.0\n",
            "Epoch 955, Loss: 192510016.0\n",
            "Epoch 956, Loss: 192348832.0\n",
            "Epoch 957, Loss: 192181952.0\n",
            "Epoch 958, Loss: 192010432.0\n",
            "Epoch 959, Loss: 191834288.0\n",
            "Epoch 960, Loss: 191653776.0\n",
            "Epoch 961, Loss: 191469328.0\n",
            "Epoch 962, Loss: 191278976.0\n",
            "Epoch 963, Loss: 191083360.0\n",
            "Epoch 964, Loss: 190881968.0\n",
            "Epoch 965, Loss: 190674928.0\n",
            "Epoch 966, Loss: 190462640.0\n",
            "Epoch 967, Loss: 190245040.0\n",
            "Epoch 968, Loss: 190022160.0\n",
            "Epoch 969, Loss: 189792960.0\n",
            "Epoch 970, Loss: 189557376.0\n",
            "Epoch 971, Loss: 189316160.0\n",
            "Epoch 972, Loss: 189069760.0\n",
            "Epoch 973, Loss: 188818624.0\n",
            "Epoch 974, Loss: 188563440.0\n",
            "Epoch 975, Loss: 188301552.0\n",
            "Epoch 976, Loss: 188030640.0\n",
            "Epoch 977, Loss: 187748160.0\n",
            "Epoch 978, Loss: 187455392.0\n",
            "Epoch 979, Loss: 187149664.0\n",
            "Epoch 980, Loss: 186829024.0\n",
            "Epoch 981, Loss: 186491920.0\n",
            "Epoch 982, Loss: 186136224.0\n",
            "Epoch 983, Loss: 185764992.0\n",
            "Epoch 984, Loss: 185375792.0\n",
            "Epoch 985, Loss: 184970112.0\n",
            "Epoch 986, Loss: 184547552.0\n",
            "Epoch 987, Loss: 184102352.0\n",
            "Epoch 988, Loss: 183640496.0\n",
            "Epoch 989, Loss: 183168528.0\n",
            "Epoch 990, Loss: 182687840.0\n",
            "Epoch 991, Loss: 182198752.0\n",
            "Epoch 992, Loss: 181701568.0\n",
            "Epoch 993, Loss: 181201888.0\n",
            "Epoch 994, Loss: 180705184.0\n",
            "Epoch 995, Loss: 180220576.0\n",
            "Epoch 996, Loss: 179752720.0\n",
            "Epoch 997, Loss: 179303984.0\n",
            "Epoch 998, Loss: 178874368.0\n",
            "Epoch 999, Loss: 178461984.0\n",
            "Epoch 1000, Loss: 178069440.0\n",
            "Epoch 1001, Loss: 177695696.0\n",
            "Epoch 1002, Loss: 177339984.0\n",
            "Epoch 1003, Loss: 177001088.0\n",
            "Epoch 1004, Loss: 176678144.0\n",
            "Epoch 1005, Loss: 176371184.0\n",
            "Epoch 1006, Loss: 176080048.0\n",
            "Epoch 1007, Loss: 175803616.0\n",
            "Epoch 1008, Loss: 175540992.0\n",
            "Epoch 1009, Loss: 175291328.0\n",
            "Epoch 1010, Loss: 175053744.0\n",
            "Epoch 1011, Loss: 174826784.0\n",
            "Epoch 1012, Loss: 174609152.0\n",
            "Epoch 1013, Loss: 174399872.0\n",
            "Epoch 1014, Loss: 174197904.0\n",
            "Epoch 1015, Loss: 174002512.0\n",
            "Epoch 1016, Loss: 173812816.0\n",
            "Epoch 1017, Loss: 173627968.0\n",
            "Epoch 1018, Loss: 173447568.0\n",
            "Epoch 1019, Loss: 173271360.0\n",
            "Epoch 1020, Loss: 173098928.0\n",
            "Epoch 1021, Loss: 172929984.0\n",
            "Epoch 1022, Loss: 172764720.0\n",
            "Epoch 1023, Loss: 172602848.0\n",
            "Epoch 1024, Loss: 172444384.0\n",
            "Epoch 1025, Loss: 172289232.0\n",
            "Epoch 1026, Loss: 172137312.0\n",
            "Epoch 1027, Loss: 171988496.0\n",
            "Epoch 1028, Loss: 171842928.0\n",
            "Epoch 1029, Loss: 171700384.0\n",
            "Epoch 1030, Loss: 171560624.0\n",
            "Epoch 1031, Loss: 171423584.0\n",
            "Epoch 1032, Loss: 171289072.0\n",
            "Epoch 1033, Loss: 171157072.0\n",
            "Epoch 1034, Loss: 171027456.0\n",
            "Epoch 1035, Loss: 170900208.0\n",
            "Epoch 1036, Loss: 170775168.0\n",
            "Epoch 1037, Loss: 170652256.0\n",
            "Epoch 1038, Loss: 170531536.0\n",
            "Epoch 1039, Loss: 170412912.0\n",
            "Epoch 1040, Loss: 170296256.0\n",
            "Epoch 1041, Loss: 170181520.0\n",
            "Epoch 1042, Loss: 170068512.0\n",
            "Epoch 1043, Loss: 169957088.0\n",
            "Epoch 1044, Loss: 169847376.0\n",
            "Epoch 1045, Loss: 169739200.0\n",
            "Epoch 1046, Loss: 169632464.0\n",
            "Epoch 1047, Loss: 169527024.0\n",
            "Epoch 1048, Loss: 169422896.0\n",
            "Epoch 1049, Loss: 169319952.0\n",
            "Epoch 1050, Loss: 169218112.0\n",
            "Epoch 1051, Loss: 169117328.0\n",
            "Epoch 1052, Loss: 169017600.0\n",
            "Epoch 1053, Loss: 168918864.0\n",
            "Epoch 1054, Loss: 168821008.0\n",
            "Epoch 1055, Loss: 168724224.0\n",
            "Epoch 1056, Loss: 168628304.0\n",
            "Epoch 1057, Loss: 168533328.0\n",
            "Epoch 1058, Loss: 168439200.0\n",
            "Epoch 1059, Loss: 168345904.0\n",
            "Epoch 1060, Loss: 168253424.0\n",
            "Epoch 1061, Loss: 168161744.0\n",
            "Epoch 1062, Loss: 168070864.0\n",
            "Epoch 1063, Loss: 167980784.0\n",
            "Epoch 1064, Loss: 167891440.0\n",
            "Epoch 1065, Loss: 167802832.0\n",
            "Epoch 1066, Loss: 167714928.0\n",
            "Epoch 1067, Loss: 167627632.0\n",
            "Epoch 1068, Loss: 167541104.0\n",
            "Epoch 1069, Loss: 167455072.0\n",
            "Epoch 1070, Loss: 167369760.0\n",
            "Epoch 1071, Loss: 167284992.0\n",
            "Epoch 1072, Loss: 167200896.0\n",
            "Epoch 1073, Loss: 167117328.0\n",
            "Epoch 1074, Loss: 167034384.0\n",
            "Epoch 1075, Loss: 166951920.0\n",
            "Epoch 1076, Loss: 166870048.0\n",
            "Epoch 1077, Loss: 166788688.0\n",
            "Epoch 1078, Loss: 166707856.0\n",
            "Epoch 1079, Loss: 166627488.0\n",
            "Epoch 1080, Loss: 166547712.0\n",
            "Epoch 1081, Loss: 166468368.0\n",
            "Epoch 1082, Loss: 166389456.0\n",
            "Epoch 1083, Loss: 166311072.0\n",
            "Epoch 1084, Loss: 166233104.0\n",
            "Epoch 1085, Loss: 166155536.0\n",
            "Epoch 1086, Loss: 166078512.0\n",
            "Epoch 1087, Loss: 166001808.0\n",
            "Epoch 1088, Loss: 165925488.0\n",
            "Epoch 1089, Loss: 165849648.0\n",
            "Epoch 1090, Loss: 165774176.0\n",
            "Epoch 1091, Loss: 165699104.0\n",
            "Epoch 1092, Loss: 165624384.0\n",
            "Epoch 1093, Loss: 165550064.0\n",
            "Epoch 1094, Loss: 165476176.0\n",
            "Epoch 1095, Loss: 165402720.0\n",
            "Epoch 1096, Loss: 165329504.0\n",
            "Epoch 1097, Loss: 165256736.0\n",
            "Epoch 1098, Loss: 165184336.0\n",
            "Epoch 1099, Loss: 165112256.0\n",
            "Epoch 1100, Loss: 165040512.0\n",
            "Epoch 1101, Loss: 164969088.0\n",
            "Epoch 1102, Loss: 164898048.0\n",
            "Epoch 1103, Loss: 164827328.0\n",
            "Epoch 1104, Loss: 164756944.0\n",
            "Epoch 1105, Loss: 164686928.0\n",
            "Epoch 1106, Loss: 164617200.0\n",
            "Epoch 1107, Loss: 164547840.0\n",
            "Epoch 1108, Loss: 164478768.0\n",
            "Epoch 1109, Loss: 164409952.0\n",
            "Epoch 1110, Loss: 164341552.0\n",
            "Epoch 1111, Loss: 164273408.0\n",
            "Epoch 1112, Loss: 164205552.0\n",
            "Epoch 1113, Loss: 164138080.0\n",
            "Epoch 1114, Loss: 164070800.0\n",
            "Epoch 1115, Loss: 164003824.0\n",
            "Epoch 1116, Loss: 163937152.0\n",
            "Epoch 1117, Loss: 163870752.0\n",
            "Epoch 1118, Loss: 163804592.0\n",
            "Epoch 1119, Loss: 163738768.0\n",
            "Epoch 1120, Loss: 163673280.0\n",
            "Epoch 1121, Loss: 163608000.0\n",
            "Epoch 1122, Loss: 163543024.0\n",
            "Epoch 1123, Loss: 163478272.0\n",
            "Epoch 1124, Loss: 163413856.0\n",
            "Epoch 1125, Loss: 163349584.0\n",
            "Epoch 1126, Loss: 163285616.0\n",
            "Epoch 1127, Loss: 163221920.0\n",
            "Epoch 1128, Loss: 163158480.0\n",
            "Epoch 1129, Loss: 163095232.0\n",
            "Epoch 1130, Loss: 163032272.0\n",
            "Epoch 1131, Loss: 162969568.0\n",
            "Epoch 1132, Loss: 162907072.0\n",
            "Epoch 1133, Loss: 162844896.0\n",
            "Epoch 1134, Loss: 162782896.0\n",
            "Epoch 1135, Loss: 162721136.0\n",
            "Epoch 1136, Loss: 162659584.0\n",
            "Epoch 1137, Loss: 162598304.0\n",
            "Epoch 1138, Loss: 162537232.0\n",
            "Epoch 1139, Loss: 162476400.0\n",
            "Epoch 1140, Loss: 162415744.0\n",
            "Epoch 1141, Loss: 162355312.0\n",
            "Epoch 1142, Loss: 162295056.0\n",
            "Epoch 1143, Loss: 162235072.0\n",
            "Epoch 1144, Loss: 162175264.0\n",
            "Epoch 1145, Loss: 162115696.0\n",
            "Epoch 1146, Loss: 162056368.0\n",
            "Epoch 1147, Loss: 161997200.0\n",
            "Epoch 1148, Loss: 161938256.0\n",
            "Epoch 1149, Loss: 161879568.0\n",
            "Epoch 1150, Loss: 161821040.0\n",
            "Epoch 1151, Loss: 161762704.0\n",
            "Epoch 1152, Loss: 161704592.0\n",
            "Epoch 1153, Loss: 161646688.0\n",
            "Epoch 1154, Loss: 161588992.0\n",
            "Epoch 1155, Loss: 161531456.0\n",
            "Epoch 1156, Loss: 161474160.0\n",
            "Epoch 1157, Loss: 161417040.0\n",
            "Epoch 1158, Loss: 161360144.0\n",
            "Epoch 1159, Loss: 161303424.0\n",
            "Epoch 1160, Loss: 161246896.0\n",
            "Epoch 1161, Loss: 161190528.0\n",
            "Epoch 1162, Loss: 161134352.0\n",
            "Epoch 1163, Loss: 161078336.0\n",
            "Epoch 1164, Loss: 161022496.0\n",
            "Epoch 1165, Loss: 160966832.0\n",
            "Epoch 1166, Loss: 160911328.0\n",
            "Epoch 1167, Loss: 160856000.0\n",
            "Epoch 1168, Loss: 160800816.0\n",
            "Epoch 1169, Loss: 160745824.0\n",
            "Epoch 1170, Loss: 160691008.0\n",
            "Epoch 1171, Loss: 160636368.0\n",
            "Epoch 1172, Loss: 160581936.0\n",
            "Epoch 1173, Loss: 160527648.0\n",
            "Epoch 1174, Loss: 160473520.0\n",
            "Epoch 1175, Loss: 160419600.0\n",
            "Epoch 1176, Loss: 160365888.0\n",
            "Epoch 1177, Loss: 160312336.0\n",
            "Epoch 1178, Loss: 160258944.0\n",
            "Epoch 1179, Loss: 160205728.0\n",
            "Epoch 1180, Loss: 160152736.0\n",
            "Epoch 1181, Loss: 160099856.0\n",
            "Epoch 1182, Loss: 160047216.0\n",
            "Epoch 1183, Loss: 159994736.0\n",
            "Epoch 1184, Loss: 159942432.0\n",
            "Epoch 1185, Loss: 159890304.0\n",
            "Epoch 1186, Loss: 159838368.0\n",
            "Epoch 1187, Loss: 159786576.0\n",
            "Epoch 1188, Loss: 159734912.0\n",
            "Epoch 1189, Loss: 159683456.0\n",
            "Epoch 1190, Loss: 159632112.0\n",
            "Epoch 1191, Loss: 159580912.0\n",
            "Epoch 1192, Loss: 159529904.0\n",
            "Epoch 1193, Loss: 159478976.0\n",
            "Epoch 1194, Loss: 159428256.0\n",
            "Epoch 1195, Loss: 159377696.0\n",
            "Epoch 1196, Loss: 159327248.0\n",
            "Epoch 1197, Loss: 159277008.0\n",
            "Epoch 1198, Loss: 159226832.0\n",
            "Epoch 1199, Loss: 159176864.0\n",
            "Epoch 1200, Loss: 159127024.0\n",
            "Epoch 1201, Loss: 159077360.0\n",
            "Epoch 1202, Loss: 159027840.0\n",
            "Epoch 1203, Loss: 158978496.0\n",
            "Epoch 1204, Loss: 158929328.0\n",
            "Epoch 1205, Loss: 158880320.0\n",
            "Epoch 1206, Loss: 158831440.0\n",
            "Epoch 1207, Loss: 158782688.0\n",
            "Epoch 1208, Loss: 158734080.0\n",
            "Epoch 1209, Loss: 158685632.0\n",
            "Epoch 1210, Loss: 158637312.0\n",
            "Epoch 1211, Loss: 158589152.0\n",
            "Epoch 1212, Loss: 158541152.0\n",
            "Epoch 1213, Loss: 158493264.0\n",
            "Epoch 1214, Loss: 158445568.0\n",
            "Epoch 1215, Loss: 158398064.0\n",
            "Epoch 1216, Loss: 158350656.0\n",
            "Epoch 1217, Loss: 158303456.0\n",
            "Epoch 1218, Loss: 158256384.0\n",
            "Epoch 1219, Loss: 158209472.0\n",
            "Epoch 1220, Loss: 158162752.0\n",
            "Epoch 1221, Loss: 158116176.0\n",
            "Epoch 1222, Loss: 158069712.0\n",
            "Epoch 1223, Loss: 158023408.0\n",
            "Epoch 1224, Loss: 157977248.0\n",
            "Epoch 1225, Loss: 157931232.0\n",
            "Epoch 1226, Loss: 157885360.0\n",
            "Epoch 1227, Loss: 157839616.0\n",
            "Epoch 1228, Loss: 157794048.0\n",
            "Epoch 1229, Loss: 157748560.0\n",
            "Epoch 1230, Loss: 157703296.0\n",
            "Epoch 1231, Loss: 157658128.0\n",
            "Epoch 1232, Loss: 157613088.0\n",
            "Epoch 1233, Loss: 157568224.0\n",
            "Epoch 1234, Loss: 157523520.0\n",
            "Epoch 1235, Loss: 157478992.0\n",
            "Epoch 1236, Loss: 157434416.0\n",
            "Epoch 1237, Loss: 157379296.0\n",
            "Epoch 1238, Loss: 157334976.0\n",
            "Epoch 1239, Loss: 157272416.0\n",
            "Epoch 1240, Loss: 157227648.0\n",
            "Epoch 1241, Loss: 157164800.0\n",
            "Epoch 1242, Loss: 157114000.0\n",
            "Epoch 1243, Loss: 157068560.0\n",
            "Epoch 1244, Loss: 157007232.0\n",
            "Epoch 1245, Loss: 156954320.0\n",
            "Epoch 1246, Loss: 156881360.0\n",
            "Epoch 1247, Loss: 156829136.0\n",
            "Epoch 1248, Loss: 156763936.0\n",
            "Epoch 1249, Loss: 156703808.0\n",
            "Epoch 1250, Loss: 156643520.0\n",
            "Epoch 1251, Loss: 156582336.0\n",
            "Epoch 1252, Loss: 156504976.0\n",
            "Epoch 1253, Loss: 156438304.0\n",
            "Epoch 1254, Loss: 156378192.0\n",
            "Epoch 1255, Loss: 156321184.0\n",
            "Epoch 1256, Loss: 156239232.0\n",
            "Epoch 1257, Loss: 156131456.0\n",
            "Epoch 1258, Loss: 156055888.0\n",
            "Epoch 1259, Loss: 155958416.0\n",
            "Epoch 1260, Loss: 155850864.0\n",
            "Epoch 1261, Loss: 155742048.0\n",
            "Epoch 1262, Loss: 155643840.0\n",
            "Epoch 1263, Loss: 155514992.0\n",
            "Epoch 1264, Loss: 155400176.0\n",
            "Epoch 1265, Loss: 155262736.0\n",
            "Epoch 1266, Loss: 155071984.0\n",
            "Epoch 1267, Loss: 154944384.0\n",
            "Epoch 1268, Loss: 154799792.0\n",
            "Epoch 1269, Loss: 154669120.0\n",
            "Epoch 1270, Loss: 154539600.0\n",
            "Epoch 1271, Loss: 154352832.0\n",
            "Epoch 1272, Loss: 154161696.0\n",
            "Epoch 1273, Loss: 153987280.0\n",
            "Epoch 1274, Loss: 153793040.0\n",
            "Epoch 1275, Loss: 153630656.0\n",
            "Epoch 1276, Loss: 153454944.0\n",
            "Epoch 1277, Loss: 153231488.0\n",
            "Epoch 1278, Loss: 153046112.0\n",
            "Epoch 1279, Loss: 152791504.0\n",
            "Epoch 1280, Loss: 152616784.0\n",
            "Epoch 1281, Loss: 152377312.0\n",
            "Epoch 1282, Loss: 152156528.0\n",
            "Epoch 1283, Loss: 151913024.0\n",
            "Epoch 1284, Loss: 151706352.0\n",
            "Epoch 1285, Loss: 151466960.0\n",
            "Epoch 1286, Loss: 151307072.0\n",
            "Epoch 1287, Loss: 151133520.0\n",
            "Epoch 1288, Loss: 150926048.0\n",
            "Epoch 1289, Loss: 150764384.0\n",
            "Epoch 1290, Loss: 150603104.0\n",
            "Epoch 1291, Loss: 150404528.0\n",
            "Epoch 1292, Loss: 150242560.0\n",
            "Epoch 1293, Loss: 150098896.0\n",
            "Epoch 1294, Loss: 149983632.0\n",
            "Epoch 1295, Loss: 149838992.0\n",
            "Epoch 1296, Loss: 149660304.0\n",
            "Epoch 1297, Loss: 149470848.0\n",
            "Epoch 1298, Loss: 149352608.0\n",
            "Epoch 1299, Loss: 149246016.0\n",
            "Epoch 1300, Loss: 149052464.0\n",
            "Epoch 1301, Loss: 148933712.0\n",
            "Epoch 1302, Loss: 148808816.0\n",
            "Epoch 1303, Loss: 148721408.0\n",
            "Epoch 1304, Loss: 148569472.0\n",
            "Epoch 1305, Loss: 148488704.0\n",
            "Epoch 1306, Loss: 148381168.0\n",
            "Epoch 1307, Loss: 148300384.0\n",
            "Epoch 1308, Loss: 148213920.0\n",
            "Epoch 1309, Loss: 148125664.0\n",
            "Epoch 1310, Loss: 148045120.0\n",
            "Epoch 1311, Loss: 147978432.0\n",
            "Epoch 1312, Loss: 147726240.0\n",
            "Epoch 1313, Loss: 147447808.0\n",
            "Epoch 1314, Loss: 147196064.0\n",
            "Epoch 1315, Loss: 147025680.0\n",
            "Epoch 1316, Loss: 146827632.0\n",
            "Epoch 1317, Loss: 146621776.0\n",
            "Epoch 1318, Loss: 146443936.0\n",
            "Epoch 1319, Loss: 146257792.0\n",
            "Epoch 1320, Loss: 145843696.0\n",
            "Epoch 1321, Loss: 145547440.0\n",
            "Epoch 1322, Loss: 145196400.0\n",
            "Epoch 1323, Loss: 144897824.0\n",
            "Epoch 1324, Loss: 144626768.0\n",
            "Epoch 1325, Loss: 144333008.0\n",
            "Epoch 1326, Loss: 144102272.0\n",
            "Epoch 1327, Loss: 143912112.0\n",
            "Epoch 1328, Loss: 143674592.0\n",
            "Epoch 1329, Loss: 143292400.0\n",
            "Epoch 1330, Loss: 142829824.0\n",
            "Epoch 1331, Loss: 142431024.0\n",
            "Epoch 1332, Loss: 142062784.0\n",
            "Epoch 1333, Loss: 141719552.0\n",
            "Epoch 1334, Loss: 141284000.0\n",
            "Epoch 1335, Loss: 140656656.0\n",
            "Epoch 1336, Loss: 140175728.0\n",
            "Epoch 1337, Loss: 139657504.0\n",
            "Epoch 1338, Loss: 139164816.0\n",
            "Epoch 1339, Loss: 138759904.0\n",
            "Epoch 1340, Loss: 138393904.0\n",
            "Epoch 1341, Loss: 138082112.0\n",
            "Epoch 1342, Loss: 137767488.0\n",
            "Epoch 1343, Loss: 137467328.0\n",
            "Epoch 1344, Loss: 137181440.0\n",
            "Epoch 1345, Loss: 136956432.0\n",
            "Epoch 1346, Loss: 136679184.0\n",
            "Epoch 1347, Loss: 136466016.0\n",
            "Epoch 1348, Loss: 136258016.0\n",
            "Epoch 1349, Loss: 136033616.0\n",
            "Epoch 1350, Loss: 135820720.0\n",
            "Epoch 1351, Loss: 135546080.0\n",
            "Epoch 1352, Loss: 135326880.0\n",
            "Epoch 1353, Loss: 135120640.0\n",
            "Epoch 1354, Loss: 134891840.0\n",
            "Epoch 1355, Loss: 134676496.0\n",
            "Epoch 1356, Loss: 134518720.0\n",
            "Epoch 1357, Loss: 134349136.0\n",
            "Epoch 1358, Loss: 134196792.0\n",
            "Epoch 1359, Loss: 134030760.0\n",
            "Epoch 1360, Loss: 133924768.0\n",
            "Epoch 1361, Loss: 133774264.0\n",
            "Epoch 1362, Loss: 133633288.0\n",
            "Epoch 1363, Loss: 133529680.0\n",
            "Epoch 1364, Loss: 133376008.0\n",
            "Epoch 1365, Loss: 133213296.0\n",
            "Epoch 1366, Loss: 133102800.0\n",
            "Epoch 1367, Loss: 132990824.0\n",
            "Epoch 1368, Loss: 132898392.0\n",
            "Epoch 1369, Loss: 132737312.0\n",
            "Epoch 1370, Loss: 132626776.0\n",
            "Epoch 1371, Loss: 132503840.0\n",
            "Epoch 1372, Loss: 132282784.0\n",
            "Epoch 1373, Loss: 132057408.0\n",
            "Epoch 1374, Loss: 131884584.0\n",
            "Epoch 1375, Loss: 131662640.0\n",
            "Epoch 1376, Loss: 131457824.0\n",
            "Epoch 1377, Loss: 131319864.0\n",
            "Epoch 1378, Loss: 131183976.0\n",
            "Epoch 1379, Loss: 131093592.0\n",
            "Epoch 1380, Loss: 130741768.0\n",
            "Epoch 1381, Loss: 130429544.0\n",
            "Epoch 1382, Loss: 130123336.0\n",
            "Epoch 1383, Loss: 129917736.0\n",
            "Epoch 1384, Loss: 129721488.0\n",
            "Epoch 1385, Loss: 129492968.0\n",
            "Epoch 1386, Loss: 129269344.0\n",
            "Epoch 1387, Loss: 129108200.0\n",
            "Epoch 1388, Loss: 128927384.0\n",
            "Epoch 1389, Loss: 128795368.0\n",
            "Epoch 1390, Loss: 128582560.0\n",
            "Epoch 1391, Loss: 128462496.0\n",
            "Epoch 1392, Loss: 128202456.0\n",
            "Epoch 1393, Loss: 128036192.0\n",
            "Epoch 1394, Loss: 127831216.0\n",
            "Epoch 1395, Loss: 127657824.0\n",
            "Epoch 1396, Loss: 127512792.0\n",
            "Epoch 1397, Loss: 127320808.0\n",
            "Epoch 1398, Loss: 127124184.0\n",
            "Epoch 1399, Loss: 126972696.0\n",
            "Epoch 1400, Loss: 126791672.0\n",
            "Epoch 1401, Loss: 126635776.0\n",
            "Epoch 1402, Loss: 126483096.0\n",
            "Epoch 1403, Loss: 126353952.0\n",
            "Epoch 1404, Loss: 126206408.0\n",
            "Epoch 1405, Loss: 126073320.0\n",
            "Epoch 1406, Loss: 125923336.0\n",
            "Epoch 1407, Loss: 125811816.0\n",
            "Epoch 1408, Loss: 125732152.0\n",
            "Epoch 1409, Loss: 125600776.0\n",
            "Epoch 1410, Loss: 125464968.0\n",
            "Epoch 1411, Loss: 125360256.0\n",
            "Epoch 1412, Loss: 125204072.0\n",
            "Epoch 1413, Loss: 125121080.0\n",
            "Epoch 1414, Loss: 125042864.0\n",
            "Epoch 1415, Loss: 124964976.0\n",
            "Epoch 1416, Loss: 124892912.0\n",
            "Epoch 1417, Loss: 124808608.0\n",
            "Epoch 1418, Loss: 124747816.0\n",
            "Epoch 1419, Loss: 124694280.0\n",
            "Epoch 1420, Loss: 124634312.0\n",
            "Epoch 1421, Loss: 124533872.0\n",
            "Epoch 1422, Loss: 124036944.0\n",
            "Epoch 1423, Loss: 123575640.0\n",
            "Epoch 1424, Loss: 123156760.0\n",
            "Epoch 1425, Loss: 122832272.0\n",
            "Epoch 1426, Loss: 122434456.0\n",
            "Epoch 1427, Loss: 122130032.0\n",
            "Epoch 1428, Loss: 121890040.0\n",
            "Epoch 1429, Loss: 121661648.0\n",
            "Epoch 1430, Loss: 121429312.0\n",
            "Epoch 1431, Loss: 121277064.0\n",
            "Epoch 1432, Loss: 121095304.0\n",
            "Epoch 1433, Loss: 120925632.0\n",
            "Epoch 1434, Loss: 120766408.0\n",
            "Epoch 1435, Loss: 120592360.0\n",
            "Epoch 1436, Loss: 120472136.0\n",
            "Epoch 1437, Loss: 120343544.0\n",
            "Epoch 1438, Loss: 120244448.0\n",
            "Epoch 1439, Loss: 120130928.0\n",
            "Epoch 1440, Loss: 120045288.0\n",
            "Epoch 1441, Loss: 119938752.0\n",
            "Epoch 1442, Loss: 119871728.0\n",
            "Epoch 1443, Loss: 119780864.0\n",
            "Epoch 1444, Loss: 119737400.0\n",
            "Epoch 1445, Loss: 119679728.0\n",
            "Epoch 1446, Loss: 119599632.0\n",
            "Epoch 1447, Loss: 119473896.0\n",
            "Epoch 1448, Loss: 119377336.0\n",
            "Epoch 1449, Loss: 119278400.0\n",
            "Epoch 1450, Loss: 119202296.0\n",
            "Epoch 1451, Loss: 119109552.0\n",
            "Epoch 1452, Loss: 118996552.0\n",
            "Epoch 1453, Loss: 118895992.0\n",
            "Epoch 1454, Loss: 118789776.0\n",
            "Epoch 1455, Loss: 118666936.0\n",
            "Epoch 1456, Loss: 118585176.0\n",
            "Epoch 1457, Loss: 118509424.0\n",
            "Epoch 1458, Loss: 118424544.0\n",
            "Epoch 1459, Loss: 118348128.0\n",
            "Epoch 1460, Loss: 118258416.0\n",
            "Epoch 1461, Loss: 118021464.0\n",
            "Epoch 1462, Loss: 117805080.0\n",
            "Epoch 1463, Loss: 117570160.0\n",
            "Epoch 1464, Loss: 117415296.0\n",
            "Epoch 1465, Loss: 117239816.0\n",
            "Epoch 1466, Loss: 117045952.0\n",
            "Epoch 1467, Loss: 116945888.0\n",
            "Epoch 1468, Loss: 116837512.0\n",
            "Epoch 1469, Loss: 116702176.0\n",
            "Epoch 1470, Loss: 116590440.0\n",
            "Epoch 1471, Loss: 116514792.0\n",
            "Epoch 1472, Loss: 116394200.0\n",
            "Epoch 1473, Loss: 116180256.0\n",
            "Epoch 1474, Loss: 116108768.0\n",
            "Epoch 1475, Loss: 116041368.0\n",
            "Epoch 1476, Loss: 115991120.0\n",
            "Epoch 1477, Loss: 115892776.0\n",
            "Epoch 1478, Loss: 115803360.0\n",
            "Epoch 1479, Loss: 115751536.0\n",
            "Epoch 1480, Loss: 115682784.0\n",
            "Epoch 1481, Loss: 115628976.0\n",
            "Epoch 1482, Loss: 115559416.0\n",
            "Epoch 1483, Loss: 115506168.0\n",
            "Epoch 1484, Loss: 115465928.0\n",
            "Epoch 1485, Loss: 115415744.0\n",
            "Epoch 1486, Loss: 115353840.0\n",
            "Epoch 1487, Loss: 115281720.0\n",
            "Epoch 1488, Loss: 115245016.0\n",
            "Epoch 1489, Loss: 115218336.0\n",
            "Epoch 1490, Loss: 115185864.0\n",
            "Epoch 1491, Loss: 115154472.0\n",
            "Epoch 1492, Loss: 115123488.0\n",
            "Epoch 1493, Loss: 115089184.0\n",
            "Epoch 1494, Loss: 115054176.0\n",
            "Epoch 1495, Loss: 115025728.0\n",
            "Epoch 1496, Loss: 114999192.0\n",
            "Epoch 1497, Loss: 114976000.0\n",
            "Epoch 1498, Loss: 114955192.0\n",
            "Epoch 1499, Loss: 114933792.0\n",
            "Epoch 1500, Loss: 114905920.0\n",
            "Epoch 1501, Loss: 114875136.0\n",
            "Epoch 1502, Loss: 114840512.0\n",
            "Epoch 1503, Loss: 114819200.0\n",
            "Epoch 1504, Loss: 114796080.0\n",
            "Epoch 1505, Loss: 114776064.0\n",
            "Epoch 1506, Loss: 114754768.0\n",
            "Epoch 1507, Loss: 114734904.0\n",
            "Epoch 1508, Loss: 114714744.0\n",
            "Epoch 1509, Loss: 114686496.0\n",
            "Epoch 1510, Loss: 114653680.0\n",
            "Epoch 1511, Loss: 114628968.0\n",
            "Epoch 1512, Loss: 114609640.0\n",
            "Epoch 1513, Loss: 114589760.0\n",
            "Epoch 1514, Loss: 114570968.0\n",
            "Epoch 1515, Loss: 114552248.0\n",
            "Epoch 1516, Loss: 114522920.0\n",
            "Epoch 1517, Loss: 114502984.0\n",
            "Epoch 1518, Loss: 114484072.0\n",
            "Epoch 1519, Loss: 114465048.0\n",
            "Epoch 1520, Loss: 114446648.0\n",
            "Epoch 1521, Loss: 114428328.0\n",
            "Epoch 1522, Loss: 114410432.0\n",
            "Epoch 1523, Loss: 114392784.0\n",
            "Epoch 1524, Loss: 114375208.0\n",
            "Epoch 1525, Loss: 114357704.0\n",
            "Epoch 1526, Loss: 114340336.0\n",
            "Epoch 1527, Loss: 114323192.0\n",
            "Epoch 1528, Loss: 114306496.0\n",
            "Epoch 1529, Loss: 114289440.0\n",
            "Epoch 1530, Loss: 114272648.0\n",
            "Epoch 1531, Loss: 114256016.0\n",
            "Epoch 1532, Loss: 114239512.0\n",
            "Epoch 1533, Loss: 114223104.0\n",
            "Epoch 1534, Loss: 114206856.0\n",
            "Epoch 1535, Loss: 114190536.0\n",
            "Epoch 1536, Loss: 114168176.0\n",
            "Epoch 1537, Loss: 114151512.0\n",
            "Epoch 1538, Loss: 114135312.0\n",
            "Epoch 1539, Loss: 114113392.0\n",
            "Epoch 1540, Loss: 114088096.0\n",
            "Epoch 1541, Loss: 114069384.0\n",
            "Epoch 1542, Loss: 114054080.0\n",
            "Epoch 1543, Loss: 114029616.0\n",
            "Epoch 1544, Loss: 114012792.0\n",
            "Epoch 1545, Loss: 113997072.0\n",
            "Epoch 1546, Loss: 113982200.0\n",
            "Epoch 1547, Loss: 113967216.0\n",
            "Epoch 1548, Loss: 113951440.0\n",
            "Epoch 1549, Loss: 113931864.0\n",
            "Epoch 1550, Loss: 113917264.0\n",
            "Epoch 1551, Loss: 113902520.0\n",
            "Epoch 1552, Loss: 113877872.0\n",
            "Epoch 1553, Loss: 113863088.0\n",
            "Epoch 1554, Loss: 113813936.0\n",
            "Epoch 1555, Loss: 113799200.0\n",
            "Epoch 1556, Loss: 113785016.0\n",
            "Epoch 1557, Loss: 113770368.0\n",
            "Epoch 1558, Loss: 113755488.0\n",
            "Epoch 1559, Loss: 113741904.0\n",
            "Epoch 1560, Loss: 113723992.0\n",
            "Epoch 1561, Loss: 113704728.0\n",
            "Epoch 1562, Loss: 113684496.0\n",
            "Epoch 1563, Loss: 113660728.0\n",
            "Epoch 1564, Loss: 113639760.0\n",
            "Epoch 1565, Loss: 113609944.0\n",
            "Epoch 1566, Loss: 113595328.0\n",
            "Epoch 1567, Loss: 113581792.0\n",
            "Epoch 1568, Loss: 113563560.0\n",
            "Epoch 1569, Loss: 113549296.0\n",
            "Epoch 1570, Loss: 113535256.0\n",
            "Epoch 1571, Loss: 113514168.0\n",
            "Epoch 1572, Loss: 113500416.0\n",
            "Epoch 1573, Loss: 113487304.0\n",
            "Epoch 1574, Loss: 113471520.0\n",
            "Epoch 1575, Loss: 113456472.0\n",
            "Epoch 1576, Loss: 113428912.0\n",
            "Epoch 1577, Loss: 113409624.0\n",
            "Epoch 1578, Loss: 113367168.0\n",
            "Epoch 1579, Loss: 113319088.0\n",
            "Epoch 1580, Loss: 113287816.0\n",
            "Epoch 1581, Loss: 113249376.0\n",
            "Epoch 1582, Loss: 113218648.0\n",
            "Epoch 1583, Loss: 113181416.0\n",
            "Epoch 1584, Loss: 113152608.0\n",
            "Epoch 1585, Loss: 113106816.0\n",
            "Epoch 1586, Loss: 113075808.0\n",
            "Epoch 1587, Loss: 113052520.0\n",
            "Epoch 1588, Loss: 113008176.0\n",
            "Epoch 1589, Loss: 112987520.0\n",
            "Epoch 1590, Loss: 112971472.0\n",
            "Epoch 1591, Loss: 112952104.0\n",
            "Epoch 1592, Loss: 112911832.0\n",
            "Epoch 1593, Loss: 112896840.0\n",
            "Epoch 1594, Loss: 112879680.0\n",
            "Epoch 1595, Loss: 112862488.0\n",
            "Epoch 1596, Loss: 112833464.0\n",
            "Epoch 1597, Loss: 112761160.0\n",
            "Epoch 1598, Loss: 112613904.0\n",
            "Epoch 1599, Loss: 112482456.0\n",
            "Epoch 1600, Loss: 112424912.0\n",
            "Epoch 1601, Loss: 112314232.0\n",
            "Epoch 1602, Loss: 112226080.0\n",
            "Epoch 1603, Loss: 112150736.0\n",
            "Epoch 1604, Loss: 112047200.0\n",
            "Epoch 1605, Loss: 111964008.0\n",
            "Epoch 1606, Loss: 111886128.0\n",
            "Epoch 1607, Loss: 111785920.0\n",
            "Epoch 1608, Loss: 111700512.0\n",
            "Epoch 1609, Loss: 111622080.0\n",
            "Epoch 1610, Loss: 111522752.0\n",
            "Epoch 1611, Loss: 111415640.0\n",
            "Epoch 1612, Loss: 111305752.0\n",
            "Epoch 1613, Loss: 111172536.0\n",
            "Epoch 1614, Loss: 111017024.0\n",
            "Epoch 1615, Loss: 110484888.0\n",
            "Epoch 1616, Loss: 109889016.0\n",
            "Epoch 1617, Loss: 109033816.0\n",
            "Epoch 1618, Loss: 107918048.0\n",
            "Epoch 1619, Loss: 106497464.0\n",
            "Epoch 1620, Loss: 104418968.0\n",
            "Epoch 1621, Loss: 99597632.0\n",
            "Epoch 1622, Loss: 93630456.0\n",
            "Epoch 1623, Loss: 84384328.0\n",
            "Epoch 1624, Loss: 75056240.0\n",
            "Epoch 1625, Loss: 67205056.0\n",
            "Epoch 1626, Loss: 58769828.0\n",
            "Epoch 1627, Loss: 51548252.0\n",
            "Epoch 1628, Loss: 45171328.0\n",
            "Epoch 1629, Loss: 40317860.0\n",
            "Epoch 1630, Loss: 36614232.0\n",
            "Epoch 1631, Loss: 32094990.0\n",
            "Epoch 1632, Loss: 28647918.0\n",
            "Epoch 1633, Loss: 25884814.0\n",
            "Epoch 1634, Loss: 23693856.0\n",
            "Epoch 1635, Loss: 21783750.0\n",
            "Epoch 1636, Loss: 20074184.0\n",
            "Epoch 1637, Loss: 18321762.0\n",
            "Epoch 1638, Loss: 16887232.0\n",
            "Epoch 1639, Loss: 15778732.0\n",
            "Epoch 1640, Loss: 14780224.0\n",
            "Epoch 1641, Loss: 13990488.0\n",
            "Epoch 1642, Loss: 13283797.0\n",
            "Epoch 1643, Loss: 12639639.0\n",
            "Epoch 1644, Loss: 12063566.0\n",
            "Epoch 1645, Loss: 11569571.0\n",
            "Epoch 1646, Loss: 11088229.0\n",
            "Epoch 1647, Loss: 10649242.0\n",
            "Epoch 1648, Loss: 10153857.0\n",
            "Epoch 1649, Loss: 9826953.0\n",
            "Epoch 1650, Loss: 9549340.0\n",
            "Epoch 1651, Loss: 9280972.0\n",
            "Epoch 1652, Loss: 9051601.0\n",
            "Epoch 1653, Loss: 8887238.0\n",
            "Epoch 1654, Loss: 8748336.0\n",
            "Epoch 1655, Loss: 8536869.0\n",
            "Epoch 1656, Loss: 8393359.0\n",
            "Epoch 1657, Loss: 8279266.0\n",
            "Epoch 1658, Loss: 8156929.0\n",
            "Epoch 1659, Loss: 8018685.0\n",
            "Epoch 1660, Loss: 7893110.0\n",
            "Epoch 1661, Loss: 7799043.5\n",
            "Epoch 1662, Loss: 7709197.5\n",
            "Epoch 1663, Loss: 7651141.5\n",
            "Epoch 1664, Loss: 7583768.0\n",
            "Epoch 1665, Loss: 7508590.0\n",
            "Epoch 1666, Loss: 7474406.5\n",
            "Epoch 1667, Loss: 7411987.0\n",
            "Epoch 1668, Loss: 7358637.5\n",
            "Epoch 1669, Loss: 7317285.0\n",
            "Epoch 1670, Loss: 7290394.5\n",
            "Epoch 1671, Loss: 7270559.5\n",
            "Epoch 1672, Loss: 7199402.0\n",
            "Epoch 1673, Loss: 7132358.0\n",
            "Epoch 1674, Loss: 7081576.5\n",
            "Epoch 1675, Loss: 7009335.0\n",
            "Epoch 1676, Loss: 6900784.0\n",
            "Epoch 1677, Loss: 6838428.5\n",
            "Epoch 1678, Loss: 6757592.5\n",
            "Epoch 1679, Loss: 6666325.5\n",
            "Epoch 1680, Loss: 6607000.5\n",
            "Epoch 1681, Loss: 6536433.5\n",
            "Epoch 1682, Loss: 6454079.0\n",
            "Epoch 1683, Loss: 6421297.5\n",
            "Epoch 1684, Loss: 6376166.0\n",
            "Epoch 1685, Loss: 6278153.5\n",
            "Epoch 1686, Loss: 6229245.5\n",
            "Epoch 1687, Loss: 6177440.0\n",
            "Epoch 1688, Loss: 6102982.0\n",
            "Epoch 1689, Loss: 6037371.5\n",
            "Epoch 1690, Loss: 5953933.5\n",
            "Epoch 1691, Loss: 5888312.5\n",
            "Epoch 1692, Loss: 5831301.0\n",
            "Epoch 1693, Loss: 5740384.0\n",
            "Epoch 1694, Loss: 5679931.5\n",
            "Epoch 1695, Loss: 5576079.0\n",
            "Epoch 1696, Loss: 5496869.0\n",
            "Epoch 1697, Loss: 5430415.0\n",
            "Epoch 1698, Loss: 5377029.0\n",
            "Epoch 1699, Loss: 5346937.5\n",
            "Epoch 1700, Loss: 5251863.0\n",
            "Epoch 1701, Loss: 5156419.0\n",
            "Epoch 1702, Loss: 5110068.0\n",
            "Epoch 1703, Loss: 5054483.5\n",
            "Epoch 1704, Loss: 4991585.5\n",
            "Epoch 1705, Loss: 4886686.5\n",
            "Epoch 1706, Loss: 4741689.0\n",
            "Epoch 1707, Loss: 4634054.0\n",
            "Epoch 1708, Loss: 4539312.5\n",
            "Epoch 1709, Loss: 4461527.5\n",
            "Epoch 1710, Loss: 4394505.5\n",
            "Epoch 1711, Loss: 4337571.5\n",
            "Epoch 1712, Loss: 4225543.5\n",
            "Epoch 1713, Loss: 4153479.25\n",
            "Epoch 1714, Loss: 4060264.5\n",
            "Epoch 1715, Loss: 3969550.5\n",
            "Epoch 1716, Loss: 3914490.5\n",
            "Epoch 1717, Loss: 3859999.5\n",
            "Epoch 1718, Loss: 3811963.0\n",
            "Epoch 1719, Loss: 3774578.75\n",
            "Epoch 1720, Loss: 3734382.5\n",
            "Epoch 1721, Loss: 3686914.0\n",
            "Epoch 1722, Loss: 3637916.75\n",
            "Epoch 1723, Loss: 3615588.5\n",
            "Epoch 1724, Loss: 3571912.75\n",
            "Epoch 1725, Loss: 3537202.25\n",
            "Epoch 1726, Loss: 3501847.0\n",
            "Epoch 1727, Loss: 3474920.75\n",
            "Epoch 1728, Loss: 3445584.5\n",
            "Epoch 1729, Loss: 3419253.25\n",
            "Epoch 1730, Loss: 3405968.5\n",
            "Epoch 1731, Loss: 3380137.75\n",
            "Epoch 1732, Loss: 3339480.25\n",
            "Epoch 1733, Loss: 3318214.0\n",
            "Epoch 1734, Loss: 3294308.75\n",
            "Epoch 1735, Loss: 3281720.75\n",
            "Epoch 1736, Loss: 3267436.0\n",
            "Epoch 1737, Loss: 3244687.5\n",
            "Epoch 1738, Loss: 3241039.5\n",
            "Epoch 1739, Loss: 3228086.0\n",
            "Epoch 1740, Loss: 3218916.75\n",
            "Epoch 1741, Loss: 3206929.5\n",
            "Epoch 1742, Loss: 3185700.25\n",
            "Epoch 1743, Loss: 3177162.25\n",
            "Epoch 1744, Loss: 3159054.25\n",
            "Epoch 1745, Loss: 3140520.75\n",
            "Epoch 1746, Loss: 3133267.5\n",
            "Epoch 1747, Loss: 3130815.0\n",
            "Epoch 1748, Loss: 3122575.25\n",
            "Epoch 1749, Loss: 3111009.75\n",
            "Epoch 1750, Loss: 3104887.0\n",
            "Epoch 1751, Loss: 3104060.0\n",
            "Epoch 1752, Loss: 3102210.0\n",
            "Epoch 1753, Loss: 3096436.5\n",
            "Epoch 1754, Loss: 3090495.75\n",
            "Epoch 1755, Loss: 3083423.25\n",
            "Epoch 1756, Loss: 3076394.75\n",
            "Epoch 1757, Loss: 3064699.75\n",
            "Epoch 1758, Loss: 3055648.75\n",
            "Epoch 1759, Loss: 3053503.0\n",
            "Epoch 1760, Loss: 3042059.5\n",
            "Epoch 1761, Loss: 3010228.25\n",
            "Epoch 1762, Loss: 2975516.0\n",
            "Epoch 1763, Loss: 2957266.75\n",
            "Epoch 1764, Loss: 2936805.0\n",
            "Epoch 1765, Loss: 2913487.25\n",
            "Epoch 1766, Loss: 2896131.0\n",
            "Epoch 1767, Loss: 2880129.0\n",
            "Epoch 1768, Loss: 2848347.0\n",
            "Epoch 1769, Loss: 2825755.5\n",
            "Epoch 1770, Loss: 2792214.25\n",
            "Epoch 1771, Loss: 2785361.5\n",
            "Epoch 1772, Loss: 2769857.25\n",
            "Epoch 1773, Loss: 2740526.75\n",
            "Epoch 1774, Loss: 2664168.5\n",
            "Epoch 1775, Loss: 2599189.5\n",
            "Epoch 1776, Loss: 2528651.25\n",
            "Epoch 1777, Loss: 2445968.25\n",
            "Epoch 1778, Loss: 2390714.0\n",
            "Epoch 1779, Loss: 2299880.25\n",
            "Epoch 1780, Loss: 2208142.5\n",
            "Epoch 1781, Loss: 2099603.0\n",
            "Epoch 1782, Loss: 2021732.75\n",
            "Epoch 1783, Loss: 1958249.625\n",
            "Epoch 1784, Loss: 1910826.25\n",
            "Epoch 1785, Loss: 1880493.25\n",
            "Epoch 1786, Loss: 1808758.125\n",
            "Epoch 1787, Loss: 1721392.75\n",
            "Epoch 1788, Loss: 1657703.0\n",
            "Epoch 1789, Loss: 1613746.75\n",
            "Epoch 1790, Loss: 1574703.625\n",
            "Epoch 1791, Loss: 1537496.875\n",
            "Epoch 1792, Loss: 1366742.0\n",
            "Epoch 1793, Loss: 1202917.5\n",
            "Epoch 1794, Loss: 1034858.25\n",
            "Epoch 1795, Loss: 937103.3125\n",
            "Epoch 1796, Loss: 777236.6875\n",
            "Epoch 1797, Loss: 626167.375\n",
            "Epoch 1798, Loss: 509669.96875\n",
            "Epoch 1799, Loss: 414357.375\n",
            "Epoch 1800, Loss: 325500.8125\n",
            "Epoch 1801, Loss: 295122.90625\n",
            "Epoch 1802, Loss: 245838.234375\n",
            "Epoch 1803, Loss: 218223.859375\n",
            "Epoch 1804, Loss: 203265.109375\n",
            "Epoch 1805, Loss: 190575.046875\n",
            "Epoch 1806, Loss: 179907.0625\n",
            "Epoch 1807, Loss: 170109.890625\n",
            "Epoch 1808, Loss: 153357.375\n",
            "Epoch 1809, Loss: 142519.0625\n",
            "Epoch 1810, Loss: 132711.140625\n",
            "Epoch 1811, Loss: 97954.8984375\n",
            "Epoch 1812, Loss: 89330.2265625\n",
            "Epoch 1813, Loss: 83991.2421875\n",
            "Epoch 1814, Loss: 73936.359375\n",
            "Epoch 1815, Loss: 71992.9921875\n",
            "Epoch 1816, Loss: 61709.1953125\n",
            "Epoch 1817, Loss: 55811.90625\n",
            "Epoch 1818, Loss: 52512.90234375\n",
            "Epoch 1819, Loss: 49556.6484375\n",
            "Epoch 1820, Loss: 49425.01171875\n",
            "Epoch 1821, Loss: 49304.73046875\n",
            "Epoch 1822, Loss: 44201.375\n",
            "Epoch 1823, Loss: 39804.51171875\n",
            "Epoch 1824, Loss: 39687.06640625\n",
            "Epoch 1825, Loss: 37773.87109375\n",
            "Epoch 1826, Loss: 35472.10546875\n",
            "Epoch 1827, Loss: 35405.46875\n",
            "Epoch 1828, Loss: 35351.51171875\n",
            "Epoch 1829, Loss: 35301.984375\n",
            "Epoch 1830, Loss: 32141.564453125\n",
            "Epoch 1831, Loss: 28310.5859375\n",
            "Epoch 1832, Loss: 28252.0859375\n",
            "Epoch 1833, Loss: 28215.421875\n",
            "Epoch 1834, Loss: 28183.89453125\n",
            "Epoch 1835, Loss: 28155.20703125\n",
            "Epoch 1836, Loss: 28128.365234375\n",
            "Epoch 1837, Loss: 28103.271484375\n",
            "Epoch 1838, Loss: 28079.5078125\n",
            "Epoch 1839, Loss: 28056.970703125\n",
            "Epoch 1840, Loss: 28035.609375\n",
            "Epoch 1841, Loss: 28015.24609375\n",
            "Epoch 1842, Loss: 27995.55859375\n",
            "Epoch 1843, Loss: 27976.78125\n",
            "Epoch 1844, Loss: 27958.697265625\n",
            "Epoch 1845, Loss: 27941.189453125\n",
            "Epoch 1846, Loss: 27924.228515625\n",
            "Epoch 1847, Loss: 27907.64453125\n",
            "Epoch 1848, Loss: 27891.634765625\n",
            "Epoch 1849, Loss: 27876.115234375\n",
            "Epoch 1850, Loss: 27860.912109375\n",
            "Epoch 1851, Loss: 27845.8984375\n",
            "Epoch 1852, Loss: 27831.28125\n",
            "Epoch 1853, Loss: 27816.9140625\n",
            "Epoch 1854, Loss: 27802.794921875\n",
            "Epoch 1855, Loss: 27788.89453125\n",
            "Epoch 1856, Loss: 27775.21875\n",
            "Epoch 1857, Loss: 27761.634765625\n",
            "Epoch 1858, Loss: 27748.21484375\n",
            "Epoch 1859, Loss: 27734.974609375\n",
            "Epoch 1860, Loss: 27721.81640625\n",
            "Epoch 1861, Loss: 27708.748046875\n",
            "Epoch 1862, Loss: 27695.896484375\n",
            "Epoch 1863, Loss: 27682.98828125\n",
            "Epoch 1864, Loss: 27670.275390625\n",
            "Epoch 1865, Loss: 27657.583984375\n",
            "Epoch 1866, Loss: 27644.943359375\n",
            "Epoch 1867, Loss: 27632.41015625\n",
            "Epoch 1868, Loss: 27619.826171875\n",
            "Epoch 1869, Loss: 27607.2578125\n",
            "Epoch 1870, Loss: 27594.875\n",
            "Epoch 1871, Loss: 27582.486328125\n",
            "Epoch 1872, Loss: 27570.046875\n",
            "Epoch 1873, Loss: 27557.693359375\n",
            "Epoch 1874, Loss: 27545.517578125\n",
            "Epoch 1875, Loss: 27533.267578125\n",
            "Epoch 1876, Loss: 27521.01953125\n",
            "Epoch 1877, Loss: 27508.865234375\n",
            "Epoch 1878, Loss: 27496.59375\n",
            "Epoch 1879, Loss: 27484.505859375\n",
            "Epoch 1880, Loss: 27472.224609375\n",
            "Epoch 1881, Loss: 26748.70703125\n",
            "Epoch 1882, Loss: 13627.17578125\n",
            "Epoch 1883, Loss: 4528.318359375\n",
            "Epoch 1884, Loss: 2457.195068359375\n",
            "Epoch 1885, Loss: 0.8019131422042847\n",
            "Epoch 1886, Loss: 0.6715543866157532\n",
            "Epoch 1887, Loss: 0.6277011036872864\n",
            "Epoch 1888, Loss: 0.6034708023071289\n",
            "Epoch 1889, Loss: 0.5876404643058777\n",
            "Epoch 1890, Loss: 0.5763982534408569\n",
            "Epoch 1891, Loss: 0.5680074095726013\n",
            "Epoch 1892, Loss: 0.5615304708480835\n",
            "Epoch 1893, Loss: 0.5564071536064148\n",
            "Epoch 1894, Loss: 0.5522797107696533\n",
            "Epoch 1895, Loss: 0.548905074596405\n",
            "Epoch 1896, Loss: 0.5461114645004272\n",
            "Epoch 1897, Loss: 0.543775737285614\n",
            "Epoch 1898, Loss: 0.5418059825897217\n",
            "Epoch 1899, Loss: 0.540133535861969\n",
            "Epoch 1900, Loss: 0.538703441619873\n",
            "Epoch 1901, Loss: 0.5374745726585388\n",
            "Epoch 1902, Loss: 0.5364125967025757\n",
            "Epoch 1903, Loss: 0.5354920029640198\n",
            "Epoch 1904, Loss: 0.5346900224685669\n",
            "Epoch 1905, Loss: 0.5339888334274292\n",
            "Epoch 1906, Loss: 0.533374547958374\n",
            "Epoch 1907, Loss: 0.532833993434906\n",
            "Epoch 1908, Loss: 0.5323583483695984\n",
            "Epoch 1909, Loss: 0.5319382548332214\n",
            "Epoch 1910, Loss: 0.531566858291626\n",
            "Epoch 1911, Loss: 0.5312368869781494\n",
            "Epoch 1912, Loss: 0.5309441685676575\n",
            "Epoch 1913, Loss: 0.5306844711303711\n",
            "Epoch 1914, Loss: 0.530453085899353\n",
            "Epoch 1915, Loss: 0.530246913433075\n",
            "Epoch 1916, Loss: 0.5300627946853638\n",
            "Epoch 1917, Loss: 0.5298984050750732\n",
            "Epoch 1918, Loss: 0.5297514200210571\n",
            "Epoch 1919, Loss: 0.5296201705932617\n",
            "Epoch 1920, Loss: 0.5295021533966064\n",
            "Epoch 1921, Loss: 0.5293965339660645\n",
            "Epoch 1922, Loss: 0.5293018817901611\n",
            "Epoch 1923, Loss: 0.5292170643806458\n",
            "Epoch 1924, Loss: 0.5291408896446228\n",
            "Epoch 1925, Loss: 0.5290727019309998\n",
            "Epoch 1926, Loss: 0.5290115475654602\n",
            "Epoch 1927, Loss: 0.5289562344551086\n",
            "Epoch 1928, Loss: 0.5289068222045898\n",
            "Epoch 1929, Loss: 0.5288622975349426\n",
            "Epoch 1930, Loss: 0.5288225412368774\n",
            "Epoch 1931, Loss: 0.5287867784500122\n",
            "Epoch 1932, Loss: 0.5287544131278992\n",
            "Epoch 1933, Loss: 0.5287256240844727\n",
            "Epoch 1934, Loss: 0.5286996364593506\n",
            "Epoch 1935, Loss: 0.5286762118339539\n",
            "Epoch 1936, Loss: 0.5286552309989929\n",
            "Epoch 1937, Loss: 0.5286359786987305\n",
            "Epoch 1938, Loss: 0.5286188721656799\n",
            "Epoch 1939, Loss: 0.5286033153533936\n",
            "Epoch 1940, Loss: 0.5285894274711609\n",
            "Epoch 1941, Loss: 0.5285769104957581\n",
            "Epoch 1942, Loss: 0.5285653471946716\n",
            "Epoch 1943, Loss: 0.5285550951957703\n",
            "Epoch 1944, Loss: 0.5285457372665405\n",
            "Epoch 1945, Loss: 0.5285375714302063\n",
            "Epoch 1946, Loss: 0.5285300016403198\n",
            "Epoch 1947, Loss: 0.5285231471061707\n",
            "Epoch 1948, Loss: 0.5285171866416931\n",
            "Epoch 1949, Loss: 0.5285117030143738\n",
            "Epoch 1950, Loss: 0.5285068154335022\n",
            "Epoch 1951, Loss: 0.5285022854804993\n",
            "Epoch 1952, Loss: 0.5284982919692993\n",
            "Epoch 1953, Loss: 0.528494656085968\n",
            "Epoch 1954, Loss: 0.5284913182258606\n",
            "Epoch 1955, Loss: 0.5284883379936218\n",
            "Epoch 1956, Loss: 0.5284857153892517\n",
            "Epoch 1957, Loss: 0.5284833312034607\n",
            "Epoch 1958, Loss: 0.528481125831604\n",
            "Epoch 1959, Loss: 0.5284790396690369\n",
            "Epoch 1960, Loss: 0.5284772515296936\n",
            "Epoch 1961, Loss: 0.5284757018089294\n",
            "Epoch 1962, Loss: 0.5284743309020996\n",
            "Epoch 1963, Loss: 0.528472900390625\n",
            "Epoch 1964, Loss: 0.5284716486930847\n",
            "Epoch 1965, Loss: 0.5284706950187683\n",
            "Epoch 1966, Loss: 0.5284696221351624\n",
            "Epoch 1967, Loss: 0.5284687280654907\n",
            "Epoch 1968, Loss: 0.5284679532051086\n",
            "Epoch 1969, Loss: 0.5284671783447266\n",
            "Epoch 1970, Loss: 0.5284664034843445\n",
            "Epoch 1971, Loss: 0.5284658074378967\n",
            "Epoch 1972, Loss: 0.5284653902053833\n",
            "Epoch 1973, Loss: 0.5284649133682251\n",
            "Epoch 1974, Loss: 0.5284645557403564\n",
            "Epoch 1975, Loss: 0.5284643173217773\n",
            "Epoch 1976, Loss: 0.528464138507843\n",
            "Epoch 1977, Loss: 0.5284639000892639\n",
            "Epoch 1978, Loss: 0.5284637212753296\n",
            "Epoch 1979, Loss: 0.5284634828567505\n",
            "Epoch 1980, Loss: 0.5284633636474609\n",
            "Epoch 1981, Loss: 0.5284631252288818\n",
            "Epoch 1982, Loss: 0.5284630060195923\n",
            "Epoch 1983, Loss: 0.5284627676010132\n",
            "Epoch 1984, Loss: 0.5284625887870789\n",
            "Epoch 1985, Loss: 0.5284624695777893\n",
            "Epoch 1986, Loss: 0.528462290763855\n",
            "Epoch 1987, Loss: 0.5284621119499207\n",
            "Epoch 1988, Loss: 0.5284620523452759\n",
            "Epoch 1989, Loss: 0.5284619331359863\n",
            "Epoch 1990, Loss: 0.528461754322052\n",
            "Epoch 1991, Loss: 0.5284616351127625\n",
            "Epoch 1992, Loss: 0.5284615159034729\n",
            "Epoch 1993, Loss: 0.5284613966941833\n",
            "Epoch 1994, Loss: 0.5284612774848938\n",
            "Epoch 1995, Loss: 0.5284611582756042\n",
            "Epoch 1996, Loss: 0.5284610390663147\n",
            "Epoch 1997, Loss: 0.5284608602523804\n",
            "Epoch 1998, Loss: 0.5284608006477356\n",
            "Epoch 1999, Loss: 0.528460681438446\n",
            "Epoch 2000, Loss: 0.5284605026245117\n",
            "Epoch 2001, Loss: 0.5284604430198669\n",
            "Epoch 2002, Loss: 0.5284602642059326\n",
            "Epoch 2003, Loss: 0.5284601449966431\n",
            "Epoch 2004, Loss: 0.5284599661827087\n",
            "Epoch 2005, Loss: 0.528459906578064\n",
            "Epoch 2006, Loss: 0.5284597873687744\n",
            "Epoch 2007, Loss: 0.5284596681594849\n",
            "Epoch 2008, Loss: 0.5284595489501953\n",
            "Epoch 2009, Loss: 0.5284594297409058\n",
            "Epoch 2010, Loss: 0.5284593105316162\n",
            "Epoch 2011, Loss: 0.5284591317176819\n",
            "Epoch 2012, Loss: 0.5284590125083923\n",
            "Epoch 2013, Loss: 0.5284589529037476\n",
            "Epoch 2014, Loss: 0.5284587740898132\n",
            "Epoch 2015, Loss: 0.5284586548805237\n",
            "Epoch 2016, Loss: 0.5284585356712341\n",
            "Epoch 2017, Loss: 0.5284584164619446\n",
            "Epoch 2018, Loss: 0.528458297252655\n",
            "Epoch 2019, Loss: 0.5284581184387207\n",
            "Epoch 2020, Loss: 0.5284580588340759\n",
            "Epoch 2021, Loss: 0.5284578800201416\n",
            "Epoch 2022, Loss: 0.528457760810852\n",
            "Epoch 2023, Loss: 0.5284576416015625\n",
            "Epoch 2024, Loss: 0.528457522392273\n",
            "Epoch 2025, Loss: 0.5284574031829834\n",
            "Epoch 2026, Loss: 0.5284572839736938\n",
            "Epoch 2027, Loss: 0.5284571647644043\n",
            "Epoch 2028, Loss: 0.52845698595047\n",
            "Epoch 2029, Loss: 0.5284569263458252\n",
            "Epoch 2030, Loss: 0.5284568071365356\n",
            "Epoch 2031, Loss: 0.5284566283226013\n",
            "Epoch 2032, Loss: 0.5284565091133118\n",
            "Epoch 2033, Loss: 0.5284563899040222\n",
            "Epoch 2034, Loss: 0.5284562706947327\n",
            "Epoch 2035, Loss: 0.5284561514854431\n",
            "Epoch 2036, Loss: 0.5284560322761536\n",
            "Epoch 2037, Loss: 0.528455913066864\n",
            "Epoch 2038, Loss: 0.5284557342529297\n",
            "Epoch 2039, Loss: 0.5284556746482849\n",
            "Epoch 2040, Loss: 0.5284554958343506\n",
            "Epoch 2041, Loss: 0.528455376625061\n",
            "Epoch 2042, Loss: 0.5284552574157715\n",
            "Epoch 2043, Loss: 0.5284551382064819\n",
            "Epoch 2044, Loss: 0.5284550189971924\n",
            "Epoch 2045, Loss: 0.5284548401832581\n",
            "Epoch 2046, Loss: 0.5284547805786133\n",
            "Epoch 2047, Loss: 0.528454601764679\n",
            "Epoch 2048, Loss: 0.5284544825553894\n",
            "Epoch 2049, Loss: 0.5284544229507446\n",
            "Epoch 2050, Loss: 0.5284542441368103\n",
            "Epoch 2051, Loss: 0.5284541249275208\n",
            "Epoch 2052, Loss: 0.5284540057182312\n",
            "Epoch 2053, Loss: 0.5284538865089417\n",
            "Epoch 2054, Loss: 0.5284537076950073\n",
            "Epoch 2055, Loss: 0.5284535884857178\n",
            "Epoch 2056, Loss: 0.5284534692764282\n",
            "Epoch 2057, Loss: 0.5284533500671387\n",
            "Epoch 2058, Loss: 0.5284532308578491\n",
            "Epoch 2059, Loss: 0.5284531116485596\n",
            "Epoch 2060, Loss: 0.5284529328346252\n",
            "Epoch 2061, Loss: 0.5284528136253357\n",
            "Epoch 2062, Loss: 0.5284526944160461\n",
            "Epoch 2063, Loss: 0.5284525752067566\n",
            "Epoch 2064, Loss: 0.528452455997467\n",
            "Epoch 2065, Loss: 0.5284523367881775\n",
            "Epoch 2066, Loss: 0.5284521579742432\n",
            "Epoch 2067, Loss: 0.5284520387649536\n",
            "Epoch 2068, Loss: 0.5284519195556641\n",
            "Epoch 2069, Loss: 0.5284518003463745\n",
            "Epoch 2070, Loss: 0.528451681137085\n",
            "Epoch 2071, Loss: 0.5284515619277954\n",
            "Epoch 2072, Loss: 0.5284514427185059\n",
            "Epoch 2073, Loss: 0.5284513235092163\n",
            "Epoch 2074, Loss: 0.528451144695282\n",
            "Epoch 2075, Loss: 0.5284510254859924\n",
            "Epoch 2076, Loss: 0.5284509062767029\n",
            "Epoch 2077, Loss: 0.5284507870674133\n",
            "Epoch 2078, Loss: 0.5284506678581238\n",
            "Epoch 2079, Loss: 0.5284505486488342\n",
            "Epoch 2080, Loss: 0.5284503698348999\n",
            "Epoch 2081, Loss: 0.5284502506256104\n",
            "Epoch 2082, Loss: 0.5284501314163208\n",
            "Epoch 2083, Loss: 0.5284500122070312\n",
            "Epoch 2084, Loss: 0.5284498929977417\n",
            "Epoch 2085, Loss: 0.5284497141838074\n",
            "Epoch 2086, Loss: 0.5284495949745178\n",
            "Epoch 2087, Loss: 0.5284494757652283\n",
            "Epoch 2088, Loss: 0.5284493565559387\n",
            "Epoch 2089, Loss: 0.5284491777420044\n",
            "Epoch 2090, Loss: 0.5284491181373596\n",
            "Epoch 2091, Loss: 0.5284489393234253\n",
            "Epoch 2092, Loss: 0.5284488201141357\n",
            "Epoch 2093, Loss: 0.5284487009048462\n",
            "Epoch 2094, Loss: 0.5284485816955566\n",
            "Epoch 2095, Loss: 0.5284484624862671\n",
            "Epoch 2096, Loss: 0.5284483432769775\n",
            "Epoch 2097, Loss: 0.5284481644630432\n",
            "Epoch 2098, Loss: 0.5284480452537537\n",
            "Epoch 2099, Loss: 0.5284479260444641\n",
            "Epoch 2100, Loss: 0.5284478068351746\n",
            "Epoch 2101, Loss: 0.5284476280212402\n",
            "Epoch 2102, Loss: 0.5284475088119507\n",
            "Epoch 2103, Loss: 0.5284473896026611\n",
            "Epoch 2104, Loss: 0.5284472703933716\n",
            "Epoch 2105, Loss: 0.5284470915794373\n",
            "Epoch 2106, Loss: 0.5284470319747925\n",
            "Epoch 2107, Loss: 0.5284468531608582\n",
            "Epoch 2108, Loss: 0.5284467339515686\n",
            "Epoch 2109, Loss: 0.528446614742279\n",
            "Epoch 2110, Loss: 0.5284464359283447\n",
            "Epoch 2111, Loss: 0.5284463167190552\n",
            "Epoch 2112, Loss: 0.5284461975097656\n",
            "Epoch 2113, Loss: 0.5284460783004761\n",
            "Epoch 2114, Loss: 0.5284458994865417\n",
            "Epoch 2115, Loss: 0.528445839881897\n",
            "Epoch 2116, Loss: 0.5284456610679626\n",
            "Epoch 2117, Loss: 0.5284455418586731\n",
            "Epoch 2118, Loss: 0.5284454226493835\n",
            "Epoch 2119, Loss: 0.528445303440094\n",
            "Epoch 2120, Loss: 0.5284451246261597\n",
            "Epoch 2121, Loss: 0.5284450054168701\n",
            "Epoch 2122, Loss: 0.5284448862075806\n",
            "Epoch 2123, Loss: 0.528444766998291\n",
            "Epoch 2124, Loss: 0.5284445881843567\n",
            "Epoch 2125, Loss: 0.5284444689750671\n",
            "Epoch 2126, Loss: 0.5284443497657776\n",
            "Epoch 2127, Loss: 0.528444230556488\n",
            "Epoch 2128, Loss: 0.5284440517425537\n",
            "Epoch 2129, Loss: 0.5284439325332642\n",
            "Epoch 2130, Loss: 0.5284438133239746\n",
            "Epoch 2131, Loss: 0.5284436941146851\n",
            "Epoch 2132, Loss: 0.5284435153007507\n",
            "Epoch 2133, Loss: 0.528443455696106\n",
            "Epoch 2134, Loss: 0.5284432768821716\n",
            "Epoch 2135, Loss: 0.5284431576728821\n",
            "Epoch 2136, Loss: 0.5284429788589478\n",
            "Epoch 2137, Loss: 0.5284428596496582\n",
            "Epoch 2138, Loss: 0.5284427404403687\n",
            "Epoch 2139, Loss: 0.5284426212310791\n",
            "Epoch 2140, Loss: 0.5284425020217896\n",
            "Epoch 2141, Loss: 0.5284423232078552\n",
            "Epoch 2142, Loss: 0.5284422039985657\n",
            "Epoch 2143, Loss: 0.5284420251846313\n",
            "Epoch 2144, Loss: 0.5284419059753418\n",
            "Epoch 2145, Loss: 0.5284417867660522\n",
            "Epoch 2146, Loss: 0.5284416675567627\n",
            "Epoch 2147, Loss: 0.5284415483474731\n",
            "Epoch 2148, Loss: 0.5284414291381836\n",
            "Epoch 2149, Loss: 0.5284412503242493\n",
            "Epoch 2150, Loss: 0.5284411311149597\n",
            "Epoch 2151, Loss: 0.5284409523010254\n",
            "Epoch 2152, Loss: 0.5284408330917358\n",
            "Epoch 2153, Loss: 0.5284407138824463\n",
            "Epoch 2154, Loss: 0.528440535068512\n",
            "Epoch 2155, Loss: 0.5284404158592224\n",
            "Epoch 2156, Loss: 0.5284403562545776\n",
            "Epoch 2157, Loss: 0.5284401774406433\n",
            "Epoch 2158, Loss: 0.5284400582313538\n",
            "Epoch 2159, Loss: 0.5284399390220642\n",
            "Epoch 2160, Loss: 0.5284397602081299\n",
            "Epoch 2161, Loss: 0.5284396409988403\n",
            "Epoch 2162, Loss: 0.5284395217895508\n",
            "Epoch 2163, Loss: 0.5284393429756165\n",
            "Epoch 2164, Loss: 0.5284392237663269\n",
            "Epoch 2165, Loss: 0.5284391045570374\n",
            "Epoch 2166, Loss: 0.5284389853477478\n",
            "Epoch 2167, Loss: 0.5284388661384583\n",
            "Epoch 2168, Loss: 0.5284386873245239\n",
            "Epoch 2169, Loss: 0.5284385681152344\n",
            "Epoch 2170, Loss: 0.5284383893013\n",
            "Epoch 2171, Loss: 0.5284382700920105\n",
            "Epoch 2172, Loss: 0.528438150882721\n",
            "Epoch 2173, Loss: 0.5284379720687866\n",
            "Epoch 2174, Loss: 0.5284378528594971\n",
            "Epoch 2175, Loss: 0.5284376740455627\n",
            "Epoch 2176, Loss: 0.528437614440918\n",
            "Epoch 2177, Loss: 0.5284374356269836\n",
            "Epoch 2178, Loss: 0.5284373164176941\n",
            "Epoch 2179, Loss: 0.5284371972084045\n",
            "Epoch 2180, Loss: 0.528437077999115\n",
            "Epoch 2181, Loss: 0.5284368991851807\n",
            "Epoch 2182, Loss: 0.5284367203712463\n",
            "Epoch 2183, Loss: 0.5284366607666016\n",
            "Epoch 2184, Loss: 0.5284364819526672\n",
            "Epoch 2185, Loss: 0.5284363627433777\n",
            "Epoch 2186, Loss: 0.5284361839294434\n",
            "Epoch 2187, Loss: 0.5284360647201538\n",
            "Epoch 2188, Loss: 0.5284359455108643\n",
            "Epoch 2189, Loss: 0.5284358263015747\n",
            "Epoch 2190, Loss: 0.5284356474876404\n",
            "Epoch 2191, Loss: 0.528435468673706\n",
            "Epoch 2192, Loss: 0.5284353494644165\n",
            "Epoch 2193, Loss: 0.528435230255127\n",
            "Epoch 2194, Loss: 0.5284351110458374\n",
            "Epoch 2195, Loss: 0.5284349918365479\n",
            "Epoch 2196, Loss: 0.5284348726272583\n",
            "Epoch 2197, Loss: 0.528434693813324\n",
            "Epoch 2198, Loss: 0.5284345149993896\n",
            "Epoch 2199, Loss: 0.5284344553947449\n",
            "Epoch 2200, Loss: 0.5284342765808105\n",
            "Epoch 2201, Loss: 0.528434157371521\n",
            "Epoch 2202, Loss: 0.5284339785575867\n",
            "Epoch 2203, Loss: 0.5284338593482971\n",
            "Epoch 2204, Loss: 0.5284337401390076\n",
            "Epoch 2205, Loss: 0.5284335613250732\n",
            "Epoch 2206, Loss: 0.5284334421157837\n",
            "Epoch 2207, Loss: 0.5284332633018494\n",
            "Epoch 2208, Loss: 0.5284331440925598\n",
            "Epoch 2209, Loss: 0.5284330248832703\n",
            "Epoch 2210, Loss: 0.5284329056739807\n",
            "Epoch 2211, Loss: 0.5284327268600464\n",
            "Epoch 2212, Loss: 0.5284326076507568\n",
            "Epoch 2213, Loss: 0.5284324884414673\n",
            "Epoch 2214, Loss: 0.528432309627533\n",
            "Epoch 2215, Loss: 0.5284321904182434\n",
            "Epoch 2216, Loss: 0.5284320712089539\n",
            "Epoch 2217, Loss: 0.5284318923950195\n",
            "Epoch 2218, Loss: 0.52843177318573\n",
            "Epoch 2219, Loss: 0.5284315943717957\n",
            "Epoch 2220, Loss: 0.5284314751625061\n",
            "Epoch 2221, Loss: 0.5284313559532166\n",
            "Epoch 2222, Loss: 0.528431236743927\n",
            "Epoch 2223, Loss: 0.5284310579299927\n",
            "Epoch 2224, Loss: 0.5284309387207031\n",
            "Epoch 2225, Loss: 0.5284308195114136\n",
            "Epoch 2226, Loss: 0.5284306406974792\n",
            "Epoch 2227, Loss: 0.5284305214881897\n",
            "Epoch 2228, Loss: 0.5284303426742554\n",
            "Epoch 2229, Loss: 0.5284302234649658\n",
            "Epoch 2230, Loss: 0.5284301042556763\n",
            "Epoch 2231, Loss: 0.5284299254417419\n",
            "Epoch 2232, Loss: 0.5284298062324524\n",
            "Epoch 2233, Loss: 0.5284296274185181\n",
            "Epoch 2234, Loss: 0.5284295082092285\n",
            "Epoch 2235, Loss: 0.528429388999939\n",
            "Epoch 2236, Loss: 0.5284292101860046\n",
            "Epoch 2237, Loss: 0.5284290909767151\n",
            "Epoch 2238, Loss: 0.5284289717674255\n",
            "Epoch 2239, Loss: 0.5284287929534912\n",
            "Epoch 2240, Loss: 0.5284286737442017\n",
            "Epoch 2241, Loss: 0.5284284949302673\n",
            "Epoch 2242, Loss: 0.5284283757209778\n",
            "Epoch 2243, Loss: 0.5284282565116882\n",
            "Epoch 2244, Loss: 0.5284280776977539\n",
            "Epoch 2245, Loss: 0.5284279584884644\n",
            "Epoch 2246, Loss: 0.5284278392791748\n",
            "Epoch 2247, Loss: 0.5284276604652405\n",
            "Epoch 2248, Loss: 0.5284275412559509\n",
            "Epoch 2249, Loss: 0.5284273624420166\n",
            "Epoch 2250, Loss: 0.528427243232727\n",
            "Epoch 2251, Loss: 0.5284270644187927\n",
            "Epoch 2252, Loss: 0.5284269452095032\n",
            "Epoch 2253, Loss: 0.5284268260002136\n",
            "Epoch 2254, Loss: 0.5284266471862793\n",
            "Epoch 2255, Loss: 0.5284265279769897\n",
            "Epoch 2256, Loss: 0.5284263491630554\n",
            "Epoch 2257, Loss: 0.5284262299537659\n",
            "Epoch 2258, Loss: 0.5284261107444763\n",
            "Epoch 2259, Loss: 0.528425931930542\n",
            "Epoch 2260, Loss: 0.5284258127212524\n",
            "Epoch 2261, Loss: 0.5284256935119629\n",
            "Epoch 2262, Loss: 0.5284255146980286\n",
            "Epoch 2263, Loss: 0.528425395488739\n",
            "Epoch 2264, Loss: 0.5284252166748047\n",
            "Epoch 2265, Loss: 0.5284250974655151\n",
            "Epoch 2266, Loss: 0.5284249782562256\n",
            "Epoch 2267, Loss: 0.5284247994422913\n",
            "Epoch 2268, Loss: 0.5284246802330017\n",
            "Epoch 2269, Loss: 0.5284245014190674\n",
            "Epoch 2270, Loss: 0.5284243822097778\n",
            "Epoch 2271, Loss: 0.5284242630004883\n",
            "Epoch 2272, Loss: 0.528424084186554\n",
            "Epoch 2273, Loss: 0.5284239053726196\n",
            "Epoch 2274, Loss: 0.5284237861633301\n",
            "Epoch 2275, Loss: 0.5284236669540405\n",
            "Epoch 2276, Loss: 0.5284234285354614\n",
            "Epoch 2277, Loss: 0.5284233689308167\n",
            "Epoch 2278, Loss: 0.5284231901168823\n",
            "Epoch 2279, Loss: 0.528423011302948\n",
            "Epoch 2280, Loss: 0.5284228920936584\n",
            "Epoch 2281, Loss: 0.5284227728843689\n",
            "Epoch 2282, Loss: 0.5284225940704346\n",
            "Epoch 2283, Loss: 0.528422474861145\n",
            "Epoch 2284, Loss: 0.5284222960472107\n",
            "Epoch 2285, Loss: 0.5284221768379211\n",
            "Epoch 2286, Loss: 0.5284220576286316\n",
            "Epoch 2287, Loss: 0.5284218788146973\n",
            "Epoch 2288, Loss: 0.5284217596054077\n",
            "Epoch 2289, Loss: 0.5284215807914734\n",
            "Epoch 2290, Loss: 0.5284214615821838\n",
            "Epoch 2291, Loss: 0.5284212827682495\n",
            "Epoch 2292, Loss: 0.52842116355896\n",
            "Epoch 2293, Loss: 0.5284209847450256\n",
            "Epoch 2294, Loss: 0.5284208655357361\n",
            "Epoch 2295, Loss: 0.5284206867218018\n",
            "Epoch 2296, Loss: 0.5284205675125122\n",
            "Epoch 2297, Loss: 0.5284204483032227\n",
            "Epoch 2298, Loss: 0.5284202694892883\n",
            "Epoch 2299, Loss: 0.528420090675354\n",
            "Epoch 2300, Loss: 0.5284200310707092\n",
            "Epoch 2301, Loss: 0.5284198522567749\n",
            "Epoch 2302, Loss: 0.5284196734428406\n",
            "Epoch 2303, Loss: 0.528419554233551\n",
            "Epoch 2304, Loss: 0.5284193754196167\n",
            "Epoch 2305, Loss: 0.5284192562103271\n",
            "Epoch 2306, Loss: 0.5284191370010376\n",
            "Epoch 2307, Loss: 0.5284189581871033\n",
            "Epoch 2308, Loss: 0.5284188389778137\n",
            "Epoch 2309, Loss: 0.5284186601638794\n",
            "Epoch 2310, Loss: 0.5284185409545898\n",
            "Epoch 2311, Loss: 0.5284183621406555\n",
            "Epoch 2312, Loss: 0.528418242931366\n",
            "Epoch 2313, Loss: 0.5284180641174316\n",
            "Epoch 2314, Loss: 0.5284179449081421\n",
            "Epoch 2315, Loss: 0.5284178256988525\n",
            "Epoch 2316, Loss: 0.5284176468849182\n",
            "Epoch 2317, Loss: 0.5284174680709839\n",
            "Epoch 2318, Loss: 0.5284173488616943\n",
            "Epoch 2319, Loss: 0.52841717004776\n",
            "Epoch 2320, Loss: 0.5284170508384705\n",
            "Epoch 2321, Loss: 0.5284169316291809\n",
            "Epoch 2322, Loss: 0.5284167528152466\n",
            "Epoch 2323, Loss: 0.5284165740013123\n",
            "Epoch 2324, Loss: 0.5284164547920227\n",
            "Epoch 2325, Loss: 0.5284162759780884\n",
            "Epoch 2326, Loss: 0.5284162163734436\n",
            "Epoch 2327, Loss: 0.5284159779548645\n",
            "Epoch 2328, Loss: 0.528415858745575\n",
            "Epoch 2329, Loss: 0.5284156799316406\n",
            "Epoch 2330, Loss: 0.5284155607223511\n",
            "Epoch 2331, Loss: 0.5284153819084167\n",
            "Epoch 2332, Loss: 0.5284152626991272\n",
            "Epoch 2333, Loss: 0.5284151434898376\n",
            "Epoch 2334, Loss: 0.5284149646759033\n",
            "Epoch 2335, Loss: 0.528414785861969\n",
            "Epoch 2336, Loss: 0.5284146070480347\n",
            "Epoch 2337, Loss: 0.5284144878387451\n",
            "Epoch 2338, Loss: 0.5284143686294556\n",
            "Epoch 2339, Loss: 0.5284141898155212\n",
            "Epoch 2340, Loss: 0.5284140706062317\n",
            "Epoch 2341, Loss: 0.5284138917922974\n",
            "Epoch 2342, Loss: 0.5284137725830078\n",
            "Epoch 2343, Loss: 0.5284135937690735\n",
            "Epoch 2344, Loss: 0.5284134745597839\n",
            "Epoch 2345, Loss: 0.5284132957458496\n",
            "Epoch 2346, Loss: 0.5284131765365601\n",
            "Epoch 2347, Loss: 0.5284129977226257\n",
            "Epoch 2348, Loss: 0.5284128189086914\n",
            "Epoch 2349, Loss: 0.5284126996994019\n",
            "Epoch 2350, Loss: 0.5284125804901123\n",
            "Epoch 2351, Loss: 0.528412401676178\n",
            "Epoch 2352, Loss: 0.5284122228622437\n",
            "Epoch 2353, Loss: 0.5284121632575989\n",
            "Epoch 2354, Loss: 0.5284119248390198\n",
            "Epoch 2355, Loss: 0.5284118056297302\n",
            "Epoch 2356, Loss: 0.5284116268157959\n",
            "Epoch 2357, Loss: 0.5284115076065063\n",
            "Epoch 2358, Loss: 0.528411328792572\n",
            "Epoch 2359, Loss: 0.5284112095832825\n",
            "Epoch 2360, Loss: 0.5284110903739929\n",
            "Epoch 2361, Loss: 0.5284108519554138\n",
            "Epoch 2362, Loss: 0.5284107327461243\n",
            "Epoch 2363, Loss: 0.5284105539321899\n",
            "Epoch 2364, Loss: 0.5284104347229004\n",
            "Epoch 2365, Loss: 0.5284102559089661\n",
            "Epoch 2366, Loss: 0.5284101366996765\n",
            "Epoch 2367, Loss: 0.5284099578857422\n",
            "Epoch 2368, Loss: 0.5284098386764526\n",
            "Epoch 2369, Loss: 0.5284096598625183\n",
            "Epoch 2370, Loss: 0.528409481048584\n",
            "Epoch 2371, Loss: 0.5284093618392944\n",
            "Epoch 2372, Loss: 0.5284092426300049\n",
            "Epoch 2373, Loss: 0.5284090638160706\n",
            "Epoch 2374, Loss: 0.5284088850021362\n",
            "Epoch 2375, Loss: 0.5284087657928467\n",
            "Epoch 2376, Loss: 0.5284085869789124\n",
            "Epoch 2377, Loss: 0.528408408164978\n",
            "Epoch 2378, Loss: 0.5284082889556885\n",
            "Epoch 2379, Loss: 0.5284081697463989\n",
            "Epoch 2380, Loss: 0.5284079909324646\n",
            "Epoch 2381, Loss: 0.528407871723175\n",
            "Epoch 2382, Loss: 0.528407633304596\n",
            "Epoch 2383, Loss: 0.5284075140953064\n",
            "Epoch 2384, Loss: 0.5284073352813721\n",
            "Epoch 2385, Loss: 0.5284072160720825\n",
            "Epoch 2386, Loss: 0.528407096862793\n",
            "Epoch 2387, Loss: 0.5284068584442139\n",
            "Epoch 2388, Loss: 0.5284067392349243\n",
            "Epoch 2389, Loss: 0.52840656042099\n",
            "Epoch 2390, Loss: 0.5284064412117004\n",
            "Epoch 2391, Loss: 0.5284063220024109\n",
            "Epoch 2392, Loss: 0.5284061431884766\n",
            "Epoch 2393, Loss: 0.5284059643745422\n",
            "Epoch 2394, Loss: 0.5284057855606079\n",
            "Epoch 2395, Loss: 0.5284056663513184\n",
            "Epoch 2396, Loss: 0.528405487537384\n",
            "Epoch 2397, Loss: 0.5284053087234497\n",
            "Epoch 2398, Loss: 0.5284052491188049\n",
            "Epoch 2399, Loss: 0.5284050703048706\n",
            "Epoch 2400, Loss: 0.5284048914909363\n",
            "Epoch 2401, Loss: 0.528404712677002\n",
            "Epoch 2402, Loss: 0.5284045934677124\n",
            "Epoch 2403, Loss: 0.5284044146537781\n",
            "Epoch 2404, Loss: 0.5284042358398438\n",
            "Epoch 2405, Loss: 0.5284040570259094\n",
            "Epoch 2406, Loss: 0.5284039378166199\n",
            "Epoch 2407, Loss: 0.5284038186073303\n",
            "Epoch 2408, Loss: 0.528403639793396\n",
            "Epoch 2409, Loss: 0.5284035205841064\n",
            "Epoch 2410, Loss: 0.5284033417701721\n",
            "Epoch 2411, Loss: 0.5284031629562378\n",
            "Epoch 2412, Loss: 0.5284030437469482\n",
            "Epoch 2413, Loss: 0.5284028649330139\n",
            "Epoch 2414, Loss: 0.5284027457237244\n",
            "Epoch 2415, Loss: 0.52840256690979\n",
            "Epoch 2416, Loss: 0.5284023880958557\n",
            "Epoch 2417, Loss: 0.5284022092819214\n",
            "Epoch 2418, Loss: 0.5284020900726318\n",
            "Epoch 2419, Loss: 0.5284019112586975\n",
            "Epoch 2420, Loss: 0.5284017324447632\n",
            "Epoch 2421, Loss: 0.5284016132354736\n",
            "Epoch 2422, Loss: 0.5284014344215393\n",
            "Epoch 2423, Loss: 0.5284013152122498\n",
            "Epoch 2424, Loss: 0.5284011363983154\n",
            "Epoch 2425, Loss: 0.5284010171890259\n",
            "Epoch 2426, Loss: 0.5284008383750916\n",
            "Epoch 2427, Loss: 0.5284006595611572\n",
            "Epoch 2428, Loss: 0.5284005403518677\n",
            "Epoch 2429, Loss: 0.5284003019332886\n",
            "Epoch 2430, Loss: 0.528400182723999\n",
            "Epoch 2431, Loss: 0.5284000635147095\n",
            "Epoch 2432, Loss: 0.5283998847007751\n",
            "Epoch 2433, Loss: 0.5283997654914856\n",
            "Epoch 2434, Loss: 0.5283995866775513\n",
            "Epoch 2435, Loss: 0.5283994078636169\n",
            "Epoch 2436, Loss: 0.5283992290496826\n",
            "Epoch 2437, Loss: 0.5283991098403931\n",
            "Epoch 2438, Loss: 0.5283989310264587\n",
            "Epoch 2439, Loss: 0.5283987522125244\n",
            "Epoch 2440, Loss: 0.5283985733985901\n",
            "Epoch 2441, Loss: 0.5283984541893005\n",
            "Epoch 2442, Loss: 0.528398334980011\n",
            "Epoch 2443, Loss: 0.5283980965614319\n",
            "Epoch 2444, Loss: 0.5283979773521423\n",
            "Epoch 2445, Loss: 0.528397798538208\n",
            "Epoch 2446, Loss: 0.5283976197242737\n",
            "Epoch 2447, Loss: 0.5283975005149841\n",
            "Epoch 2448, Loss: 0.5283973813056946\n",
            "Epoch 2449, Loss: 0.5283972024917603\n",
            "Epoch 2450, Loss: 0.5283970236778259\n",
            "Epoch 2451, Loss: 0.5283968448638916\n",
            "Epoch 2452, Loss: 0.5283966660499573\n",
            "Epoch 2453, Loss: 0.5283965468406677\n",
            "Epoch 2454, Loss: 0.5283963680267334\n",
            "Epoch 2455, Loss: 0.5283962488174438\n",
            "Epoch 2456, Loss: 0.5283960103988647\n",
            "Epoch 2457, Loss: 0.5283958911895752\n",
            "Epoch 2458, Loss: 0.5283957719802856\n",
            "Epoch 2459, Loss: 0.5283955931663513\n",
            "Epoch 2460, Loss: 0.528395414352417\n",
            "Epoch 2461, Loss: 0.5283952355384827\n",
            "Epoch 2462, Loss: 0.5283950567245483\n",
            "Epoch 2463, Loss: 0.5283949375152588\n",
            "Epoch 2464, Loss: 0.5283947587013245\n",
            "Epoch 2465, Loss: 0.5283946394920349\n",
            "Epoch 2466, Loss: 0.5283944606781006\n",
            "Epoch 2467, Loss: 0.5283942818641663\n",
            "Epoch 2468, Loss: 0.5283941030502319\n",
            "Epoch 2469, Loss: 0.5283939838409424\n",
            "Epoch 2470, Loss: 0.5283938050270081\n",
            "Epoch 2471, Loss: 0.5283936262130737\n",
            "Epoch 2472, Loss: 0.5283934473991394\n",
            "Epoch 2473, Loss: 0.5283933281898499\n",
            "Epoch 2474, Loss: 0.5283931493759155\n",
            "Epoch 2475, Loss: 0.5283929705619812\n",
            "Epoch 2476, Loss: 0.5283928513526917\n",
            "Epoch 2477, Loss: 0.5283926725387573\n",
            "Epoch 2478, Loss: 0.5283925533294678\n",
            "Epoch 2479, Loss: 0.5283923149108887\n",
            "Epoch 2480, Loss: 0.5283921957015991\n",
            "Epoch 2481, Loss: 0.5283920764923096\n",
            "Epoch 2482, Loss: 0.5283918976783752\n",
            "Epoch 2483, Loss: 0.5283917188644409\n",
            "Epoch 2484, Loss: 0.5283915400505066\n",
            "Epoch 2485, Loss: 0.5283913612365723\n",
            "Epoch 2486, Loss: 0.5283911824226379\n",
            "Epoch 2487, Loss: 0.5283910632133484\n",
            "Epoch 2488, Loss: 0.5283908843994141\n",
            "Epoch 2489, Loss: 0.5283907055854797\n",
            "Epoch 2490, Loss: 0.5283905267715454\n",
            "Epoch 2491, Loss: 0.5283904075622559\n",
            "Epoch 2492, Loss: 0.5283902287483215\n",
            "Epoch 2493, Loss: 0.5283900499343872\n",
            "Epoch 2494, Loss: 0.5283899307250977\n",
            "Epoch 2495, Loss: 0.5283897519111633\n",
            "Epoch 2496, Loss: 0.528389573097229\n",
            "Epoch 2497, Loss: 0.5283893942832947\n",
            "Epoch 2498, Loss: 0.5283892750740051\n",
            "Epoch 2499, Loss: 0.5283890962600708\n",
            "Epoch 2500, Loss: 0.5283889174461365\n",
            "Epoch 2501, Loss: 0.5283887386322021\n",
            "Epoch 2502, Loss: 0.5283886194229126\n",
            "Epoch 2503, Loss: 0.5283884406089783\n",
            "Epoch 2504, Loss: 0.528388261795044\n",
            "Epoch 2505, Loss: 0.5283880829811096\n",
            "Epoch 2506, Loss: 0.5283879637718201\n",
            "Epoch 2507, Loss: 0.5283877849578857\n",
            "Epoch 2508, Loss: 0.5283876061439514\n",
            "Epoch 2509, Loss: 0.5283874273300171\n",
            "Epoch 2510, Loss: 0.5283872485160828\n",
            "Epoch 2511, Loss: 0.5283871293067932\n",
            "Epoch 2512, Loss: 0.5283870100975037\n",
            "Epoch 2513, Loss: 0.5283867716789246\n",
            "Epoch 2514, Loss: 0.5283865928649902\n",
            "Epoch 2515, Loss: 0.5283864736557007\n",
            "Epoch 2516, Loss: 0.5283862948417664\n",
            "Epoch 2517, Loss: 0.528386116027832\n",
            "Epoch 2518, Loss: 0.5283859372138977\n",
            "Epoch 2519, Loss: 0.5283857583999634\n",
            "Epoch 2520, Loss: 0.5283856391906738\n",
            "Epoch 2521, Loss: 0.5283854007720947\n",
            "Epoch 2522, Loss: 0.5283852815628052\n",
            "Epoch 2523, Loss: 0.5283851027488708\n",
            "Epoch 2524, Loss: 0.5283849835395813\n",
            "Epoch 2525, Loss: 0.528384804725647\n",
            "Epoch 2526, Loss: 0.5283846259117126\n",
            "Epoch 2527, Loss: 0.5283844470977783\n",
            "Epoch 2528, Loss: 0.528384268283844\n",
            "Epoch 2529, Loss: 0.5283841490745544\n",
            "Epoch 2530, Loss: 0.5283839106559753\n",
            "Epoch 2531, Loss: 0.5283837914466858\n",
            "Epoch 2532, Loss: 0.5283836126327515\n",
            "Epoch 2533, Loss: 0.5283834338188171\n",
            "Epoch 2534, Loss: 0.5283833146095276\n",
            "Epoch 2535, Loss: 0.5283831357955933\n",
            "Epoch 2536, Loss: 0.5283829569816589\n",
            "Epoch 2537, Loss: 0.5283827781677246\n",
            "Epoch 2538, Loss: 0.5283826589584351\n",
            "Epoch 2539, Loss: 0.5283824801445007\n",
            "Epoch 2540, Loss: 0.5283823013305664\n",
            "Epoch 2541, Loss: 0.5283821225166321\n",
            "Epoch 2542, Loss: 0.5283819437026978\n",
            "Epoch 2543, Loss: 0.5283817648887634\n",
            "Epoch 2544, Loss: 0.5283815860748291\n",
            "Epoch 2545, Loss: 0.5283814668655396\n",
            "Epoch 2546, Loss: 0.5283812880516052\n",
            "Epoch 2547, Loss: 0.5283811092376709\n",
            "Epoch 2548, Loss: 0.5283809304237366\n",
            "Epoch 2549, Loss: 0.528380811214447\n",
            "Epoch 2550, Loss: 0.5283805727958679\n",
            "Epoch 2551, Loss: 0.5283804535865784\n",
            "Epoch 2552, Loss: 0.528380274772644\n",
            "Epoch 2553, Loss: 0.5283800959587097\n",
            "Epoch 2554, Loss: 0.5283799171447754\n",
            "Epoch 2555, Loss: 0.5283797383308411\n",
            "Epoch 2556, Loss: 0.5283795595169067\n",
            "Epoch 2557, Loss: 0.5283794403076172\n",
            "Epoch 2558, Loss: 0.5283792018890381\n",
            "Epoch 2559, Loss: 0.5283790826797485\n",
            "Epoch 2560, Loss: 0.5283789038658142\n",
            "Epoch 2561, Loss: 0.5283787846565247\n",
            "Epoch 2562, Loss: 0.5283786058425903\n",
            "Epoch 2563, Loss: 0.528378427028656\n",
            "Epoch 2564, Loss: 0.5283782482147217\n",
            "Epoch 2565, Loss: 0.5283780694007874\n",
            "Epoch 2566, Loss: 0.528377890586853\n",
            "Epoch 2567, Loss: 0.5283777117729187\n",
            "Epoch 2568, Loss: 0.5283775329589844\n",
            "Epoch 2569, Loss: 0.52837735414505\n",
            "Epoch 2570, Loss: 0.5283772349357605\n",
            "Epoch 2571, Loss: 0.5283769965171814\n",
            "Epoch 2572, Loss: 0.5283768177032471\n",
            "Epoch 2573, Loss: 0.5283767580986023\n",
            "Epoch 2574, Loss: 0.5283765196800232\n",
            "Epoch 2575, Loss: 0.5283763408660889\n",
            "Epoch 2576, Loss: 0.5283762216567993\n",
            "Epoch 2577, Loss: 0.528376042842865\n",
            "Epoch 2578, Loss: 0.5283758640289307\n",
            "Epoch 2579, Loss: 0.5283756852149963\n",
            "Epoch 2580, Loss: 0.528375506401062\n",
            "Epoch 2581, Loss: 0.5283753275871277\n",
            "Epoch 2582, Loss: 0.5283751487731934\n",
            "Epoch 2583, Loss: 0.528374969959259\n",
            "Epoch 2584, Loss: 0.5283747911453247\n",
            "Epoch 2585, Loss: 0.5283746719360352\n",
            "Epoch 2586, Loss: 0.528374433517456\n",
            "Epoch 2587, Loss: 0.5283743143081665\n",
            "Epoch 2588, Loss: 0.5283740758895874\n",
            "Epoch 2589, Loss: 0.5283739566802979\n",
            "Epoch 2590, Loss: 0.5283737778663635\n",
            "Epoch 2591, Loss: 0.5283735990524292\n",
            "Epoch 2592, Loss: 0.5283734798431396\n",
            "Epoch 2593, Loss: 0.5283732414245605\n",
            "Epoch 2594, Loss: 0.528373122215271\n",
            "Epoch 2595, Loss: 0.5283729434013367\n",
            "Epoch 2596, Loss: 0.5283727645874023\n",
            "Epoch 2597, Loss: 0.5283725261688232\n",
            "Epoch 2598, Loss: 0.5283724069595337\n",
            "Epoch 2599, Loss: 0.5283722281455994\n",
            "Epoch 2600, Loss: 0.528372049331665\n",
            "Epoch 2601, Loss: 0.5283718705177307\n",
            "Epoch 2602, Loss: 0.5283716917037964\n",
            "Epoch 2603, Loss: 0.5283715128898621\n",
            "Epoch 2604, Loss: 0.5283713340759277\n",
            "Epoch 2605, Loss: 0.5283711552619934\n",
            "Epoch 2606, Loss: 0.5283710360527039\n",
            "Epoch 2607, Loss: 0.5283707976341248\n",
            "Epoch 2608, Loss: 0.5283706784248352\n",
            "Epoch 2609, Loss: 0.5283704400062561\n",
            "Epoch 2610, Loss: 0.5283703207969666\n",
            "Epoch 2611, Loss: 0.5283701419830322\n",
            "Epoch 2612, Loss: 0.5283699631690979\n",
            "Epoch 2613, Loss: 0.5283697843551636\n",
            "Epoch 2614, Loss: 0.5283696055412292\n",
            "Epoch 2615, Loss: 0.5283694863319397\n",
            "Epoch 2616, Loss: 0.5283692479133606\n",
            "Epoch 2617, Loss: 0.5283690690994263\n",
            "Epoch 2618, Loss: 0.5283689498901367\n",
            "Epoch 2619, Loss: 0.5283687710762024\n",
            "Epoch 2620, Loss: 0.5283685326576233\n",
            "Epoch 2621, Loss: 0.5283684134483337\n",
            "Epoch 2622, Loss: 0.5283681750297546\n",
            "Epoch 2623, Loss: 0.5283680558204651\n",
            "Epoch 2624, Loss: 0.5283678770065308\n",
            "Epoch 2625, Loss: 0.5283676981925964\n",
            "Epoch 2626, Loss: 0.5283675193786621\n",
            "Epoch 2627, Loss: 0.5283673405647278\n",
            "Epoch 2628, Loss: 0.5283671617507935\n",
            "Epoch 2629, Loss: 0.5283669829368591\n",
            "Epoch 2630, Loss: 0.5283668637275696\n",
            "Epoch 2631, Loss: 0.5283666253089905\n",
            "Epoch 2632, Loss: 0.5283665060997009\n",
            "Epoch 2633, Loss: 0.5283662676811218\n",
            "Epoch 2634, Loss: 0.5283661484718323\n",
            "Epoch 2635, Loss: 0.528365969657898\n",
            "Epoch 2636, Loss: 0.5283657908439636\n",
            "Epoch 2637, Loss: 0.5283655524253845\n",
            "Epoch 2638, Loss: 0.528365433216095\n",
            "Epoch 2639, Loss: 0.5283651947975159\n",
            "Epoch 2640, Loss: 0.5283650755882263\n",
            "Epoch 2641, Loss: 0.5283648371696472\n",
            "Epoch 2642, Loss: 0.5283647179603577\n",
            "Epoch 2643, Loss: 0.5283645391464233\n",
            "Epoch 2644, Loss: 0.528364360332489\n",
            "Epoch 2645, Loss: 0.5283641219139099\n",
            "Epoch 2646, Loss: 0.5283640027046204\n",
            "Epoch 2647, Loss: 0.528363823890686\n",
            "Epoch 2648, Loss: 0.5283636450767517\n",
            "Epoch 2649, Loss: 0.5283634662628174\n",
            "Epoch 2650, Loss: 0.5283632874488831\n",
            "Epoch 2651, Loss: 0.5283631086349487\n",
            "Epoch 2652, Loss: 0.5283629298210144\n",
            "Epoch 2653, Loss: 0.5283627510070801\n",
            "Epoch 2654, Loss: 0.5283625721931458\n",
            "Epoch 2655, Loss: 0.5283623337745667\n",
            "Epoch 2656, Loss: 0.5283622145652771\n",
            "Epoch 2657, Loss: 0.528361976146698\n",
            "Epoch 2658, Loss: 0.5283618569374084\n",
            "Epoch 2659, Loss: 0.5283616185188293\n",
            "Epoch 2660, Loss: 0.5283614993095398\n",
            "Epoch 2661, Loss: 0.5283612608909607\n",
            "Epoch 2662, Loss: 0.5283611416816711\n",
            "Epoch 2663, Loss: 0.528360903263092\n",
            "Epoch 2664, Loss: 0.5283607244491577\n",
            "Epoch 2665, Loss: 0.5283606052398682\n",
            "Epoch 2666, Loss: 0.5283603668212891\n",
            "Epoch 2667, Loss: 0.5283602476119995\n",
            "Epoch 2668, Loss: 0.5283600687980652\n",
            "Epoch 2669, Loss: 0.5283598303794861\n",
            "Epoch 2670, Loss: 0.5283597111701965\n",
            "Epoch 2671, Loss: 0.5283594727516174\n",
            "Epoch 2672, Loss: 0.5283593535423279\n",
            "Epoch 2673, Loss: 0.5283591747283936\n",
            "Epoch 2674, Loss: 0.5283589959144592\n",
            "Epoch 2675, Loss: 0.5283588171005249\n",
            "Epoch 2676, Loss: 0.5283585786819458\n",
            "Epoch 2677, Loss: 0.5283583998680115\n",
            "Epoch 2678, Loss: 0.5283582806587219\n",
            "Epoch 2679, Loss: 0.5283581018447876\n",
            "Epoch 2680, Loss: 0.5283578634262085\n",
            "Epoch 2681, Loss: 0.5283576846122742\n",
            "Epoch 2682, Loss: 0.5283575654029846\n",
            "Epoch 2683, Loss: 0.5283573865890503\n",
            "Epoch 2684, Loss: 0.5283571481704712\n",
            "Epoch 2685, Loss: 0.5283569693565369\n",
            "Epoch 2686, Loss: 0.5283567905426025\n",
            "Epoch 2687, Loss: 0.5283566117286682\n",
            "Epoch 2688, Loss: 0.5283564329147339\n",
            "Epoch 2689, Loss: 0.5283562541007996\n",
            "Epoch 2690, Loss: 0.5283560752868652\n",
            "Epoch 2691, Loss: 0.5283558964729309\n",
            "Epoch 2692, Loss: 0.5283557176589966\n",
            "Epoch 2693, Loss: 0.5283555388450623\n",
            "Epoch 2694, Loss: 0.5283553600311279\n",
            "Epoch 2695, Loss: 0.5283551812171936\n",
            "Epoch 2696, Loss: 0.5283550024032593\n",
            "Epoch 2697, Loss: 0.528354823589325\n",
            "Epoch 2698, Loss: 0.5283546447753906\n",
            "Epoch 2699, Loss: 0.5283544659614563\n",
            "Epoch 2700, Loss: 0.5283542275428772\n",
            "Epoch 2701, Loss: 0.5283541083335876\n",
            "Epoch 2702, Loss: 0.5283538699150085\n",
            "Epoch 2703, Loss: 0.5283536911010742\n",
            "Epoch 2704, Loss: 0.5283535122871399\n",
            "Epoch 2705, Loss: 0.5283533334732056\n",
            "Epoch 2706, Loss: 0.5283531546592712\n",
            "Epoch 2707, Loss: 0.5283529758453369\n",
            "Epoch 2708, Loss: 0.5283527970314026\n",
            "Epoch 2709, Loss: 0.5283526182174683\n",
            "Epoch 2710, Loss: 0.5283524394035339\n",
            "Epoch 2711, Loss: 0.5283522605895996\n",
            "Epoch 2712, Loss: 0.5283520221710205\n",
            "Epoch 2713, Loss: 0.5283518433570862\n",
            "Epoch 2714, Loss: 0.5283516645431519\n",
            "Epoch 2715, Loss: 0.5283514261245728\n",
            "Epoch 2716, Loss: 0.5283513069152832\n",
            "Epoch 2717, Loss: 0.5283511281013489\n",
            "Epoch 2718, Loss: 0.5283509492874146\n",
            "Epoch 2719, Loss: 0.5283507704734802\n",
            "Epoch 2720, Loss: 0.5283505916595459\n",
            "Epoch 2721, Loss: 0.5283504128456116\n",
            "Epoch 2722, Loss: 0.5283501744270325\n",
            "Epoch 2723, Loss: 0.5283499956130981\n",
            "Epoch 2724, Loss: 0.5283498167991638\n",
            "Epoch 2725, Loss: 0.5283496379852295\n",
            "Epoch 2726, Loss: 0.5283494591712952\n",
            "Epoch 2727, Loss: 0.5283492207527161\n",
            "Epoch 2728, Loss: 0.5283491015434265\n",
            "Epoch 2729, Loss: 0.5283488631248474\n",
            "Epoch 2730, Loss: 0.5283486843109131\n",
            "Epoch 2731, Loss: 0.5283485054969788\n",
            "Epoch 2732, Loss: 0.5283483266830444\n",
            "Epoch 2733, Loss: 0.5283481478691101\n",
            "Epoch 2734, Loss: 0.5283479690551758\n",
            "Epoch 2735, Loss: 0.5283477902412415\n",
            "Epoch 2736, Loss: 0.5283476114273071\n",
            "Epoch 2737, Loss: 0.528347373008728\n",
            "Epoch 2738, Loss: 0.5283471941947937\n",
            "Epoch 2739, Loss: 0.5283470153808594\n",
            "Epoch 2740, Loss: 0.528346836566925\n",
            "Epoch 2741, Loss: 0.5283466577529907\n",
            "Epoch 2742, Loss: 0.5283464789390564\n",
            "Epoch 2743, Loss: 0.5283463001251221\n",
            "Epoch 2744, Loss: 0.528346061706543\n",
            "Epoch 2745, Loss: 0.5283458828926086\n",
            "Epoch 2746, Loss: 0.5283457040786743\n",
            "Epoch 2747, Loss: 0.52834552526474\n",
            "Epoch 2748, Loss: 0.5283453464508057\n",
            "Epoch 2749, Loss: 0.5283451676368713\n",
            "Epoch 2750, Loss: 0.528344988822937\n",
            "Epoch 2751, Loss: 0.5283447504043579\n",
            "Epoch 2752, Loss: 0.5283446311950684\n",
            "Epoch 2753, Loss: 0.5283443927764893\n",
            "Epoch 2754, Loss: 0.5283442139625549\n",
            "Epoch 2755, Loss: 0.5283440351486206\n",
            "Epoch 2756, Loss: 0.5283438563346863\n",
            "Epoch 2757, Loss: 0.528343677520752\n",
            "Epoch 2758, Loss: 0.5283434987068176\n",
            "Epoch 2759, Loss: 0.5283432602882385\n",
            "Epoch 2760, Loss: 0.5283430814743042\n",
            "Epoch 2761, Loss: 0.5283429026603699\n",
            "Epoch 2762, Loss: 0.5283427238464355\n",
            "Epoch 2763, Loss: 0.5283425450325012\n",
            "Epoch 2764, Loss: 0.5283423662185669\n",
            "Epoch 2765, Loss: 0.5283421277999878\n",
            "Epoch 2766, Loss: 0.5283419489860535\n",
            "Epoch 2767, Loss: 0.5283417701721191\n",
            "Epoch 2768, Loss: 0.52834153175354\n",
            "Epoch 2769, Loss: 0.5283413529396057\n",
            "Epoch 2770, Loss: 0.5283411741256714\n",
            "Epoch 2771, Loss: 0.5283409953117371\n",
            "Epoch 2772, Loss: 0.5283408164978027\n",
            "Epoch 2773, Loss: 0.5283406376838684\n",
            "Epoch 2774, Loss: 0.5283403992652893\n",
            "Epoch 2775, Loss: 0.5283402800559998\n",
            "Epoch 2776, Loss: 0.5283400416374207\n",
            "Epoch 2777, Loss: 0.5283398628234863\n",
            "Epoch 2778, Loss: 0.528339684009552\n",
            "Epoch 2779, Loss: 0.5283395051956177\n",
            "Epoch 2780, Loss: 0.5283392667770386\n",
            "Epoch 2781, Loss: 0.528339147567749\n",
            "Epoch 2782, Loss: 0.5283389091491699\n",
            "Epoch 2783, Loss: 0.5283387303352356\n",
            "Epoch 2784, Loss: 0.5283385515213013\n",
            "Epoch 2785, Loss: 0.5283383727073669\n",
            "Epoch 2786, Loss: 0.5283381342887878\n",
            "Epoch 2787, Loss: 0.5283379554748535\n",
            "Epoch 2788, Loss: 0.5283377170562744\n",
            "Epoch 2789, Loss: 0.5283375382423401\n",
            "Epoch 2790, Loss: 0.5283373594284058\n",
            "Epoch 2791, Loss: 0.5283371806144714\n",
            "Epoch 2792, Loss: 0.5283370018005371\n",
            "Epoch 2793, Loss: 0.528336763381958\n",
            "Epoch 2794, Loss: 0.5283365845680237\n",
            "Epoch 2795, Loss: 0.5283364057540894\n",
            "Epoch 2796, Loss: 0.528336226940155\n",
            "Epoch 2797, Loss: 0.5283359885215759\n",
            "Epoch 2798, Loss: 0.5283358097076416\n",
            "Epoch 2799, Loss: 0.5283356308937073\n",
            "Epoch 2800, Loss: 0.528335452079773\n",
            "Epoch 2801, Loss: 0.5283352732658386\n",
            "Epoch 2802, Loss: 0.5283350944519043\n",
            "Epoch 2803, Loss: 0.5283348560333252\n",
            "Epoch 2804, Loss: 0.5283346176147461\n",
            "Epoch 2805, Loss: 0.5283344984054565\n",
            "Epoch 2806, Loss: 0.5283342599868774\n",
            "Epoch 2807, Loss: 0.5283340811729431\n",
            "Epoch 2808, Loss: 0.5283339023590088\n",
            "Epoch 2809, Loss: 0.5283336639404297\n",
            "Epoch 2810, Loss: 0.5283334851264954\n",
            "Epoch 2811, Loss: 0.528333306312561\n",
            "Epoch 2812, Loss: 0.5283331274986267\n",
            "Epoch 2813, Loss: 0.5283328890800476\n",
            "Epoch 2814, Loss: 0.5283327102661133\n",
            "Epoch 2815, Loss: 0.528332531452179\n",
            "Epoch 2816, Loss: 0.5283323526382446\n",
            "Epoch 2817, Loss: 0.5283321738243103\n",
            "Epoch 2818, Loss: 0.528331995010376\n",
            "Epoch 2819, Loss: 0.5283318161964417\n",
            "Epoch 2820, Loss: 0.5283315777778625\n",
            "Epoch 2821, Loss: 0.5283313989639282\n",
            "Epoch 2822, Loss: 0.5283311605453491\n",
            "Epoch 2823, Loss: 0.5283310413360596\n",
            "Epoch 2824, Loss: 0.5283308029174805\n",
            "Epoch 2825, Loss: 0.5283305644989014\n",
            "Epoch 2826, Loss: 0.528330385684967\n",
            "Epoch 2827, Loss: 0.5283302068710327\n",
            "Epoch 2828, Loss: 0.5283300280570984\n",
            "Epoch 2829, Loss: 0.5283297896385193\n",
            "Epoch 2830, Loss: 0.528329610824585\n",
            "Epoch 2831, Loss: 0.5283294320106506\n",
            "Epoch 2832, Loss: 0.5283291935920715\n",
            "Epoch 2833, Loss: 0.5283290147781372\n",
            "Epoch 2834, Loss: 0.5283287763595581\n",
            "Epoch 2835, Loss: 0.5283286571502686\n",
            "Epoch 2836, Loss: 0.5283284783363342\n",
            "Epoch 2837, Loss: 0.5283282399177551\n",
            "Epoch 2838, Loss: 0.528328001499176\n",
            "Epoch 2839, Loss: 0.5283278226852417\n",
            "Epoch 2840, Loss: 0.5283276438713074\n",
            "Epoch 2841, Loss: 0.528327465057373\n",
            "Epoch 2842, Loss: 0.528327226638794\n",
            "Epoch 2843, Loss: 0.5283270478248596\n",
            "Epoch 2844, Loss: 0.5283268690109253\n",
            "Epoch 2845, Loss: 0.528326690196991\n",
            "Epoch 2846, Loss: 0.5283264517784119\n",
            "Epoch 2847, Loss: 0.5283262133598328\n",
            "Epoch 2848, Loss: 0.5283260345458984\n",
            "Epoch 2849, Loss: 0.5283258557319641\n",
            "Epoch 2850, Loss: 0.5283256769180298\n",
            "Epoch 2851, Loss: 0.5283254384994507\n",
            "Epoch 2852, Loss: 0.5283252596855164\n",
            "Epoch 2853, Loss: 0.528325080871582\n",
            "Epoch 2854, Loss: 0.5283249020576477\n",
            "Epoch 2855, Loss: 0.5283246636390686\n",
            "Epoch 2856, Loss: 0.5283244848251343\n",
            "Epoch 2857, Loss: 0.5283243060112\n",
            "Epoch 2858, Loss: 0.5283240675926208\n",
            "Epoch 2859, Loss: 0.5283238887786865\n",
            "Epoch 2860, Loss: 0.5283236503601074\n",
            "Epoch 2861, Loss: 0.5283234715461731\n",
            "Epoch 2862, Loss: 0.5283232927322388\n",
            "Epoch 2863, Loss: 0.5283231139183044\n",
            "Epoch 2864, Loss: 0.5283228754997253\n",
            "Epoch 2865, Loss: 0.528322696685791\n",
            "Epoch 2866, Loss: 0.5283224582672119\n",
            "Epoch 2867, Loss: 0.5283222794532776\n",
            "Epoch 2868, Loss: 0.5283221006393433\n",
            "Epoch 2869, Loss: 0.5283218622207642\n",
            "Epoch 2870, Loss: 0.5283216834068298\n",
            "Epoch 2871, Loss: 0.5283214449882507\n",
            "Epoch 2872, Loss: 0.5283212661743164\n",
            "Epoch 2873, Loss: 0.5283210873603821\n",
            "Epoch 2874, Loss: 0.5283209085464478\n",
            "Epoch 2875, Loss: 0.5283206701278687\n",
            "Epoch 2876, Loss: 0.5283204913139343\n",
            "Epoch 2877, Loss: 0.5283202528953552\n",
            "Epoch 2878, Loss: 0.5283200740814209\n",
            "Epoch 2879, Loss: 0.5283198952674866\n",
            "Epoch 2880, Loss: 0.5283197164535522\n",
            "Epoch 2881, Loss: 0.5283194780349731\n",
            "Epoch 2882, Loss: 0.528319239616394\n",
            "Epoch 2883, Loss: 0.5283190608024597\n",
            "Epoch 2884, Loss: 0.5283188819885254\n",
            "Epoch 2885, Loss: 0.5283186435699463\n",
            "Epoch 2886, Loss: 0.528318464756012\n",
            "Epoch 2887, Loss: 0.5283182859420776\n",
            "Epoch 2888, Loss: 0.5283180475234985\n",
            "Epoch 2889, Loss: 0.5283178091049194\n",
            "Epoch 2890, Loss: 0.5283176302909851\n",
            "Epoch 2891, Loss: 0.5283174514770508\n",
            "Epoch 2892, Loss: 0.5283172130584717\n",
            "Epoch 2893, Loss: 0.5283170342445374\n",
            "Epoch 2894, Loss: 0.528316855430603\n",
            "Epoch 2895, Loss: 0.5283166170120239\n",
            "Epoch 2896, Loss: 0.5283164381980896\n",
            "Epoch 2897, Loss: 0.5283161997795105\n",
            "Epoch 2898, Loss: 0.528316080570221\n",
            "Epoch 2899, Loss: 0.5283158421516418\n",
            "Epoch 2900, Loss: 0.5283156037330627\n",
            "Epoch 2901, Loss: 0.5283154249191284\n",
            "Epoch 2902, Loss: 0.5283151865005493\n",
            "Epoch 2903, Loss: 0.528315007686615\n",
            "Epoch 2904, Loss: 0.5283147692680359\n",
            "Epoch 2905, Loss: 0.5283145904541016\n",
            "Epoch 2906, Loss: 0.5283144116401672\n",
            "Epoch 2907, Loss: 0.5283142328262329\n",
            "Epoch 2908, Loss: 0.5283139944076538\n",
            "Epoch 2909, Loss: 0.5283137559890747\n",
            "Epoch 2910, Loss: 0.5283135771751404\n",
            "Epoch 2911, Loss: 0.5283133387565613\n",
            "Epoch 2912, Loss: 0.528313159942627\n",
            "Epoch 2913, Loss: 0.5283129811286926\n",
            "Epoch 2914, Loss: 0.5283128023147583\n",
            "Epoch 2915, Loss: 0.5283125042915344\n",
            "Epoch 2916, Loss: 0.5283123254776001\n",
            "Epoch 2917, Loss: 0.5283121466636658\n",
            "Epoch 2918, Loss: 0.5283119082450867\n",
            "Epoch 2919, Loss: 0.5283117294311523\n",
            "Epoch 2920, Loss: 0.528311550617218\n",
            "Epoch 2921, Loss: 0.5283113121986389\n",
            "Epoch 2922, Loss: 0.5283111333847046\n",
            "Epoch 2923, Loss: 0.5283109545707703\n",
            "Epoch 2924, Loss: 0.5283107161521912\n",
            "Epoch 2925, Loss: 0.5283104777336121\n",
            "Epoch 2926, Loss: 0.5283102989196777\n",
            "Epoch 2927, Loss: 0.5283100605010986\n",
            "Epoch 2928, Loss: 0.5283098816871643\n",
            "Epoch 2929, Loss: 0.52830970287323\n",
            "Epoch 2930, Loss: 0.5283094644546509\n",
            "Epoch 2931, Loss: 0.5283092260360718\n",
            "Epoch 2932, Loss: 0.5283091068267822\n",
            "Epoch 2933, Loss: 0.5283088684082031\n",
            "Epoch 2934, Loss: 0.528308629989624\n",
            "Epoch 2935, Loss: 0.5283084511756897\n",
            "Epoch 2936, Loss: 0.5283082127571106\n",
            "Epoch 2937, Loss: 0.5283080339431763\n",
            "Epoch 2938, Loss: 0.5283077955245972\n",
            "Epoch 2939, Loss: 0.5283075571060181\n",
            "Epoch 2940, Loss: 0.5283073782920837\n",
            "Epoch 2941, Loss: 0.5283071994781494\n",
            "Epoch 2942, Loss: 0.5283069610595703\n",
            "Epoch 2943, Loss: 0.528306782245636\n",
            "Epoch 2944, Loss: 0.5283066034317017\n",
            "Epoch 2945, Loss: 0.5283063650131226\n",
            "Epoch 2946, Loss: 0.5283061861991882\n",
            "Epoch 2947, Loss: 0.5283059477806091\n",
            "Epoch 2948, Loss: 0.52830570936203\n",
            "Epoch 2949, Loss: 0.5283055305480957\n",
            "Epoch 2950, Loss: 0.5283052921295166\n",
            "Epoch 2951, Loss: 0.5283051133155823\n",
            "Epoch 2952, Loss: 0.5283048748970032\n",
            "Epoch 2953, Loss: 0.5283046364784241\n",
            "Epoch 2954, Loss: 0.5283044576644897\n",
            "Epoch 2955, Loss: 0.5283042788505554\n",
            "Epoch 2956, Loss: 0.5283040404319763\n",
            "Epoch 2957, Loss: 0.5283038020133972\n",
            "Epoch 2958, Loss: 0.5283036828041077\n",
            "Epoch 2959, Loss: 0.5283034443855286\n",
            "Epoch 2960, Loss: 0.5283032059669495\n",
            "Epoch 2961, Loss: 0.5283029675483704\n",
            "Epoch 2962, Loss: 0.528302788734436\n",
            "Epoch 2963, Loss: 0.5283026099205017\n",
            "Epoch 2964, Loss: 0.5283023715019226\n",
            "Epoch 2965, Loss: 0.5283021926879883\n",
            "Epoch 2966, Loss: 0.5283019542694092\n",
            "Epoch 2967, Loss: 0.5283017158508301\n",
            "Epoch 2968, Loss: 0.5283015370368958\n",
            "Epoch 2969, Loss: 0.5283012986183167\n",
            "Epoch 2970, Loss: 0.5283011198043823\n",
            "Epoch 2971, Loss: 0.5283008813858032\n",
            "Epoch 2972, Loss: 0.5283007025718689\n",
            "Epoch 2973, Loss: 0.5283004641532898\n",
            "Epoch 2974, Loss: 0.5283002257347107\n",
            "Epoch 2975, Loss: 0.5283000469207764\n",
            "Epoch 2976, Loss: 0.5282998085021973\n",
            "Epoch 2977, Loss: 0.5282996296882629\n",
            "Epoch 2978, Loss: 0.5282994508743286\n",
            "Epoch 2979, Loss: 0.5282992124557495\n",
            "Epoch 2980, Loss: 0.5282989740371704\n",
            "Epoch 2981, Loss: 0.5282987356185913\n",
            "Epoch 2982, Loss: 0.528298556804657\n",
            "Epoch 2983, Loss: 0.5282983183860779\n",
            "Epoch 2984, Loss: 0.5282980799674988\n",
            "Epoch 2985, Loss: 0.5282979011535645\n",
            "Epoch 2986, Loss: 0.5282976627349854\n",
            "Epoch 2987, Loss: 0.528297483921051\n",
            "Epoch 2988, Loss: 0.5282973051071167\n",
            "Epoch 2989, Loss: 0.5282970666885376\n",
            "Epoch 2990, Loss: 0.5282968282699585\n",
            "Epoch 2991, Loss: 0.5282965898513794\n",
            "Epoch 2992, Loss: 0.5282964110374451\n",
            "Epoch 2993, Loss: 0.528296172618866\n",
            "Epoch 2994, Loss: 0.5282959938049316\n",
            "Epoch 2995, Loss: 0.5282957553863525\n",
            "Epoch 2996, Loss: 0.5282955765724182\n",
            "Epoch 2997, Loss: 0.5282953381538391\n",
            "Epoch 2998, Loss: 0.52829509973526\n",
            "Epoch 2999, Loss: 0.5282949209213257\n",
            "Epoch 3000, Loss: 0.5282946825027466\n"
          ]
        }
      ],
      "source": [
        "args = argparse.ArgumentParser(description='Process some integers.')\n",
        "args.scenario = \"intersection\"\n",
        "args.restore = False\n",
        "args.goal = \"straight\"\n",
        "args.epochs = 3000\n",
        "args.lr = 0.0002\n",
        "data = load_data(args)\n",
        "nn(data, args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1065c665",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1065c665",
        "outputId": "aacfd942-06ed-4ab6-c420-af17405558c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar 12 05:48:47 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P0    27W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls policies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt8pRy96Wvya",
        "outputId": "c6161729-d08b-40e7-a0d4-410dcafc6bb4"
      },
      "id": "Mt8pRy96Wvya",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint                                    intersection_left_ILDIST.index\n",
            "intersection_left_ILDIST.data-00000-of-00001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hEndv6bEYsFY"
      },
      "id": "hEndv6bEYsFY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}